# 十四、容器

从开发过渡到生产一直是一个痛苦的过程。它涉及大量文档，移交，安装和配置。由于每种编程语言产生的软件行为略有不同，因此异构应用的部署始终很困难。

其中一些问题已通过集装箱得到缓解。有了容器，安装和配置大多标准化。如何处理发行有几种方法，但是这个问题也有一些标准可以遵循。这使得容器成为希望增加开发和运营之间合作的组织的绝佳选择。

本章将介绍以下主题:

*   建造集装箱
*   测试和集成容器
*   了解容器编排

# 技术要求

本章列出的示例需要以下内容:

*   Docker 20.10
*   清单工具 ([https://github.com/estesp/ 清单工具](https://github.com/estesp/manifest-tool))
*   建造 1.16
*   Ansible 2.10
*   ansible-bender
*   C 让 3.15

本章中出现的代码已放在 GitHub 上，https://github.com/PacktPublishing/ 软件架构与 Cpp/tree/master/Chapter14。

# 重新引入集装箱

集装箱最近引起了很多轰动。人们可能会认为它们是一种全新的技术，以前是没有的。然而，事实并非如此。在目前行业中占主导地位的 Docker 和 Kubernetes 崛起之前，已经有 LXC 等解决方案，它们提供了许多类似的功能。

我们可以使用 UNIX 系统 1979 年中可用的 chroot 机制来追踪将一个执行环境与另一个执行环境分开的起源。FreeBSD 监狱和 Solaris 地区也使用了类似的概念。

容器的主要任务是将一个执行环境与另一个执行环境隔离。这个孤立的环境可以有自己的配置，不同的应用，甚至不同于主机环境的用户帐户。

即使容器与主机隔离，它们通常共享相同的操作系统内核。这是与虚拟化环境的主要区别。虚拟机具有专用的虚拟资源，这意味着它们在硬件级别是分开的。容器在流程级别是分开的，这意味着运行它们的开销更少。

打包和运行另一个已经为运行应用进行了优化和配置的操作系统的能力是容器的一个强大优势。如果没有容器，构建和部署过程通常包括几个步骤:

1.  应用的构建。
2.  提供了示例配置文件。
3.  准备安装脚本和相关文档。
4.  该应用是为目标操作系统 (如 Debian 或 Red Hat) 打包的。
5.  包部署到目标平台。
6.  安装脚本为应用运行准备基础。
7.  必须调整配置以适应现有系统。

当您切换到容器时，对健壮的安装脚本的需求就更少了。该应用将仅针对单个知名操作系统-容器中存在的操作系统。配置也是如此: 应用不是准备许多可配置选项，而是为目标操作系统预先配置并分布在目标操作系统旁边。部署过程仅包括解包容器映像并在其中运行应用进程。

虽然容器和微服务通常被认为是一回事，但事实并非如此。而且，容器可能意味着应用容器或操作系统容器，并且只有应用容器才能很好地与微服务相适应。以下各节将告诉你原因。我们将描述您可能遇到的不同容器类型，向您展示它们与微服务的关系，并解释何时最好使用它们 (以及何时避免使用它们)。

## 探索容器类型

到目前为止描述的容器中，操作系统容器与当前由 Docker，Kubernetes 和 LXD 领导的容器趋势根本不同。应用容器不再专注于使用 syslog 和 cron 等服务重新创建整个操作系统，而是专注于在容器内运行单个进程-只是应用。

专有解决方案取代了所有通常的操作系统级服务。这些解决方案提供了一种统一的方式来管理容器内的应用。例如，不是使用 syslog 来处理日志，而是将带有 PID 1 的进程的标准输出视为应用日志。应用容器的生命周期由运行时应用处理，而不是使用诸如`init.d`或 systemd 之类的机制。

由于目前 Docker 是应用容器的主要解决方案，因此在本书中，我们将主要使用它作为示例。为了使图片完整，我们将提供可行的替代方案，因为它们可能更适合您的需求。由于项目和规范是开源的，因此这些替代方案与 Docker 兼容，可以用作替代品。

在本章的后面，我们将解释如何使用 Docker 来构建、部署、运行和管理应用容器。

## 微服务的兴起

Docker 的成功与采用微服务的兴起相吻合。这并不奇怪，因为微服务和应用容器自然地结合在一起。

没有应用容器，就没有简单统一的方法来打包、部署和维护微服务。尽管个别公司开发了一些解决方案来解决这些问题，但没有一家公司流行到足以成为行业标准。

没有微服务，应用容器非常有限。软件体系结构的重点是构建为在那里运行的给定服务集显式配置的整个系统。将一项服务替换为另一项服务需要更改体系结构。

当组合在一起时，应用容器为分发微服务提供了一种标准方式。每个微服务器都嵌入了自己的配置，因此自动缩放或自我修复等操作不再需要了解基础应用。

您仍然可以在没有应用容器的情况下使用微服务，并且可以在其中不托管微服务的情况下使用应用容器。例如，即使 PostgreSQL 数据库和 Nginx web 服务器都不是微服务，它们通常用于应用容器中。

## 选择何时使用容器

集装箱方法有几个好处。OS 容器和应用容器也有一些不同的用例，它们的优势在于它们。

### 集装箱的好处

与虚拟机 (隔离环境的另一种流行方法) 相比，容器在运行时所需的开销更少。与虚拟机不同，不需要运行单独版本的操作系统内核，也不需要使用硬件或软件虚拟化技术。应用容器也不运行通常在虚拟机 (如 syslog、cron 或 init) 中找到的其他操作系统服务。此外，应用容器提供较小的映像，因为它们通常不必携带整个操作系统副本。在极端示例中，应用容器可以由单个静态链接的二进制文件组成。

在这一点上，您可能想知道，如果里面只有一个二进制文件，为什么要打扰容器呢？有一个特别的好处是有一个统一和标准化的方式来构建和运行容器。由于容器必须遵循特定的约定，因此比常规二进制文件更容易编排它们，因为常规二进制文件在日志记录，配置，打开端口等方面可能具有不同的期望。

另一件事是容器提供了一种内置的隔离手段。每个容器都有自己的进程命名空间和用户帐户命名空间等。这意味着来自一个容器的进程 (或多个进程) 没有主机或其他容器中的进程的概念。沙箱可以走得更远，因为您可以使用相同的标准用户界面 (无论是 Docker，Kubernetes 还是其他) 为容器分配内存和 CPU 配额。

标准化的运行时也意味着更高的可移植性。构建容器后，您通常可以在不同的操作系统上运行它，而无需进行修改。这也意味着在操作中运行的内容与在开发中运行的内容非常接近或相同。问题再现更加轻松，调试也是如此。

### 集装箱的缺点

由于如今将工作负载转移到容器上的压力很大，因此您希望以架构师的身份了解与此类迁移相关的所有风险。好处到处都在吹捧，您可能已经了解它们。

采用容器的主要障碍是，并非所有应用都可以轻松地迁移到容器中。尤其是在考虑微服务的情况下设计的应用容器。如果您的应用不是基于微服务体系结构，则将其放入容器中可能会带来比它解决的问题更多的问题。

如果您的应用已经很好地扩展，使用基于 TCP/IP 的 IPC，并且大部分是无状态的，那么迁移到容器应该不会有挑战性。否则，这些方面中的每一个都将构成挑战，并促使人们重新考虑现有的设计。

与容器相关的另一个问题是持久性存储。理想情况下，容器应该没有自己的持久性存储。这使得可以利用快速启动、易于扩展和灵活调度的优势。问题是，提供业务价值的应用不能在没有持久性存储的情况下存在。

通常通过使大多数容器无状态并依靠外部非容器化组件来存储数据和状态来减轻此缺点。这样的外部组件可以是传统的自托管数据库，也可以是来自云提供商的托管数据库。朝着任何一个方向发展都需要您重新考虑架构并相应地对其进行修改。

由于应用容器遵循特定的约定，因此必须修改应用以遵循这些约定。对于某些应用，这将是一项低工作量的任务。对于其他的，例如使用内存**进程间通信** (**IPC**) 的多进程组件，将会很复杂。

经常忽略的一点是，只要其中的应用是本机 Linux 应用，应用容器就可以很好的工作。虽然支持 Windows 容器，但它们既不方便，也不像 Linux 容器那样受支持。它们还需要许可的 Windows 计算机作为主机运行。

如果您从头开始构建新的应用，并且可以基于此技术进行设计，则更容易享受应用容器的好处。将现有应用移动到应用容器 (尤其是复杂的应用) 将需要更多的工作，并且可能还需要对整个体系结构进行改进。在这种情况下，我们建议您格外仔细地考虑所有的利弊。做出错误的决定可能会损害您产品的交货时间、可用性和预算。

# 建造集装箱

应用容器是本节的重点。虽然 OS 容器大多遵循系统编程原则，但应用容器带来了新的挑战和模式。此外，他们还提供专门的构建工具来应对这些挑战。我们将考虑的主要工具是 Docker，因为它是构建和运行应用容器的当前事实上的标准。我们还将介绍一些构建应用容器的替代方法。

除非另有说明，否则从现在开始，每当我们使用 “容器” 一词时，它都与 “应用容器” 有关。

在本节中，我们将重点介绍使用 Docker 构建和部署容器的不同方法。

## 容器图像解释

在我们描述容器图像以及如何构建它们之前，了解容器和容器图像之间的区别至关重要。术语之间经常存在混淆，尤其是在非正式对话中。

容器和容器映像之间的区别与正在运行的进程和可执行文件之间的区别相同。

**容器映像是静态的**: 它们是特定文件系统和关联元数据的快照。元数据描述了在运行时设置的环境变量或从映像创建容器时要运行的程序。

**容器是动态的**: 它们正在运行容器镜像中包含的进程。我们可以从容器映像创建容器，也可以通过快照运行中的容器来创建容器映像。实际上，容器映像构建过程包括创建多个容器，在其中执行命令，并在命令完成后快照它们。

为了区分容器映像引入的数据和运行时生成的数据，Docker 使用 union mount filesystems 创建不同的文件系统层。这些层也存在于容器图像中。通常，容器映像的每个构建步骤对应于生成的容器映像中的新层。

## 使用 Dockerfiles 构建应用

使用 Docker 构建应用容器映像的最常见方法是使用 Dockerfile。Dockerfile 是一种命令式语言，描述了生成结果图像所需的操作。某些操作创建新的文件系统层; 其他操作则对元数据进行操作。

我们将不涉及与 Dockerfiles 相关的细节和细节。相反，我们将展示容器化 C 应用的不同方法。为此，我们需要介绍一些与 Dockerfiles 相关的语法和概念。

下面是一个非常简单的 Dockerfile 的例子:

```cpp
FROM ubuntu:bionic

RUN apt-get update && apt-get -y install build-essentials gcc

CMD /usr/bin/gcc
```

通常，我们可以将 Dockerfile 分为三个部分:

*   导入基本图像 (`FROM`指令)
*   在容器内执行将产生容器映像的操作 (`RUN`指令)
*   运行时使用的元数据 (`CMD`命令)

后两个部分可以是交错的，并且它们中的每一个可以包括一个或多个指令。也可以省略任何后面的部分，因为只有基本图像是强制性的。这并不意味着您不能从空文件系统开始。为此目的，有一个特殊的基础图像，名为`scratch`。将单个静态链接的二进制文件添加到否则为空的文件系统可能如下所示:

```cpp
FROM scratch

COPY customer /bin/customer

CMD /bin/customer
```

在第一个 Dockerfile 中，我们采取的步骤如下:

1.  导入基本 Ubuntu 仿生图像。
2.  在容器内部运行命令。命令的结果将在目标映像内部创建一个新的文件系统层。这意味着安装有`apt-get`的软件包将在基于此映像的所有容器中可用。
3.  设置运行时元数据。在基于该映像创建容器时，我们希望将`GCC`作为默认进程运行。

要从 Dockerfile 构建映像，您将使用`docker build`命令。它需要一个必需的参数，即包含构建上下文的目录，这意味着 Dockerfile 本身以及您要在容器中复制的其他文件。若要从当前目录构建 Dockerfile，请使用`docker build`。

这将建立一个匿名图像，这不是很有用。大多数时候，你想使用命名图像。在命名容器图像时要遵循一个约定，这就是我们将在下一节中介绍的内容。

## 命名和分发图像

Docker 中的每个容器映像都有一个独特的名称，由三个元素组成: 注册表名称，映像名称，标签。容器注册表是保存容器映像的对象存储库。Docker 的默认容器注册表为`docker.io`。从此注册表中提取图像时，我们可能会省略注册表名称。

我们前面有`ubuntu:bionic`的例子有`docker.io/ubuntu:bionic`的全称。在此示例中，`ubuntu`是图像的名称，而`bionic`是表示图像的特定版本的标签。

在基于容器构建应用时，您将对存储所有注册表映像感兴趣。可以托管您的私人注册表并将图像保留在那里或使用托管解决方案。流行的托管解决方案包括以下内容:

*   码头枢纽
*   Rotary. io
*   GitHub
*   云提供商 (如 AWS、GCP 或 Azure)

Docker Hub 仍然是最受欢迎的，尽管一些公共图像正在迁移到 quay.io。两者都是通用的，并且允许存储公共和私人图像。如果您已经在使用特定的平台，并且希望将图像保持在 CI 管道或部署目标附近，则 GitHub 或云提供商将主要吸引您。如果您想减少使用的单个服务的数量，这也很有帮助。

如果没有解决方案吸引您，那么托管您自己的本地注册表也非常容易，并且需要您运行单个容器。

要构建命名映像，需要将`-t`参数传递给`docker build`命令。例如，要构建一个名为`dominicanfair/merchant:v2.0.3`的图像，您将使用`docker build -t dominicanfair/merchant:v2.0.3 .`。

## 编译的应用和容器

在为解释语言 (如 Python 或 JavaScript) 中的应用构建容器映像时，方法基本相同:

1.  安装依赖项。
2.  将源文件复制到容器映像中。
3.  复制必要的配置。
4.  设置运行时命令。

但是，对于已编译的应用，还有一个额外的步骤，即首先编译应用。有几种可能的方法来实现这一步骤，每一种方法都有其优点和缺点。

最明显的方法是首先安装所有依赖项，复制源文件，然后将应用编译为容器构建步骤之一。主要的好处是，我们可以准确地控制工具链的内容和配置，因此有一个可移植的方式来构建应用。但是，缺点太大了，不容忽视: 生成的容器映像包含大量不必要的文件。毕竟，我们在运行时既不需要源代码也不需要工具链。由于 overlay 文件系统的工作方式，在上一层引入文件后，不可能删除文件。此外，如果攻击者设法闯入容器，则容器中的源代码可能会存在安全风险。

这是它的外观:

```cpp
FROM ubuntu:bionic

RUN apt-get update && apt-get -y install build-essentials gcc cmake

ADD . /usr/src

WORKDIR /usr/src

RUN mkdir build && \
    cd build && \
    cmake .. -DCMAKE_BUILD_TYPE=Release && \
    cmake --build . && \
    cmake --install .

CMD /usr/local/bin/customer
```

另一种明显的方法，以及我们前面讨论过的方法，是在主机上构建应用，并且仅在容器映像内复制生成的二进制文件。当已经建立一个构建过程时，这需要对当前构建过程进行较少的更改。主要缺点是您必须在构建机器上匹配相同的库集，就像在容器中一样。例如，如果您正在运行 Ubuntu 20.04 作为您的主机操作系统，那么您的容器也必须基于 Ubuntu 20.04。否则，你就有不兼容的风险。使用这种方法，还需要独立于容器配置工具链。

就像这样:

```cpp
FROM scratch

COPY customer /bin/customer

CMD /bin/customer
```

一种稍微复杂的方法是进行多阶段构建。对于多阶段构建，一个阶段可能专门用于设置工具链和编译项目，而另一个阶段则将生成的二进制文件复制到其目标容器映像中。这比以前的解决方案有几个好处。首先，Dockerfiles 现在同时控制工具链和运行时环境，因此构建的每个步骤都有完整的记录。其次，可以将映像与工具链一起使用，以确保开发与**连续集成**/**连续部署** (**CI/CD**) 管道之间的兼容性。这种方式还使将升级和修复程序分发到工具链本身变得更加容易。主要的缺点是，容器化工具链可能不像本地工具链那样容易使用。此外，构建工具并不特别适合应用容器，这要求每个容器运行一个进程。每当某些进程崩溃或被强制停止时，这可能会导致意外行为。

前面示例的多阶段版本如下所示:

```cpp
FROM ubuntu:bionic AS builder

RUN apt-get update && apt-get -y install build-essentials gcc cmake

ADD . /usr/src

WORKDIR /usr/src

RUN mkdir build && \
    cd build && \
    cmake .. -DCMAKE_BUILD_TYPE=Release && \
    cmake --build .

FROM ubuntu:bionic

COPY --from=builder /usr/src/build/bin/customer /bin/customer

CMD /bin/customer
```

第一阶段，从第一个`FROM`命令开始设置构建器，添加源，并构建二进制文件。然后，第二阶段，从第二个`FROM`命令开始，从前一阶段复制生成的二进制文件，而不复制工具链或源。

## 以清单为目标的多个架构

带有 Docker 的应用容器通常在 x86_64 (也称为 AMD64) 计算机上使用。如果您仅针对此平台，则无需担心。但是，如果您正在开发 IoT，嵌入式或边缘应用，则可能会对多体系结构映像感兴趣。

由于 Docker 可在许多不同的 CPU 体系结构上使用，因此有几种方法可以在多个平台上进行映像管理。

处理为不同目标构建的图像的一种方法是使用图像标签来描述特定平台。而不是`merchant:v2.0.3`，我们可以有`merchant:v2.0.3-aarch64`。尽管这种方法似乎最容易实现，但实际上有点问题。

您不仅必须更改构建过程以将体系结构包含在标记过程中。当拉动图像以运行它们时，您还必须小心手动在任何地方附加预期的后缀。如果您使用的是 orchestrator，则将无法以直接的方式在不同平台之间共享清单，因为标签将是特定于平台的。

不需要修改部署步骤的更好方法是使用`manifest-tool` ([https://github.com/estesp/ manifest-tool](https://github.com/estesp/manifest-tool))。最初的构建过程看起来与之前建议的过程相似。图像是在所有受支持的体系结构上单独构建的，并在其标签中使用平台后缀推送到注册表。所有图片推送完成后，`manifest-tool`将图片合并，提供单个多架构的图片。这样，每个受支持的平台都可以使用完全相同的标签。

这里提供了`manifest-tool`的示例配置:

```cpp
image: hosacpp/merchant:v2.0.3
manifests:
  - image: hosacpp/merchant:v2.0.3-amd64
    platform:
      architecture: amd64
      os: linux
  - image: hosacpp/merchant:v2.0.3-arm32
    platform:
      architecture: arm
      os: linux
  - image: hosacpp/merchant:v2.0.3-arm64
    platform:
      architecture: arm64
      os: linux
```

在这里，我们有三个受支持的平台，每个平台都有各自的后缀 (`hosacpp/merchant:v2.0.3-amd64`、`hosacpp/merchant:v2.0.3-arm32`和`hosacpp/merchant:v2.0.3-arm64`)。`Manifest-tool`结合为每个平台构建的图像，并生成一个我们可以在任何地方使用的`hosacpp/merchant:v2.0.3`图像。

另一种可能性是使用 Docker 的内置功能，称为 Buildx。使用 Buildx，您可以附加多个构建器实例，每个实例都针对一个所需的体系结构。有趣的是，您不需要本机机器来运行构建; 您也可以在多阶段构建中使用 QEMU 仿真或交叉编译。尽管它比以前的方法强大得多，但 Buildx 也相当复杂。在撰写本文时，它需要 Docker 实验模式和 linux 内核 4.8 或更高版本。它要求您设置和管理建筑商，而不是一切都以直观的方式行事。在不久的将来，它可能会有所改善并变得更加稳定。

准备构建环境并构建多平台映像的示例代码可能如下所示:

```cpp
# create two build contexts running on different machines
docker context create \
    --docker host=ssh://docker-user@host1.domifair.org \
    --description="Remote engine amd64" \
    node-amd64
docker context create \
    --docker host=ssh://docker-user@host2.domifair.org \
    --description="Remote engine arm64" \
    node-arm64

# use the contexts
docker buildx create --use --name mybuild node-amd64
docker buildx create --append --name mybuild node-arm64

# build an image
docker buildx build --platform linux/amd64,linux/arm64 .
```

如您所见，如果您习惯了常规的`docker build`命令，这可能会有些混乱。

## 构建应用容器的替代方法

使用 Docker 构建容器映像需要运行 Docker 守护程序。Docker 守护程序需要 root 权限，这可能会在某些设置中带来安全问题。即使进行构建的 Docker 客户端可能由非特权用户运行，但在构建环境中安装 Docker 守护程序并不总是可行的。

### 建筑

Buildah 是构建容器映像的替代工具，可以将其配置为在没有 root 访问权限的情况下运行。Buildah 可以使用常规的 Dockerfiles，这是我们前面讨论过的。它还提供了自己的命令行界面，您可以在 shell 脚本或其他更直观的自动化中使用它。以前使用 buildah 接口重写为 shell 脚本的 Dockerfiles 之一将如下所示:

```cpp
#!/bin/sh

ctr=$(buildah from ubuntu:bionic)

buildah run $ctr -- /bin/sh -c 'apt-get update && apt-get install -y build-essential gcc'

buildah config --cmd '/usr/bin/gcc' "$ctr"

buildah commit "$ctr" hosacpp-gcc

buildah rm "$ctr"
```

Buildah 的一个有趣的功能是，它允许您将容器映像文件系统挂载到主机文件系统中。这样，您可以使用主机的命令与图像的内容进行交互。如果您有不希望 (或由于许可限制而无法) 将软件放入容器中，则在使用 Buildah 时仍然可以在容器之外调用它。

### Ansible-bender

Ansible-bender 使用 Ansible 剧本和 Buildah 来构建容器图像。所有配置 (包括基本图像和元数据) 都作为变量在 playbook 中传递。下面是我们之前转换为 Ansible 语法的例子:

```cpp
---
- name: Container image with ansible-bender
  hosts: all
  vars:
    ansible_bender:
      base_image: python:3-buster

      target_image:
        name: hosacpp-gcc
        cmd: /usr/bin/gcc
  tasks:
  - name: Install Apt packages
    apt:
      pkg:
        - build-essential
        - gcc
```

如您所见，`ansible_bender`变量负责所有特定于容器的配置。下面介绍的任务是基于`base_image`在容器内部执行的。

需要注意的一点是，Ansible 需要在基本图像中存在一个 Python 解释器。这就是为什么我们必须将前面示例中使用的`ubuntu:bionic`更改为`python:3-buster`。`ubuntu:bionic`是一个没有预装 Python 解释器的 Ubuntu 镜像。

### 其他

还有其他构建容器映像的方法。例如，您可以使用 Nix 创建文件系统映像，然后使用 Dockerfile 的`COPY`指令将其放入映像中。更进一步，您可以通过任何其他方式准备文件系统映像，然后使用`docker import`将其作为基本容器映像导入。

选择适合您特定需求的解决方案。请记住，使用`docker build`使用 Dockerfile 进行构建是最受欢迎的方法，因此它是记录最好的方法，也是最受支持的方法。使用 Buildah 更加灵活，可以让您更好地将创建容器映像纳入构建过程。最后，如果您已经在 Ansible 上投入了大量资金，并且想要重用已经可用的模块，那么`ansible-bender`可能是一个很好的解决方案。

## 将容器与 c 制造集成

在本节中，我们将演示如何通过使用 c 制造来创建 Docker 映像。

### 使用 c 制造配置 Dockerfile

首先，也是最重要的，我们需要一个码头文件。让我们使用另一个 c 让输入文件:

```cpp
configure_file(${CMAKE_CURRENT_SOURCE_DIR}/Dockerfile.in
                ${PROJECT_BINARY_DIR}/Dockerfile @ONLY)
```

请注意，如果我们的项目是更大的项目的一部分，我们正在使用`PROJECT_BINARY_DIR`不覆盖源树中其他项目创建的任何 Dockerfiles。

我们的`Dockerfile.in`文件如下所示:

```cpp
FROM ubuntu:latest
ADD Customer-@PROJECT_VERSION@-Linux.deb .
RUN apt-get update && \
    apt-get -y --no-install-recommends install ./Customer-@PROJECT_VERSION@-Linux.deb && \
    apt-get autoremove -y && \
    apt-get clean && \
    rm -r /var/lib/apt/lists/* Customer-@PROJECT_VERSION@-Linux.deb
ENTRYPOINT ["/usr/bin/customer"]
EXPOSE 8080
```

首先，我们指定我们将采用最新的 Ubuntu 映像，在其上安装 DEB 软件包及其依赖项，然后进行整理。在安装软件包的同一步骤中更新软件包管理器缓存非常重要，以避免由于 Docker 中的图层工作方式而导致的陈旧缓存问题。清理也作为相同的`RUN`命令的一部分 (在同一层中) 执行，以使层大小更小。安装软件包后，我们使映像在启动时运行`customer`微服务。最后，我们告诉 Docker 公开它将监听的端口。

现在，回到我们的`CMakeLists.txt`文件。

### 将容器与 c 制造集成

对于基于 cjke 的项目，可以包括负责构建容器的构建步骤。为此，我们需要告诉 c 让找到 Docker 可执行文件，如果没有，请予以救助。我们可以使用以下方法来做到这一点:

```cpp
find_program(Docker_EXECUTABLE docker)
 if(NOT Docker_EXECUTABLE)
   message(FATAL_ERROR "Docker not found")
 endif()
```

让我们从[第 7 章](07.html)，*构建和包装*中的一个示例重新审视。在那里，我们为客户应用构建了一个二进制文件和一个柯南包。现在，我们希望将此应用打包为 Debian 存档，并使用客户应用的预安装软件包构建 Debian 容器映像。

要创建我们的 DEB 包，我们需要一个帮助目标。让我们使用 cmado 的`add_custom_target`功能:

```cpp
add_custom_target(
   customer-deb
   COMMENT "Creating Customer DEB package"
   COMMAND ${CMAKE_CPACK_COMMAND} -G DEB
   WORKING_DIRECTORY ${PROJECT_BINARY_DIR}
   VERBATIM)
 add_dependencies(customer-deb libcustomer)
```

我们的目标调用 CPack 来创建一个对我们来说很有趣的软件包，而省略了其余的软件包。为了方便起见，我们希望在与 Dockerfile 相同的目录中创建软件包。`VERBATIM`关键字推荐为，有了它，c 让会转义有问题的字符。如果未指定，则脚本的行为可能会因不同平台而异。

`add_dependencies`调用将确保在 c 使得生成`customer-deb`目标之前，已经生成`libcustomer`。因为我们现在有了我们的帮助对象目标，让我们在创建容器映像时使用它:

```cpp
add_custom_target(
   docker
   COMMENT "Preparing Docker image"
   COMMAND ${Docker_EXECUTABLE} build ${PROJECT_BINARY_DIR}
           -t dominicanfair/customer:${PROJECT_VERSION} -t dominicanfair/customer:latest
   VERBATIM)
 add_dependencies(docker customer-deb)
```

如您所见，我们调用前面在包含 Dockerfile 和 DEB 包的目录中找到的 Docker 可执行文件来创建映像。我们还告诉 Docker 将我们的图像标记为最新的和我们项目的版本。最后，我们确保在调用 Docker 目标时将构建 DEB 包。

如果`make`是您选择的生成器，那么构建图像就像`make docker`一样简单。如果您更喜欢 full ccreate 命令 (例如，创建 generator 不可知脚本)，则调用为`cmake --build . --target docker`。

# 测试和集成容器

容器非常适合 CI/CD 管道。由于除了容器运行时本身之外，它们通常不需要其他依赖项，因此可以轻松测试它们。不必为满足测试需求而配备工作机器，因此添加更多节点要容易得多。更重要的是，它们都是通用的，因此它们既可以充当构建者，测试跑步者，甚至可以充当部署执行者，而无需任何先前的配置。

在**CI**/**CD**中使用容器的另一个巨大好处是它们彼此隔离。这意味着在同一台计算机上运行的多个副本不应干扰。除非测试需要来自主机操作系统的一些资源，例如端口转发或卷挂载，否则这是正确的。因此，最好设计测试，这样这样的资源是不必要的 (或者至少它们不会冲突)。例如，端口随机化是一种避免冲突的有用技术。

## 容器内的运行库

容器的选择可能会影响工具链的选择，因此会影响应用可用的 c 语言功能。由于容器通常是基于 Linux 的，因此可用的系统编译器通常是带有 glibc 作为标准库的 GNU GCC。但是，一些受容器欢迎的 Linux 发行版 (例如 Alpine Linux) 基于不同的标准库 musl。

如果您的目标是这样的发行版，请确保您将使用的代码，无论是内部开发的还是来自第三方提供商的代码，都与 musl 兼容。musl 和 Alpine Linux 的主要优点是它的容器映像要小得多。例如，为 Debian Buster 构建的 Python 映像约为 330 MB，精简的 Debian 版本约为 40 MB，而 Alpine 版本仅约为 16 MB。较小的图像意味着更少的浪费带宽 (用于上传和下载) 和更快的更新。

Alpine 还可能引入一些不需要的特征，例如更长的构建时间，模糊的错误或性能降低。如果要使用它来减小大小，请运行适当的测试以确保应用的行为没有问题。

为了进一步减小图像的大小，您可以考虑完全放弃底层操作系统。这里的操作系统是指容器中通常存在的所有 userland 工具，例如 shell，包管理器和共享库。毕竟，如果你的应用是唯一要运行的东西，其他一切都是不必要的。

对于 Go 或 Rust 应用来说，典型的是提供静态构建，该构建是自给自足的，并且可以形成容器图像。虽然这在 C 中可能不那么简单，但值得考虑。

还有一些与减小图像尺寸相关的缺点。首先，如果您决定使用 Alpine Linux，请记住它不如 Ubuntu，Debian 或 CentOS 流行。尽管它通常是容器开发人员的首选平台，但对于任何其他目的而言，它都是非常不寻常的。

这意味着可能存在新的兼容性问题，主要是因为它不是基于事实上的标准 glibc 实现。如果您依赖第三方组件，则提供商可能不会为此平台提供支持。

如果您决定在容器映像路由内使用单个静态链接的二进制文件，则还需要考虑一些挑战。首先，不鼓励您静态链接 glibc，因为它内部使用 dloopen 来处理**名称服务开关** (**NSS**) 和 iconv。如果您的软件依赖于 DNS 解析或字符集转换，则无论如何您都必须提供 glibc 和相关库的副本。

需要考虑的另一点是，shell 和包管理器通常用于调试行为不当的容器。当您的一个容器行为异常时，您可能会在容器内启动另一个进程，并使用标准 UNIX 工具 (如`ps`、`ls`或`cat`) 来了解内部发生了什么。要在容器内部运行这样的应用，它必须首先出现在容器映像中。一些解决方法允许操作员将调试二进制文件注入正在运行的容器中，但目前没有一个得到很好的支持。

## 替代容器运行时间

Docker 是构建和运行容器的最流行方法，但是由于容器标准是开放的，因此您还可以使用其他运行时。提供类似用户体验的 Docker 的主要替代品是 Podman。与上一节中介绍的 Buildah 一起，它们是旨在完全取代 Docker 的工具。

额外的好处是，它们*不需要像 Docker 那样在主机上运行的其他守护程序*。两者都有对无根操作的支持 (尽管尚未成熟)，这使它们更适合安全关键操作。Podman 接受您期望 Docker CLI 采取的所有命令，因此您可以简单地将其用作别名。

旨在提供更好安全性的另一种容器方法是**Kata containers**计划。Kata 容器使用轻量级虚拟机来利用容器和主机操作系统之间额外级别隔离所需的硬件虚拟化。

Cri-O 和 containerd 也是 Kubernetes 使用的流行运行时。

# 了解容器编排

只有当您使用容器编排器来管理它们时，某些容器的好处才会变得明显。orchestrator 会跟踪将运行您的工作负载的所有节点，并且还会监视分布在这些节点上的容器的运行状况和状态。

更高级的功能，例如高可用性，需要适当设置协调器，这通常意味着将至少三个机器专用于控制平面，将另外三个机器专用于工作节点。节点的自动缩放，除了容器的自动缩放之外，还要求协调器具有能够控制底层基础架构的驱动程序 (例如，通过使用云提供商的 API)。

在这里，我们将介绍一些最受欢迎的编曲器，您可以选择这些编曲器作为您的系统的基础。您将在下一章[第 15 章](https://cdp.packtpub.com/hands_on_software_architecture_with_c__/wp-admin/post.php?post=41&action=edit)，*云原生设计*中找到更多关于 Kubernetes 的实用信息。在这里，我们向您概述可能的选择。

所呈现的编排器在类似的对象 (服务、容器、批处理作业) 上操作，尽管每个对象可能表现不同。可用的功能和操作原理在它们之间有所不同。它们的共同点是，您通常编写一个配置文件，声明性地描述所需的资源，然后使用专用的 CLI 工具应用此配置。为了说明这些工具之间的差异，我们提供了一个示例配置，该配置指定了之前引入的 web 应用 (merchant service) 和流行的 web 服务器 Nginx 来充当代理。

## 自托管解决方案

无论您是在本地、私有云中还是在公共云中运行应用，您都可能希望对您选择的编排器进行严格控制。以下是该空间中的自托管解决方案的集合。请记住，它们中的大多数也可以作为托管服务使用。但是，使用自托管可以帮助您防止供应商锁定，这对于您的组织可能是理想的。

### Kubernetes

Kubernetes 可能是我们在这里提到的所有协调者中最著名的协调者。它很普遍，这意味着如果您决定实施它，将有很多文档和社区支持。

即使 Kubernetes 使用与 Docker 相同的应用容器格式，但这基本上是所有相似之处的结尾。使用标准 Docker 工具直接与 Kubernetes 集群和资源进行交互是不可能的。使用 Kubernetes 时有一套新的工具和概念需要学习。

而对于 Docker，容器是您将要操作的主要对象，对于 Kubernetes，运行时的最小部分称为 Pod。一个 Pod 可能由一个或多个共享挂载点和网络资源的容器组成。Pod 本身很少引起人们的兴趣，因为 Kubernetes 还具有更高阶的概念，例如复制控制器，部署控制器或守护进程集。它们的作用是跟踪 pod 并确保在节点上运行所需数量的副本。

Kubernetes 中的联网模式也与 Docker 有很大不同。使用 Docker，您可以从容器转发端口，以使其可以从不同的计算机访问。使用 Kubernetes，如果您想要访问 pod，通常会创建一个服务资源，该资源可以充当负载均衡器来处理到构成服务后端的 pod 的流量。服务可能用于 pod 到 pod 的通信，但它们也可能暴露在 internet 上。在内部，Kubernetes 资源使用 DNS 名称执行服务发现。

Kubernetes 是声明性的，最终是一致的。这意味着，您无需直接创建和分配资源，只需提供所需结束状态的描述，Kubernetes 将完成将集群带到所需状态所需的工作。资源通常使用 YAML 来描述。

由于 Kubernetes 具有高度可扩展性，在**云计算基础** (**CNCF**) 下开发的关联项目很多，将 Kubernetes 变成了一个与提供商无关的云开发平台。我们将在下一章中更详细地介绍 Kubernetes，[第 15 章](15.html)，*云原生设计*。

以下是资源定义如何使用 YAML (`merchant.yaml`) 查找 Kubernetes:

```cpp
apiVersion: apps/v1
kind: Deployment
metadata:
  labels:
    app: dominican-front
  name: dominican-front
spec:
  selector:
    matchLabels:
      app: dominican-front
  template:
    metadata:
      labels:
        app: dominican-front
    spec:
      containers:
        - name: webserver
          imagePullPolicy: Always
          image: nginx
          ports:
            - name: http
              containerPort: 80
              protocol: TCP
      restartPolicy: Always
---
apiVersion: v1
kind: Service
metadata:
  labels:
    app: dominican-front
  name: dominican-front
spec:
  ports:
    - port: 80
      protocol: TCP
      targetPort: 80
  selector:
    app: dominican-front
  type: ClusterIP
---
apiVersion: apps/v1
kind: Deployment
metadata:
  labels:
    app: dominican-merchant
  name: merchant
spec:
  selector:
    matchLabels:
      app: dominican-merchant
  replicas: 3
  template:
    metadata:
      labels:
        app: dominican-merchant
    spec:
      containers:
        - name: merchant
          imagePullPolicy: Always
          image: hosacpp/merchant:v2.0.3
          ports:
            - name: http
              containerPort: 8000
              protocol: TCP
      restartPolicy: Always
---
apiVersion: v1
kind: Service
metadata:
  labels:
    app: dominican-merchant
  name: merchant
spec:
  ports:
    - port: 80
      protocol: TCP
      targetPort: 8000
  selector:
    app: dominican-merchant
    type: ClusterIP
```

要应用此配置并编排容器，请使用`kubectl apply -f merchant.yaml`。

### 码头工人群

构建和运行 Docker 容器也需要 Docker 引擎，它预装了自己的 orchestrator。该 orchestrator 是 Docker Swarm，其主要功能是通过使用 Docker API 与现有 Docker 工具高度兼容。

Docker Swarm 使用服务的概念来管理健康检查和自动缩放。它本地支持服务的滚动升级。服务能够发布其端口，然后由 Swarm 的负载平衡器提供服务。它支持将配置存储为用于运行时自定义的对象，并且内置了基本的秘密管理。

Docker Swarm 比 Kubernetes 更简单，可扩展性也更低。如果您不想了解 Kubernetes 的所有细节，这可能是一个优势。但是，主要的缺点是缺乏知名度，这意味着很难找到有关 Docker Swarm 的相关资料。

使用 Docker Swarm 的好处之一是您不必学习新命令。如果您已经习惯了 Docker 和 Docker 编写，则 Swarm 使用相同的资源。它允许扩展 Docker 来处理部署的特定选项。

用 Swarm 编排的两个服务看起来像这样 (`docker-compose.yml` ):

```cpp
version: "3.8"
services:
  web:
    image: nginx
    ports:
      - "80:80"
    depends_on:
      - merchant
  merchant:
    image: hosacpp/merchant:v2.0.3
    deploy:
      replicas: 3
    ports:
      - "8000"
```

要应用配置，请运行`docker stack deploy --compose-file docker-compose.yml dominican`。

### 游牧民族

Nomad 与前两种解决方案不同，因为它不仅仅专注于容器。它是一个通用的协调器，支持 Docker，Podman，Qemu 虚拟机，隔离的 fork/exec 和其他几个任务驱动程序。如果您想在不将应用迁移到容器的情况下获得容器编排的一些优势，Nomad 是一个值得学习的解决方案。

与其他 HashiCorp 产品 (例如用于服务发现的 Consul 和用于秘密管理的 Vault) 进行设置和集成相对容易。与 Docker 或 Kubernetes 一样，Nomad 客户端可以在本地运行并连接到负责管理群集的服务器。

Nomad 有三种工作类型:

*   **服务**: 一个长期的任务，不应该在没有人工干预的情况下退出 (例如，web 服务器或数据库)。
*   **Batch**: 寿命较短的任务，可以在短短几分钟内完成。如果批处理作业返回指示错误的退出代码，则根据配置重新启动或重新安排。
*   **System**: 集群中每个节点 (例如 logging agent) 都需要运行的任务。

与其他编曲者相比，Nomad 相对易于安装和维护。当涉及到任务驱动程序或设备插件 (用于访问专用硬件，如 gpu 或 fpga) 时，它也是可扩展的。与 Kubernetes 相比，它缺乏社区支持和第三方集成。Nomad 不需要您重新设计应用的体系结构来访问所提供的好处，Kubernetes 通常是这种情况。

要使用 Nomad 配置这两个服务，我们需要两个配置文件。第一个是`nginx.nomad`:

```cpp
job "web" {
  datacenters = ["dc1"]
  type = "service"
  group "nginx" {
    task "nginx" {
      driver = "docker"
      config {
        image = "nginx"
        port_map {
          http = 80
        }
      }
      resources {
        network {
          port "http" {
              static = 80
          }
        }
      }
      service {
        name = "nginx"
        tags = [ "dominican-front", "web", "nginx" ]
        port = "http"
        check {
          type = "tcp"
          interval = "10s"
          timeout = "2s"
        }
      }
    }
  }
}
```

第二个描述了商家应用，所以它被称为`merchant.nomad`:

```cpp
job "merchant" {
  datacenters = ["dc1"]
  type = "service"
  group "merchant" {
    count = 3
    task "merchant" {
      driver = "docker"
      config {
        image = "hosacpp/merchant:v2.0.3"
        port_map {
          http = 8000
        }
      }
      resources {
        network {
          port "http" {
              static = 8000
          }
        }
      }
      service {
        name = "merchant"
        tags = [ "dominican-front", "merchant" ]
        port = "http"
        check {
          type = "tcp"
          interval = "10s"
          timeout = "2s"
        }
      }
    }
  }
}
```

要应用配置，请运行`nomad job run merchant.nomad && nomad job run nginx.nomad`。

### 开放班次

OpenShift 是 Red Hat 基于 Kubernetes 构建的商业容器平台。它包括许多其他组件，这些组件在 Kubernetes 集群的日常操作中很有用。您将获得一个容器注册表，一个类似于 Jenkins 的构建工具，用于监视的 Prometheus，用于服务网格的 Istio 和用于跟踪的 Jaeger。它与 Kubernetes 不完全兼容，因此不应将其视为直接替代品。

它建立在现有的 Red Hat 技术之上，例如 CoreOS 和 Red Hat Enterprise Linux。您可以在本地、红帽云中、受支持的公共云提供商之一 (包括 AWS、GCP、IBM 和 Microsoft Azure) 上使用它，也可以作为混合云使用它。

还有一个开源社区支持的项目，名为 OKD，它构成了 Red Hat 的 OpenShift 的基础。如果您不需要 OpenShift 的商业支持和其他好处，则仍可以将 OKD 用于 Kubernetes 工作流。

## 托管服务

如前所述，上述协调器中的一些也可作为托管服务使用。例如，Kubernetes 可以作为托管解决方案在多个公共云提供商中使用。本节将向您展示一些不同的容器编排方法，这些方法并不基于上面提到的任何解决方案。

### AWS ECS

在 Kubernetes 发布 1.0 版本之前，Amazon Web Services 提出了自己的容器编排技术，称为**弹性容器服务** (**ECS**)。ECS 提供了一个协调器，可以在需要时监控、扩展和重启您的服务。

要在 ECS 中运行容器，您需要提供将在其上运行工作负载的 EC2 实例。您不需要为 orchestrator 的使用付费，但您需要为通常使用的所有 AWS 服务 (例如，底层 EC2 实例或 RDS 数据库) 付费。

ECS 的一大优势是它与 AWS 生态系统的其他部分的出色集成。如果您已经熟悉 AWS 服务并对平台进行了投资，那么理解和管理 ECS 的麻烦就会更少。

如果您不需要许多 Kubernetes 高级功能及其扩展，则 ECS 可能是更好的选择，因为它更直接，更易于学习。

### AWS Fargate

AWS 提供的另一个托管协调器是 Fargate。与 ECS 不同，它不需要您为底层 EC2 实例进行配置和支付。您关注的唯一组件是容器，附加到它们的网络接口以及 IAM 权限。

与其他解决方案相比，Fargate 所需的维护量最少，并且最容易学习。由于该领域现有的 AWS 产品，自动缩放和负载平衡是开箱即用的。

这里的主要缺点是与 ECS 相比，您为托管服务支付的费用。无法直接比较，因为 ECS 需要为 EC2 实例付费，而 Fargate 则需要为内存和 CPU 使用率独立付费。一旦您的服务开始自动缩放，这种对群集缺乏直接控制的情况很容易导致高昂的成本。

### Azure 服务结构

上述所有解决方案的问题在于，它们主要以 Docker 容器为目标，而 Docker 容器首先是以 Linux 为中心。另一方面，Azure Service Fabric 是微软支持的 Windows 优先产品。它无需修改即可运行旧版 Windows 应用，如果它依赖此类服务，则可以帮助您迁移应用。

与 Kubernetes 一样，Azure Service Fabric 本身并不是一个容器编排器，而是一个可以在其上构建应用的平台。其中一个构建块恰好是容器，所以它作为一个协调器工作得很好。

随着最近推出 Azure Kubernetes 服务，Azure 云中的托管 Kubernetes 平台，使用 Service Fabric 的需求减少了。

# 摘要

当你是现代软件的架构师时，你必须考虑到现代技术。考虑到它们并不意味着盲目地跟随趋势; 这意味着能够客观地评估一个特定的主张在你的情况下是否有意义。

前几章介绍的微服务和本章介绍的容器都值得考虑和理解。它们也值得实施吗？这在很大程度上取决于你设计的是什么类型的产品。如果您已经阅读了此内容，则可以自己做出决定。

下一章专门介绍云原生设计。一个非常有趣但也很复杂的主题，它与面向服务的体系结构，CI/CD，微服务，容器和云服务联系在一起。事实证明，对于某些云原生构建块来说，C 的出色性能是一个受欢迎的功能。

# 问题

1.  应用容器与操作系统容器有何不同？
2.  UNIX 系统中沙箱环境的一些早期例子是什么？
3.  为什么容器非常适合微服务？
4.  容器和虚拟机的主要区别是什么？
5.  什么时候应用容器是一个糟糕的选择？
6.  构建多平台容器镜像的工具有哪些？
7.  除了 Docker，还有其他一些容器运行时？
8.  什么是一些受欢迎的管弦乐队？

# 进一步阅读

*   *学习 Docker-第二版*: [https://www.packtpub.com/product/ 学习-docker-第二版/9781786462923](https://www.packtpub.com/product/learning-docker-second-edition/9781786462923)
*   *学习 OpenShift*: [https://www.packtpub.com/product/ 学习-openshift/9781788992329](https://www.packtpub.com/product/learn-openshift/9781788992329)
*   *开发人员的 Docker*: [开发人员的 https://www.packtpub.com/product/ docker/9781789536058](https://www.packtpub.com/product/docker-for-developers/9781789536058)