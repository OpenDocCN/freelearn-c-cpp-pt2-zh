# 示例-基于 Linux 的信息娱乐系统

本章提供了一个如何使用基于 Linux 的**单板计算机** (**SBC**) 实现信息娱乐系统的示例。它还显示了如何使用蓝牙连接到远程设备，以及如何使用在线流媒体服务。生成的设备将能够播放来自各种来源的音频，而无需复杂的 UI。特别是，我们将涵盖以下主题:

*   为基于 Linux 的 SBC 开发
*   Linux 下使用蓝牙
*   播放来自各种来源的音频并录制音频
*   使用 GPIO 进行简单输入和语音识别
*   连接到在线流媒体音频服务

# 一个做所有事情的盒子

信息娱乐系统已经成为我们日常生活中的一个共同特征，从**车载娱乐** (**ICE**) 系统 (也称为**车载信息娱乐**或**IVI**) 开始，它从基本的收音机和盒式磁带播放器发展到包括导航和通过蓝牙连接到智能手机以访问一个人的音乐库等功能。另一个很大的特点是为驾驶员提供免提功能，这样他们就可以启动电话并控制收音机，而不必把眼睛从道路上移开或把手从方向盘上移开。

随着智能手机变得越来越流行，为他们的用户提供了对新闻、天气和娱乐的持续访问，在智能手机和 ICEs 上使用语音驱动界面的机载助手的到来最终导致了针对家庭使用的语音驱动信息娱乐系统的到来。这些通常包括扬声器和麦克风，以及用于语音驱动接口和访问所需的基于 internet 的服务所需的硬件。

本章将主要关注这种语音驱动的信息娱乐系统。在[第 10 章](10.html)、*用 Qt*开发嵌入式系统中，我们将深入了解添加图形用户界面的情况。

我们在这里要实现的目标如下:

*   播放来自蓝牙源的音乐，如智能手机
*   播放在线流媒体服务中的音乐
*   从本地文件系统播放音乐，包括 u 盘
*   录制音频片段，并在被询问时重复
*   用声音控制所有动作，用一些动作的按钮

在接下来的部分中，我们将研究这些目标以及如何实现它们。

# 需要硬件

对于这个项目，任何能够运行 Linux 的 SBC 都应该工作。它还需要具有以下功能才能实现完整:

*   访问在线内容的互联网连接 (无线或有线)。
*   蓝牙功能 (内置或作为附加模块)，允许系统充当蓝牙扬声器。
*   免费的 GPIO 输入，以允许连接按钮。
*   分别用于语音输入和音频播放的功能麦克风输入和音频输出。
*   SATA 连接或类似的连接存储设备，如硬盘驱动器。
*   用于 I2C 显示器的 I2C 总线外围设备。

对于本章中的示例代码，我们只需要麦克风输入和音频输出，以及本地媒体文件的一些存储。

在 GPIO 引脚上，我们可以连接许多按钮，这些按钮可用于控制信息娱乐系统，而无需使用声控系统。这对于使用语音激活系统会很尴尬的情况很方便，例如在打电话时暂停或静音音乐。

Connecting the buttons will not be demonstrated in this example, but an example can be found in an earlier project in [Chapter 3](03.html), *Developing for Embedded Linux and Similar Systems*. There, we used the WiringPi library to connect switches to GPIO pins and configured interrupt routines to handle changes on these switches.

如果要显示当前信息 (例如当前歌曲的名称或其他相关状态信息)，也可以将小型显示器连接到系统。可以通过 I2C 接口控制的 16x2 字符的廉价显示器是广泛可用的; 这些以及一系列 OLED 和其他小型显示器，由于其最低的硬件要求，将适用于此目的。

在[第 3 章](03.html)，*为嵌入式 Linux 和类似系统开发*中，我们简要介绍了人们可能希望为诸如此类的信息娱乐系统使用哪种硬件，以及许多可能的用户界面和存储选项。当然，正确的硬件配置取决于一个人的要求。如果要在本地存储大量音乐以进行播放，则将大型 SATA 硬盘驱动器连接到系统将非常方便。

但是，对于本章中的示例，我们将不做这样的假设，而更多地充当易于扩展的起点。因此，硬件要求非常小，超出了对麦克风和音频输出的明显需求。

# 软件要求

对于此项目，我们假设已在目标 SBC 上安装了 Linux，并且已安装并配置了用于硬件功能的驱动程序，例如麦克风和音频输出。

由于我们在此项目中使用 Qt 框架，因此也应满足所有依赖项。这意味着共享库应该存在于系统上，项目的生成二进制文件将在该系统上运行。Qt 框架可以通过操作系统的软件包管理器获得，也可以通过 Qt 网站在[http://qt.io/](http://qt.io/) 获得。

In [Chapter 10](10.html), *Developing Embedded Systems with Qt*, we will look at developing on embedded platforms with Qt in more detail. This chapter will briefly touch upon the use of Qt APIs.

根据我们是想直接在 SBC 上还是在我们的开发 PC 上编译应用程序，我们可能必须安装编译器工具链和对 SBC 的进一步依赖，或者在目标 SBC (ARM、x86 或其他体系结构) 上安装交叉编译工具链 for Linux。在[第 6 章](06.html)，*测试基于 OS 的应用程序*中，我们研究了 SBC 系统的交叉编译，以及在本地测试系统。

由于本章中的示例项目不需要任何特殊的硬件，因此可以在 Qt 框架支持的任何系统上直接编译。这是在将代码部署到 SBC 上之前测试代码的推荐方法。

# 蓝牙音频源和接收器

不幸的是，蓝牙是一项技术，尽管无处不在，但它的专有性质受到了损害。结果，缺乏对全部蓝牙功能 (以配置文件的形式) 的支持。我们对该项目感兴趣的配置文件称为**高级音频分发配置文件** (**A2DP**)。这是从蓝牙耳机到蓝牙扬声器的所有设备为了流式传输音频而使用的配置文件。

实现 A2DP 的任何设备都可以将音频流传输到 A2DP 接收器，或者本身可以充当接收器 (取决于 BT 堆栈实现)。从理论上讲，这将使某人可以将智能手机或类似设备连接到我们的信息娱乐系统，并在其上播放音乐，就像使用独立的蓝牙扬声器一样。

A2DP 配置文件中的接收器是 A2DP 接收器，而另一侧是 A2DP 源。蓝牙耳机或扬声器设备将始终是接收器设备，因为它们只能消耗音频流。可以将 PC，SBC 或类似的多功能设备配置为充当接收器或源。

如前所述，围绕在主流操作系统上实现完整蓝牙堆栈的复杂性导致除了蓝牙的基本串行通信功能之外，对其他任何东西的支持都乏善可陈。

虽然 FreeBSD，macOS，Windows 和 Android 都具有蓝牙堆栈，但它们可以支持的蓝牙适配器数量有限 (Windows 上只有一个，并且只有 USB 适配器)，它们支持的配置文件 (FreeBSD 是仅数据传输)，和可配置性 (Android 基本上只针对智能手机)。

对于 Windows 10，由于其蓝牙堆栈的更改，A2DP 配置文件支持目前已从 Windows 7 中的功能恢复为在编写之时的功能。有了 macOS，它的蓝牙堆栈增加了 A2DP 对操作系统版本 10.5 的支持 (豹，2007 年)，应该可以正常工作。

成为 Linux 官方蓝牙堆栈的 BlueZ 蓝牙堆栈最初由高通公司开发，现在包含在 linux 内核官方发行版中。它是功能最齐全的蓝牙堆栈之一。

随着从 BlueZ 版本 4 到 5 的移动，ALSA sound API 支持被删除，而是随着旧 API 的重命名而转移到 PulseAudio 音频系统。这意味着使用旧的 (版本 4) API 实现的应用程序和代码不再起作用。不幸的是，网上发现的许多示例代码和教程仍然针对版本 4，这是需要注意的，因为它们的工作方式非常不同。

BlueZ 通过 D-Bus Linux 系统 IPC (进程间通信) 系统进行配置，或者通过直接编辑配置文件进行配置。实际上，在本章的项目中以编程方式配置它的应用程序中实现 BlueZ 支持将相当复杂，但是，由于 api 的范围很广，以及设置配置选项的限制，这些选项超出了蓝牙堆栈，需要访问基于文本的配置文件。因此，应用程序必须以正确的权限运行才能访问某些属性和文件，直接编辑后者或手动执行这些步骤。

信息娱乐项目的另一个复杂之处是设置自动配对模式，否则远程设备 (智能手机) 将无法实际连接到信息娱乐系统。这也需要与蓝牙堆栈进行持续的交互，以轮询可能同时连接的任何新设备。

必须检查每个新设备以查看其是否支持 A2DP 源模式，在这种情况下，它将被添加到系统的音频输入中。然后可以连接到音频系统以利用该新输入。

由于此实现的复杂性和范围，因此在本章的示例代码中遗漏了它。但是，可以将其添加到代码中。树莓派 3 等 SBCs 配有内置蓝牙适配器。其他人可以使用 USB 设备添加蓝牙适配器。

# 在线流媒体

有许多在线流媒体服务可以集成到信息娱乐系统中，就像本章所关注的类型一样。它们都使用类似的流 API (通常是基于 HTTP 的 REST API)，它需要使用该服务创建一个帐户，使用该帐户可以获取一个特定于应用程序的令牌，该令牌可以访问该 API，从而可以查询特定的艺术家，音乐曲目，专辑，等等。

使用 HTTP 客户端 (例如在 Qt 框架中找到的客户端)，实现必要的控制流将相当容易。由于需要为这些流服务注册应用程序 ID，因此将其排除在示例代码之外。

从 REST API 流的基本序列通常是这样的，在 HTTP 调用周围有一个简单的包装类:

```cpp
#include "soundFoo"
// Create a client object with your app credentials.
client = soundFoo.new('YOUR_CLIENT_ID');
// Fetch track to stream.
track = client.get("/tracks/293")
// Get the tracks streaming URL.
stream_url = client.get(track.stream_url, true); 
// stream URL, allow redirects
// Print the tracks stream URL
std::cout << stream_url.location;
```

# 语音驱动的用户界面

该项目采用的用户界面完全可以通过语音命令控制。为此，它实现了一个由 PocketSphinx 库 (请参阅[https://cmusphinx.github.io/](https://cmusphinx.github.io/) ) 提供支持的语音到文本接口，该接口使用关键字定位和语法搜索来识别和解释给它的命令。

我们使用 PocketSphinx 发行版附带的默认美英语言模型。这意味着所讲的任何命令都应以美英口音发音，以便准确理解。要更改此设置，可以加载针对不同语言和重音的不同语言模型。可以通过 PocketSphinx 网站获得各种模型，并且可以通过一些努力来制作自己的语言模型。

# 使用场景

我们不希望信息娱乐系统在语音用户界面识别命令词时每次都被激活。防止这种情况发生的常见方法是拥有一个激活命令界面的关键字。如果在一定时间内关键字之后未识别出任何命令，则系统将恢复为关键字识别模式。

对于此示例项目，我们使用关键字`computer`。系统发现此关键字后，我们可以使用以下命令:

| **命令** | **结果** |
| Play Bluetooth | 从任何连接的 A2DP 源设备 (未实现) 开始播放。 |
| 停止蓝牙 | 停止从任何蓝牙设备播放。 |
| 玩本地游戏 | 播放 (硬编码的) 本地音乐文件。 |
| 停止本地 | 停止播放本地音乐文件 (如果当前正在播放)。 |
| 播放遥控器 | 从在线流媒体服务或服务器 (未实现) 播放。 |
| 停止远程 | 如果处于活动状态，则停止播放。 |
| 记录消息 | 记录一条消息。记录，直到出现数秒的沉默。 |
| 播放消息 | 播放录制的消息 (如果有)。 |

# 源代码

此应用程序已使用 Qt 框架作为 GUI 应用程序实现，因此我们还获得了易于调试的图形界面。此调试 UI 是使用 Qt Creator IDE 的 Qt 设计器作为单个 UI 文件设计的。

我们从创建 GUI 应用程序的实例开始:

```cpp
#include "mainwindow.h" 
#include <QApplication> 

int main(int argc, char *argv[]) { 
    QApplication a(argc, argv); 
    MainWindow w; 
    w.show(); 

    return a.exec(); 
} 
```

这将创建我们在其中实现应用程序的`MainWindow`类的实例，以及`QApplication`的实例，这是 Qt 框架使用的包装器类。

接下来，这是`MainWindow`头:

```cpp
#include <QMainWindow> 

#include <QAudioRecorder> 
#include <QAudioProbe> 
#include <QMediaPlayer> 

namespace Ui { 
    class MainWindow; 
} 

class MainWindow : public QMainWindow { 
    Q_OBJECT 

public: 
    explicit MainWindow(QWidget *parent = nullptr); 
    ~MainWindow(); 

public slots: 
    void playBluetooth(); 
    void stopBluetooth(); 
    void playOnlineStream(); 
    void stopOnlineStream(); 
    void playLocalFile(); 
    void stopLocalFile(); 
    void recordMessage(); 
    void playMessage(); 

    void errorString(QString err); 

    void quit(); 

private: 
    Ui::MainWindow *ui; 

    QMediaPlayer* player; 
    QAudioRecorder* audioRecorder; 
    QAudioProbe* audioProbe; 

    qint64 silence; // Microseconds of silence recorded so far. 

private slots: 
    void processBuffer(QAudioBuffer); 
}; 
```

它的实现包含大多数核心功能，声明音频记录器和播放器实例，仅在单独的类中处理语音命令处理:

```cpp
#include "mainwindow.h" 
#include "ui_mainwindow.h" 

#include "voiceinput.h" 

#include <QThread> 
#include <QMessageBox> 

#include <cmath> 

#define MSG_RECORD_MAX_SILENCE_US 5000000 

MainWindow::MainWindow(QWidget *parent) : QMainWindow(parent), 
    ui(new Ui::MainWindow) { 
    ui->setupUi(this); 

    // Set up menu connections. 
    connect(ui->actionQuit, SIGNAL(triggered()), this, SLOT(quit())); 

    // Set up UI connections. 
    connect(ui->playBluetoothButton, SIGNAL(pressed), this, SLOT(playBluetooth)); 
    connect(ui->stopBluetoothButton, SIGNAL(pressed), this, SLOT(stopBluetooth)); 
    connect(ui->playLocalAudioButton, SIGNAL(pressed), this, SLOT(playLocalFile)); 
    connect(ui->stopLocalAudioButton, SIGNAL(pressed), this, SLOT(stopLocalFile)); 
    connect(ui->playOnlineStreamButton, SIGNAL(pressed), this, SLOT(playOnlineStream)); 
    connect(ui->stopOnlineStreamButton, SIGNAL(pressed), this, SLOT(stopOnlineStream)); 
    connect(ui->recordMessageButton, SIGNAL(pressed), this, SLOT(recordMessage)); 
    connect(ui->playBackMessage, SIGNAL(pressed), this, SLOT(playMessage)); 

    // Defaults 
    silence = 0; 

    // Create the audio interface instances. 
    player = new QMediaPlayer(this); 
    audioRecorder = new QAudioRecorder(this); 
    audioProbe = new QAudioProbe(this); 

    // Configure the audio recorder. 
    QAudioEncoderSettings audioSettings; 
    audioSettings.setCodec("audio/amr"); 
    audioSettings.setQuality(QMultimedia::HighQuality);     
    audioRecorder->setEncodingSettings(audioSettings);     
    audioRecorder->setOutputLocation(QUrl::fromLocalFile("message/last_message.amr")); 

    // Configure audio probe. 
    connect(audioProbe, SIGNAL(audioBufferProbed(QAudioBuffer)), this, SLOT(processBuffer(QAudioBuffer))); 
    audioProbe->setSource(audioRecorder); 

    // Start the voice interface in its own thread and set up the connections. 
    QThread* thread = new QThread; 
    VoiceInput* vi = new VoiceInput(); 
    vi->moveToThread(thread); 
    connect(thread, SIGNAL(started()), vi, SLOT(run())); 
    connect(vi, SIGNAL(finished()), thread, SLOT(quit())); 
    connect(vi, SIGNAL(finished()), vi, SLOT(deleteLater())); 
    connect(thread, SIGNAL(finished()), thread, SLOT(deleteLater())); 

    connect(vi, SIGNAL(error(QString)), this, SLOT(errorString(QString))); 
    connect(vi, SIGNAL(playBluetooth), this, SLOT(playBluetooth)); 
    connect(vi, SIGNAL(stopBluetooth), this, SLOT(stopBluetooth)); 
    connect(vi, SIGNAL(playLocal), this, SLOT(playLocalFile)); 
    connect(vi, SIGNAL(stopLocal), this, SLOT(stopLocalFile)); 
    connect(vi, SIGNAL(playRemote), this, SLOT(playOnlineStream)); 
    connect(vi, SIGNAL(stopRemote), this, SLOT(stopOnlineStream)); 
    connect(vi, SIGNAL(recordMessage), this, SLOT(recordMessage)); 
    connect(vi, SIGNAL(playMessage), this, SLOT(playMessage)); 

    thread->start(); 
} 
```

在构造函数中，我们为 GUI 窗口中的按钮设置了所有 UI 连接，使我们无需使用语音用户界面即可触发应用程序的功能。这对于测试目的是有用的。

此外，我们创建了一个录音机和媒体播放器的实例，以及一个与录音机链接的音频探测器，这样我们就可以查看它正在录制的音频样本并对其进行处理。

最后，我们创建语音输入接口类的实例，并在启动它之前将其推送到自己的线程上。我们将其信号连接到特定命令，并将其他事件连接到各自的插槽:

```cpp
MainWindow::~MainWindow() { 
    delete ui; 
} 

void MainWindow::playBluetooth() { 
    // Use the link with the BlueZ Bluetooth stack in the Linux kernel to 
    // configure it to act as an A2DP sink for smartphones to connect to. 
} 

// --- STOP BLUETOOTH --- 
void MainWindow::stopBluetooth() { 
    // 
} 
```

如蓝牙技术一节所述，由于该节中解释的原因，我们没有实现蓝牙功能。

```cpp
void MainWindow::playOnlineStream() { 
    // Connect to remote streaming service's API and start streaming. 
} 

void MainWindow::stopOnlineStream() { 
    // Stop streaming from remote service. 
} 
```

在线流媒体功能也是如此。有关如何实现此功能的详细信息，请参见本章前面的在线流媒体部分。

```cpp
void MainWindow::playLocalFile() { 
    player->setMedia(QUrl::fromLocalFile("music/coolsong.mp3")); 
    player->setVolume(50); 
    player->play(); 
} 

void MainWindow::stopLocalFile() { 
    player->stop(); 
} 
```

要播放本地文件，我们希望在硬编码路径中找到一个 MP3 文件。然而，这也可以播放特定文件夹中的所有音乐，只需进行一些修改，方法是阅读文件名并逐一播放。

```cpp
void MainWindow::recordMessage() { 
    audioRecorder->record(); 
} 

void MainWindow::playMessage() { 
    player->setMedia(QUrl::fromLocalFile("message/last_message.arm")); 
    player->setVolume(50); 
    player->play(); 
} 
```

在构造函数中，我们将记录器配置为记录到名为`message`的子文件夹中的文件。如果进行了新的录制，则将被覆盖，从而允许留下可以稍后播放的消息。可选的显示器或其他附件可用于指示何时进行了新的录音并且尚未收听:

```cpp
void MainWindow::processBuffer(QAudioBuffer buffer) { 
    const quint16 *data = buffer.constData<quint16>(); 

    // Get RMS of buffer, if silence, add its duration to the counter. 
    int samples = buffer.sampleCount(); 
    double sumsquared = 0; 
    for (int i = 0; i < samples; i++) { 
        sumsquared += data[i] * data[i]; 
    } 

    double rms = sqrt((double(1) / samples)*(sumsquared)); 

    if (rms <= 100) { 
        silence += buffer.duration(); 
    } 

    if (silence >= MSG_RECORD_MAX_SILENCE_US) { 
        silence = 0; 
        audioRecorder->stop(); 
    } 
} 
```

每当录音机处于活动状态时，我们的音频探头都会调用此方法。在此函数中，我们计算音频缓冲区的**均方根** (**RMS**) 值，以确定它是否充满了静音。在这里，静音是相对的，可能必须根据录制环境进行调整。

在检测到五秒钟的沉默后，消息的记录将停止:

```cpp
void MainWindow::errorString(QString err) { 
    QMessageBox::critical(this, tr("Error"), err); 
} 

void MainWindow::quit() { 
    exit(0); 
} 
```

其余方法处理可能在应用程序中的其他地方发出的错误消息的报告，以及终止应用程序。

`VoiceInput`类头定义语音输入接口的功能:

```cpp
#include <QObject> 
#include <QAudioInput> 

extern "C" { 
#include "pocketsphinx.h" 
} 

class VoiceInput : public QObject { 
    Q_OBJECT 

    QAudioInput* audioInput; 
    QIODevice* audioDevice; 
    bool state; 

public: 
    explicit VoiceInput(QObject *parent = nullptr); 
    bool checkState() { return state; } 

signals: 
    void playBluetooth(); 
    void stopBluetooth(); 
    void playLocal(); 
    void stopLocal(); 
    void playRemote(); 
    void stopRemote(); 
    void recordMessage(); 
    void playMessage(); 

    void error(QString err); 

public slots: 
    void run(); 
}; 
```

由于 PocketSphinx 是一个 C 库，因此我们必须确保将其与 C 风格的链接一起使用。除此之外，我们还为语音输入将使用的音频输入和相关 IO 设备创建类成员。

接下来，类定义:

```cpp
#include <QDebug> 
#include <QThread> 

#include "voiceinput.h" 

extern "C" { 
#include <sphinxbase/err.h> 
#include <sphinxbase/ad.h> 
} 

VoiceInput::VoiceInput(QObject *parent) : QObject(parent) { 
    // 
} 
```

构造函数不会做任何特别的事情，因为下一个方法会完成主循环的所有初始化和设置:

```cpp
void VoiceInput::run() { 
    const int32 buffsize = 2048; 
    int16 adbuf[buffsize]; 
    uint8 utt_started, in_speech; 
    uint32 k = 0; 
    char const* hyp; 

    static ps_decoder_t *ps; 

    state = true; 

    QAudioFormat format; 
    format.setSampleRate(16000); 
    format.setChannelCount(1); 
    format.setSampleSize(16); 
    format.setCodec("audio/pcm"); 
    format.setByteOrder(QAudioFormat::LittleEndian); 
    format.setSampleType(QAudioFormat::UnSignedInt); 

    // Check that the audio device supports this format. 
    QAudioDeviceInfo info = QAudioDeviceInfo::defaultInputDevice(); 
    if (!info.isFormatSupported(format)) { 
       qWarning() << "Default format not supported, aborting."; 
       state = false; 
       return; 
    } 

    audioInput = new QAudioInput(format, this); 
    audioInput->setBufferSize(buffsize * 2);    
    audioDevice = audioInput->start(); 

    if (ps_start_utt(ps) < 0) { 
        E_FATAL("Failed to start utterance\n"); 
    } 

    utt_started = FALSE; 
    E_INFO("Ready....\n"); 
```

此方法的第一部分设置音频接口，将其配置为使用音频格式设置进行记录 PocketSphinx 要求: 单声道，小端序，16 位带符号的 PCM 音频，16,000 赫兹。检查音频输入是否支持此格式后，我们创建一个新的音频输入实例:

```cpp
    const char* keyfile = "COMPUTER/3.16227766016838e-13/\n"; 
    if (ps_set_kws(ps, "keyword_search", keyfile) != 0) { 
        return; 
    } 

    if (ps_set_search(ps, "keyword_search") != 0) { 
        return; 
    } 

    const char* gramfile = "grammar asr;\ 
            \ 
            public <rule> = <action> [<preposition>] [<objects>] [<preposition>] [<objects>];\ 
            \ 
            <action> = STOP | PLAY | RECORD;\ 
            \ 
            <objects> = BLUETOOTH | LOCAL | REMOTE | MESSAGE;\ 
            \ 
            <preposition> = FROM | TO;"; 
    ps_set_jsgf_string(ps, "jsgf", gramfile); 
```

接下来，我们设置了关键字-spotting 和 JSGF 语法文件，该文件将在音频样本的处理过程中使用。通过第一个`ps_set_search()`函数调用，我们开始关键字点搜索。以下循环将继续处理样本，直到检测到语音`computer`:

```cpp
    bool kws = true; 
    for (;;) { 
        if ((k = audioDevice->read((char*) &adbuf, 4096))) { 
            E_FATAL("Failed to read audio.\n"); 
        } 

        ps_process_raw(ps, adbuf, k, FALSE, FALSE); 
        in_speech = ps_get_in_speech(ps); 

        if (in_speech && !utt_started) { 
            utt_started = TRUE; 
            E_INFO("Listening...\n"); 
        } 
```

每个周期，我们在另一个缓冲区中读取音频样本，然后让 PocketSphinx 处理这些样本。它还为我们提供静音检测，以确定是否有人开始对着麦克风讲话。如果有人在说话，但我们还没有开始解释它，我们开始一个新的话语:

```cpp
        if (!in_speech && utt_started) { 
            ps_end_utt(ps); 
            hyp = ps_get_hyp(ps, nullptr); 
            if (hyp != nullptr) { 
                // We have a hypothesis. 

                if (kws && strstr(hyp, "computer") != nullptr) { 
                    if (ps_set_search(ps, "jsgf") != 0) { 
                        E_FATAL("ERROR: Cannot switch to jsgf mode.\n"); 
                    } 

                    kws = false; 
                    E_INFO("Switched to jsgf mode \n");                             
                    E_INFO("Mode: %s\n", ps_get_search(ps)); 
                } 
                else if (!kws) { 
                    if (hyp != nullptr) { 
                        // Check each action. 
                        if (strncmp(hyp, "play bluetooth", 14) == 0) { 
                            emit playBluetooth(); 
                        } 
                        else if (strncmp(hyp, "stop bluetooth", 14) == 0) { 
                            emit stopBluetooth(); 
                        } 
                        else if (strncmp(hyp, "play local", 10) == 0) { 
                            emit playLocal(); 
                        } 
                        else if (strncmp(hyp, "stop local", 10) == 0) { 
                            emit stopLocal(); 
                        } 
                        else if (strncmp(hyp, "play remote", 11) == 0) { 
                            emit stopBluetooth(); 
                        } 
                        else if (strncmp(hyp, "stop remote", 11) == 0) { 
                            emit stopBluetooth(); 
                        } 
                        else if (strncmp(hyp, "record message", 14) == 0) { 
                            emit stopBluetooth(); 
                        } 
                        else if (strncmp(hyp, "play message", 12) == 0) { 
                            emit stopBluetooth(); 
                        } 
                    } 
                    else { 
                        if (ps_set_search(ps, "keyword_search") != 0){ 
                            E_FATAL("ERROR: Cannot switch to kws mode.\n"); 
                        } 

                        kws = true; 
                        E_INFO("Switched to kws mode.\n"); 
                    } 
                }                 
            } 

            if (ps_start_utt(ps) < 0) { 
                E_FATAL("Failed to start utterance\n"); 
            } 

            utt_started = FALSE; 
            E_INFO("Ready....\n"); 
        } 

        QThread::msleep(100); 
    } 

} 
```

该方法的其余部分检查我们是否有可以分析的可用假设。根据我们是处于关键字模式还是语法模式，我们检查前一种情况下关键字的检测情况，并切换到语法模式。如果我们已经处于语法模式，我们将尝试将话语范围缩小到特定命令，此时我们将发出相关信号，该信号将触发连接的功能。

每当 PocketSphinx 检测到至少一秒钟的沉默时，就会开始新的发声。执行命令后，系统切换回关键字识别模式。

# 建设项目

要构建项目，必须首先构建 PocketSphinx 项目。在本章附带的示例项目的源代码中，在`sphinx`文件夹下有两个 makefile，一个在`pocketsphinx`文件夹中，一个在`sphinxbase`文件夹中。有了这些，将构建形成 PocketSphinx 的两个库。

之后，可以通过执行以下命令从 Qt Creator 或从命令行构建 Qt 项目:

```cpp
mkdir build
cd build
qmake ..
make
```

# 扩展系统

除了音频格式外，还可以添加播放视频的功能，并集成了拨打和响应电话的功能 (使用蓝牙 API)。人们可能想要扩展应用程序，使其更加灵活和模块化，以便例如，可以添加一个模块，该模块将添加语音命令和结果动作。

拥有语音输出也将很方便，使其与当前的商业产品更加一致。为此，可以使用 Qt 框架中可用的文本到语音 API。

通过查询远程 api，例如当前天气，新闻更新，甚至在当前足球比赛中运行更新，向信息娱乐系统添加更多*信息*也将很有用。基于语音的 UI 可用于设置计时器和任务提醒，集成日历等等。

最后，从本章的示例代码中可以看出，人们无法指定要播放的曲目的名称，也无法指定特定的专辑或艺术家名称。允许这样的自由式输入非常有用，但也有它自己的一系列问题。

主要问题是语音到文本系统的识别率，尤其是对于字典中没有的单词。我们中的一些人可能已经有幸提高了我们的声音，试图让语音驱动的用户界面在电话、汽车或智能手机上理解某个单词。

在这一点上，它仍然是一个很大的研究点，没有一个快速简单的解决方案。可以想象，通过使用本地音频文件名和艺术家的索引以及其他元数据作为字典的一部分，可以蛮力进行这种识别，并获得更好的准确性。对于远程流服务，可以通过查询其 API 来完成相同的操作。然而，这可能会增加识别工作的相当大的延迟。

# 摘要

在本章中，我们研究了如何使用语音到文本来构建语音驱动的用户界面，从而可以相当轻松地构建基于 SBC 的信息娱乐系统。我们还研究了可以扩展它以添加更多功能的方法。

读者有望在这一点上实现类似的系统，并将其扩展以将其连接到在线和基于网络的服务。读者还应阅读更高级的语音驱动用户界面的实现，文本到语音的添加以及 A2DP-based 蓝牙设备的使用。

在下一章中，我们将介绍如何使用微控制器和本地网络实现建筑物范围的监视和控制系统。