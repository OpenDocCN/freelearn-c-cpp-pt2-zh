# 第 11-13 章 6.低电平音频

我们现在已经读到这本书的最后一章了。 到目前为止，我们已经使用低级和高级音频引擎处理了许多不同复杂和抽象级别的音频。 这些音频引擎为开发人员提供了无价的帮助，我们绝对应该在任何可能的情况下使用它们。 在他们的帮助下，我们加载和播放了音频文件，学习了如何控制声音参数，在 3D 环境中模拟声音，并创建了复杂的、多层次的交互式声音。

然而，在本章中，我们将假装这些音频引擎并不存在，只处理计算机中代表声音的位和字节。 然后，我们将以简化的形式重新实现 FMOD 为我们提供的许多功能。 我们还将简要介绍声音合成，它是使用数学公式而不是依靠录制的音频来产生声音的行为。

本章的目的是加深我们对声音工作原理的理解，并深入了解音频引擎为我们实现的许多功能。 对于那些希望在游戏中实现复杂音频功能的人来说，它也应该是一个起点。

# 表示音频数据

在[第一章](1.html "Chapter 1. Audio Concepts")，*音频概念*中，我们讨论了数字音频理论中最重要的概念。 特别是，我们看到一个简单的数字数组就可以表示音频信号，并讨论了 PCM、采样率、位深度和多声道音频等主题。

在本章中，我们将把所有这些概念付诸实践，因此在继续之前，请确保您理解这些概念。 首先，让我们从理论和代码两个方面来研究音频数据的意义。

音频数据只不过是一个数字序列，代表偶数时间间隔的声波振幅。 但是，在计算机上表示数字的方法有很多种，这取决于用于表示它们的内存量、它们是否应该能够存储负数，以及这些数字是整数还是浮点数。 这些差异导致 C++ 提供多种数据类型来存储数字，如`int`、`short`、`float`和`double`。 因此，根据所选的数据类型，音频数据也可以以多种格式存储。

在本章中，我们将仅介绍最常见的音频格式，即带符号的 16 位线性 PCM 格式。 在此格式中，每个样本都是一个 16 位带符号整数(C++ 中的 a`signed short`)，范围从-32768(最小幅度)到 32767(最大幅度)。 为了在处理 PCM 样本和其他数量时简化表示法，我们将使用以下别名：

```cpp
typedef signed short PCM16;
typedef unsigned int U32;
typedef unsigned short U16;
```

在决定使用哪种格式之后，我们需要创建一个数组来保存所有音频样本。 根据以下公式，数组的大小直接取决于我们要存储的声音的采样率、其持续时间(以秒为单位)和正在使用的声道数：

```cpp
count = sampling rate * duration * channels
```

例如，假设采样率为 44100 Hz，我们可以创建一个数组来恰好存储 1 秒的单声道音频数据，如下所示：

```cpp
// 1 second of audio data at 44100 Hz (Mono)
// count = 44100 Hz * 1 second * 1 channel
PCM16 data[44100];
```

如果我们想存储立体声信号，我们需要存储两倍数量的信息(同样的想法也适用于更高数量的频道)。 请记住，表示立体声音频数据的最常见方式是在同一数组中交错左采样和右采样：

```cpp
// 1 second of audio data at 44100 Hz (Stereo)
// data[0] = left, data[1] = right, data[2] = left, etc.
// count = 44100 Hz * 1 second * 2 channels
PCM16 data[88200];
```

# 播放音频数据

我们需要一种方法将音频数据提交到声卡，这样我们就可以听到产生的声音。 我们可以使用非常低级的音频 API，例如 PortAudio，它提供与音频设备通信所需的最低限度的功能。 但是，FMOD也完全能够处理这项任务，而且由于我们到目前为止一直在使用它，现在更改为不同的 API 几乎没有什么好处。 因此，我们将再次使用 FMOD，但仅用作应用程序和硬件之间的桥梁，我们的代码将处理所有处理。

FMOD 允许我们播放用户创建的音频数据的方式是，首先使用`FMOD_OPENUSER`标志创建一个声音，然后指定一个回调函数，该回调函数将向该声音提供音频数据。

我们必须创建并填充一个`FMOD_CREATESOUNDEXINFO`结构，其中包含有关我们将提交的音频数据的一些详细信息，例如采样率、格式和声道数，以及指向将提供数据本身的函数的指针。

对于我们所有的示例，我们将使用 44100 Hz 的采样率，使用 16 位 PCM 格式，并且有两个声道(立体声)。 有关每个属性的更多信息，请阅读备注：

```cpp
// Create and initialize a sound info structure
FMOD_CREATESOUNDEXINFO info;
memset(&info, 0, sizeof(FMOD_CREATESOUNDEXINFO));
info.cbsize = sizeof(FMOD_CREATESOUNDEXINFO);

// Specify sampling rate, format, and number of channels to use
// In this case, 44100 Hz, signed 16-bit PCM, Stereo
info.defaultfrequency = 44100;
info.format = FMOD_SOUND_FORMAT_PCM16;
info.numchannels = 2;

// Size of the entire sound in bytes. Since the sound will be
// looping, it does not need to be too long. In this example
// we will be using the equivalent of a 5 seconds sound.
// i.e. sampleRate * channels * bytesPerSample * durationInSeconds
info.length = 44100 * 2 * sizeof(signed short) * 5;

// Number of samples we will be submitting at a time
// A smaller value results in less latency between operations
// but if it is too small we get problems in the sound
// In this case we will aim for a latency of 100ms
// i.e. sampleRate * durationInSeconds = 44100 * 0.1 = 4410
info.decodebuffersize = 4410;

// Specify the callback function that will provide the audio data
info.pcmreadcallback = WriteSoundData;
```

接下来，我们创建一个循环的流式声音，指定`FMOD_OPENUSER`模式，并将声音信息结构传递给`createStream()`的第三个参数。 然后我们可以像往常一样开始播放声音：

```cpp
// Create a looping stream with FMOD_OPENUSER and the info we filled 
FMOD::Sound* sound;
FMOD_MODE mode = FMOD_LOOP_NORMAL | FMOD_OPENUSER;
system->createStream(0, mode, &info, &sound);
system->playSound(FMOD_CHANNEL_FREE, sound, false, 0);
```

只要播放声音，音频引擎就会定期调用我们的回调函数来获取所需的数据。 回调函数必须遵循带有三个参数的特定签名，即对我们创建的声音对象的引用、要写入音频数据的数组以及应该写入数据数组的总字节数。 它还应该在末尾返回`FMOD_OK`。

数据数组由指向 void(`void*`)的指针定义，因为正如我们前面讨论的那样，数据有许多不同的格式。 将数据数组转换为正确的格式取决于我们。 因为我们使用`FMOD_SOUND_FORMAT_PCM16`创建声音，所以我们必须首先将数据数组转换为`signed short*`。

另一个重要的细节是，`length`参数指定要写入`bytes`中数组的数据量，但是我们的每个样本都是一个`signed short`，每个样本占用 2 个字节。 因此，我们应该确保写入数据数组的样本不超过`length/2`个。

下面是一个回调函数的示例，它通过用零填充整个音频缓冲区来输出静音。 不是很有趣，但它应该是一个很好的起点：

```cpp
FMOD_RESULT F_CALLBACK
WriteSoundData(FMOD_SOUND* sound, void* data, unsigned int length) {
  // Cast data pointer to the appropriate format (in this case PCM16)
  PCM16* pcmData = (PCM16*)data;

  // Calculate how many samples can fit in the data array
  // In this case, since each sample has 2 bytes, we divide
  // length by 2
  int pcmDataCount = length / 2;

  // Output 0 in every sample
  for(int i = 0; i < pcmDataCount; ++ i) {
    pcmData[i] = 0;
  }

  return FMOD_OK;
}
```

# 加载声音

获取音频数据最常见的方式是从音频文件中读取。 然而，正如我们以前看到的，有许多不同的音频文件格式，从其中读取音频数据通常不是一件简单的任务。 对于压缩音频文件格式尤其如此，它需要使用某种算法对音频数据进行解码，然后才能在我们的应用程序中使用它。 通常，使用音频引擎或外部库来读取音频文件的内容通常更好。

出于教育目的，我们将从 WAV 文件中读取音频数据。 但是，我们将假设我们读取的 wav 文件是规范格式(即，它只包含一个格式和一个数据子块，按照这个顺序)，并且音频数据是在没有任何压缩的情况下存储的。 在这些情况下，我们知道所有数据存储在哪里，并且可以简单地索引到文件中来读取它。 当然不是每个 wav 文件都是这种情况，因为它需要更复杂的加载序列。

WAV 文件格式建立在更通用的 RIFF 文件格式之上。 RIFF 文件被分成多个数据块。 每个块都以 4 个字符的 ASCII 标识符和描述块中存储了多少数据的 32 位整数开头。 接下来是块的实际数据，它根据块的类型而有所不同。

所有 WAV 文件至少包含以下三个块(其中两个块被视为第一个块的子块)：

*   包含字符串的**RIFF**块：WAVE
*   包含关于音频文件的信息的**格式**子块[T2
*   包含实际音频数据的**数据**子块[T2

下图显示了规范格式的 WAV 文件的内容。 请注意，如果文件包含压缩数据，则格式子区块可以包含比下图所示更多的数据。 其他块也可能出现在文件中，或者以不同的顺序出现：

![Loading a sound](img/9099OT_06_01.jpg)

现在我们已经有了一个表，其中列出了规范 WAV 文件的内容，现在让我们创建一个类来加载和存储文件中我们关心的所有信息(即采样率、位深度、通道数和音频数据)。

为了与我们之前在 FMOD 中使用的保持一致，我们将这个类命名为`MySound`。 为简单起见，类的每个成员都具有公共可访问性，尽管我们可以提供一些访问器方法，同时将数据设置为私有的：

```cpp
class MySound {
 public:
  MySound(const char* path);
  ~MySound();

  U32 samplingRate;
  U16 numChannels;
  U16 bitsPerSample;
  PCM16* data;
  U32 count;
};
```

在构造函数上，我们打开音频文件并将所有相关数据读入成员变量。 请注意，任何地方都不会进行错误检查，并且这只会在前面描述的条件下起作用：

```cpp
#include <iostream>
#include <fstream>

MySound::MySound(const char* path) {
  // Open file stream for input as binary
  std::ifstream file(path, std::ios::in | std::ios::binary);

  // Read number of channels and sample rate
  file.seekg(22);
  file.read((char*)&numChannels, 2);
  file.read((char*)&samplingRate, 4);

  // Read bits per sample
  file.seekg(34);
  file.read((char*)&bitsPerSample, 2);

  // Read size of data in bytes
  U32 length;
  file.seekg(40);
  file.read((char*)&length, 4);

  // Allocate array to hold all the data as PCM samples
  count = length / 2;
  data = new PCM16[count];

  // Read PCM data
  file.read((char*)data, length);
}
```

析构函数负责清理构造函数中分配的用于保存音频数据的内存：

```cpp
MySound::~MySound() {
  delete[] data;
}
```

# 播放声音

既然我们已经将个音频数据存储在内存中，我们就可以开始播放声音了。 为此，我们必须获取存储在数据数组中的每个值，并按顺序将它们发送到声卡(在我们的示例中，使用前面创建的回调方法)。

如果音频数据中的格式、采样率和通道数与输出相同，则此过程非常简单，只需将值从一个数组复制到另一个数组。 但是，如果它们有任何不同，特别是：

*   如果音频数据的采样率与输出的采样率不同，我们需要重新采样数据，使其与输出的采样率匹配，否则声音将以不同于我们预期的速率播放。 这个操作不是微不足道的，并且超出了本章的范围。
*   如果我们的音频数据与输出格式不同，我们需要首先将数据转换为新格式。 例如，我们可能需要将 32 位浮点样本转换为带符号的 16 位整数样本。 这并不复杂，主要需要将数字从一个范围扩展到另一个范围。
*   如果我们的音频数据具有与输出不同的声道数，我们必须使信号适应新的声道数。 将单声道信号调整为立体声很容易，因为我们只需要将数据的副本发送到两个声道。 将立体声信号调整为单声道通常需要将两个声道的值相加，然后将结果除以 2。

为了保持示例的简单性，我们假设音频数据具有非常特定的格式，因此不需要进行转换：

*   其采样率为 44100 Hz，与输出相同
*   它以 PCM16 音频格式存储，与输出相同
*   它只有一个通道(单声道)数据，尽管输出有两个通道(立体声)，因此我们可以看到一个如何实现平移的示例

在这些情况下，我们只需要两件事来播放声音，我们需要能够访问音频数据，并且我们需要一个变量来跟踪声音中的当前位置(即，我们到目前为止已经写入了多少样本)，以便我们知道下一步要写入哪个样本。 一旦位置大于数据中的样本数，就意味着声音已经播放完毕，我们中断这个过程。

就像我们对 Sound 类所做的那样，让我们还创建一个类来封装与播放声音相关的所有数据和行为，我们将其命名为`MyChannel`：

```cpp
class MyChannel {
 public:
  MyChannel() : sound(0), position(0) {}
  void Play(MySound* mySound);
  void Stop();
  void WriteSoundData(PCM16* data, int count);

 private:
  MySound* sound;
  int position;
};
```

与 FMOD 中的通道一样，我们应该能够为不同的声音重用单个通道对象。 因此，我们只在`Play()`方法内部分配声音对象，而不是在构造函数中获取声音对象。 此方法还会重置位置值：

```cpp
void MyChannel::Play(MySound* mySound) {
  sound = mySound;
  position = 0;
}
```

另一方面，`Stop()`方法只清除对声音对象的引用：

```cpp
void MyChannel::Stop() {
  sound = 0;
}
```

最后，流程中最重要的部分发生在`WriteSoundData()`方法中，该方法将从音频回调中调用。 此方法接受两个参数，要写入的 PCM 样本数组和此数组的大小。 请注意，此方法已经期望`data`数组采用正确的格式，而不是提供给音频回调的`void*`。 `count`还指数组中的样本数，而不是字节数。 代码中有一些注释解释了每行执行的操作：

```cpp
void MyChannel::WriteSoundData(PCM16* data, int count) {
  // If there is no sound assigned to the channel do nothing  
  if(sound == 0) return;

  // We need to write "count" samples to the "data" array
  // Since output is stereo it is easier to advance in pairs
  for (int i = 0; i < count; i += 2) {

    // If we have reached the end of the sound, stop and return
    if(position >= sound->count) {
      Stop();
      return;
    }

    // Read value from the sound data at the current position
    PCM16 value = sound->data[position];

    // Write value to both the left and right channels
    data[i] = value;
    data[i+1] = value;

    // Advance the position by one sample
    ++ position;
  }
}
```

使用这个类，我们的音频回调变得简单得多，因为我们可以将大部分工作委托给通道的`WriteSoundData()`方法。 在下面的示例中有一个通道对象，因此我们一次只能播放一个声音，但稍后我们将看到添加对多个声音以及其他几个功能的支持是多么容易：

```cpp
MyChannel channel;

FMOD_RESULT F_CALLBACK 
WriteSoundData(FMOD_SOUND *sound, void *data, unsigned int length) {
  // Clear output
  memset(data, 0, length);

  // Get data in the correct format and calculate sample count
  PCM16* pcmData = (PCM16*)data;
  int pcmDataCount = length / 2;

  // Tell the channel to write to the output
  channel.WriteSoundData(pcmData, pcmDataCount);

  return FMOD_OK;
}
```

请注意，在前面的示例中，我们首先使用`memset`清除音频缓冲区。 这是必要的，因为一旦声音停止播放，我们就不会用值填充输出，而且 FMOD 不会在回调调用之间自动清除缓冲区。

使用此体系结构播放声音非常简单，只需实例化声音，然后请求通道对象播放它：

```cpp
MySound* sound = new MySound("explosion.wav");
channel.Play(sound);
```

# 暂停声音

现在我们已经具备了播放使用`MySound`和`MyChannel`类实现的声音的基本功能，我们可以开始向其添加更多功能。 我们将从最简单的开始，暂停声音。

我们必须添加一个成员变量来保存暂停状态，并添加一些方法来修改它。 我们还必须记住在构造函数内和`Play()`方法内将该值初始化为`false`：

```cpp
public:
  bool GetPaused() const { return paused; }
  void SetPaused(bool value) { paused = value }
private:
  bool paused;
```

接下来，我们要做的就是在`WriteSoundData()`方法的开头添加一个非常简单的条件，这样当声音暂停时它就不会执行任何操作。 这就是最简单的办法了！

```cpp
void MyChannel::WriteSoundData(PCM16* data, int count) {
  if(sound == 0 || paused) return;
  for (int i = 0; i < count; i += 2) {
    if(position >= sound->count) {
      Stop();
      return;
    }
    PCM16 value = sound->data[position];
    data[i] = value;
    data[i+1] = value;
    ++ position;
  }
}    
```

# 循环发声

我们将实现的下一个功能是无休止地进行声音循环的能力。 就像暂停声音的能力一样，这一功能的实现也相当简单。 我们首先重复我们为暂停所做的一切，但不是为了循环：

```cpp
public:
  bool GetLoop() const { return loop; }
  void SetLoop(bool value) { loop = value }
private:
  bool loop;
```

在`WriteSoundData()`方法中，在我们用来检测声音是否已经到达末尾的部分，我们首先检查循环变量是否设置为`true`，如果是这样，我们将位置设置回开头，而不是停止声音：

```cpp
void MyChannel::WriteSoundData(PCM16* data, int count) {
  if(sound == 0 || paused) return;
  for (int i = 0; i < count; i += 2) {
    if(position >= sound->count) {
      if(loop) {
        position = 0;
      } else {
        Stop();
        return;
      }
    }
    PCM16 value = sound->data[position];
    data[i] = value;
    data[i+1] = value;
    ++ position;
  }
}
```

# 更改音量

我们将实现的接下来的几个功能涉及修改发送到输出的值。 改变声音的音量可能是其中最简单的，因为它只需要乘法。

让我们从创建一个变量和一些控制音量的方法开始。 音量将存储为介于 0(静音)和 1(满音量)之间的浮点数。 `SetVolume()`方法确保该值始终在此范围内。 我们还应在开始播放声音时将音量重置为 1：

```cpp
public:
  float GetVolume() const { return volume; }
  void SetVolume(float value) {
    if(value < 0.0f) volume = 0.0f;
    else if(value > 1.0f) volume = 1.0f;
    else volume = value;
  }
private:
  float volume;
```

为了以这个音量播放声音，我们需要做的就是将音频数据中的每个原始值乘以音量变量的值，然后再将它们写入输出。 因为体积变量是浮点数，所以我们需要在乘法之后将结果强制转换回 PCM16：

```cpp
void MyChannel::WriteSoundData(PCM16* data, int count) {
  if(sound == 0 || paused) return;
  for (int i = 0; i < count; i += 2) {
    if(position >= sound->count) {
      if(loop) {
        position = 0;
      } else {
        Stop();
        return;
      }
    }
    PCM16 value = (PCM16)(sound->data[position] * volume);
    data[i] = value;
    data[i+1] = value;
    ++ position;
  }
}
```

# 改变间距

改变声音的音高比改变音量稍微复杂一些。 修改声音音调的最基本方法(尽管声音的速度也会受到影响)是控制推进位置值的速度。

到目前为止，我们已经使用了一个整数`position`变量，并且每次都将其值递增一整单位。 为了提供间距控制，我们将该变量更改为浮点数，并添加一个`pitch`变量来确定位置的增量。

默认情况下，`pitch`变量的值为 1，表示以正常音调播放声音。 值为 2 将使声音的频率加倍，使声音听起来高一个八度，值为 0.5 将使声音的频率减半，使声音低一个八度。 出于实际原因，我们将其值限制在 0.25(比原始声音低两个八度)到 4(比原始声音高两个八度)之间：

```cpp
public:
  float GetPitch() const { return pitch; }
  void SetPitch(float value) {
    if(value < 0.25f) pitch = 0.25f;
    else if(value > 4.0f) pitch = 4.0f;
    else pitch = value;
  }
private:
  float position;
  float pitch;
```

在我们的`WriteSoundData()`方法中，我们将位置变量递增间距。 该过程中最困难的部分是如何将现在是浮点数的`position`变量转换回数组索引。 最简单的解决方案是使用简单强制转换，它将值截断为整数，这就是我们将使用的：

```cpp
void MyChannel::WriteSoundData(PCM16* data, int count) {
  if(sound == 0 || paused) return;
  for (int i = 0; i < count; i += 2) {
    if(position >= sound->count) {
      if(loop) {
        position = 0;
      } else {
        Stop();
        return;
      }
    }
    PCM16 value = (PCM16)(sound->data[(int)position] * volume);
    data[i] = value;
    data[i+1] = value;
    position += pitch;
  }
} 
```

然而，从投射中截断可能会给信号带来失真。 例如，如果位置以比正常速度慢的速度前进，它将有许多介于整数之间的值，但由于强制转换的截断，我们将获得多次写入输出的相同值，而不是流动的声波。

一种更好的方法是使用线性插值(或其他类型的插值)来计算样本的值，该值将周围的值和位置的小数部分考虑在内。 例如，使用线性插值，如果位置是 2.25，我们将输出`data[2]`值的 75%和`data[3]`值的 25%的混合，而不是输出`data[2]`的值。

# 更改平移

有许多不同的方法来实现声音的立体声平移。 在本节中，我们将介绍一种简单的方法，该方法只需单独修改左声道和右声道的音量即可。

在实际执行任何计算之前，让我们通过添加两个私有变量`leftGain`和`rightGain`来存储每个通道的音量，从而为类的平移做好准备：

```cpp
private:
  float leftGain;
  float rightGain;
```

然后，在`WriteSoundData()`方法中，我们可以在将数据写入输出之前将这些增益应用于数据，就像我们之前对卷所做的那样。 当然，我们应该只将`leftGain`和`rightGain`的值应用于它们各自的通道。 此外，由于我们需要在应用增益后强制转换为 PCM16，因此无需保留先前的强制转换：

```cpp
void MyChannel::WriteSoundData(PCM16* data, int count) {
  if(sound == 0 || paused) return;
  for (int i = 0; i < count; i += 2) {
    if(position >= sound->count) {
      if(loop) {
        position = 0;
      } else {
        Stop();
        return;
      }
    }
    float value = sound->data[(int)position] * volume;
    data[i] = (PCM16)(value * leftGain);
    data[i+1] = (PCM16)(value * rightGain);
    position += pitch;
  }
}
```

有了这些，我们现在需要创建一个名为`pan`的浮点变量和一些修改它的方法。 `pan`变量的值应该介于-1(全左)和 1(全右)之间。 每当`pan`的值更改时，我们调用私有`UpdatePan()`方法来计算`leftGain`和`rightGain`的新值：

```cpp
public:
  float GetPan() const { return pan; }
  void SetPan(float value) {
    if(value < -1.0f) pan = -1.0f;
    else if(value > 1.0f) pan = 1.0f;
    else pan = value;
    UpdatePan();
  }
private:
  void UpdatePan();
  float pan;
```

剩下的就是编写`UpdatePan()`方法。 有几个不同的公式可以计算立体声平移的增益值。 最简单的方法之一是使用线性平移，每个通道从一侧的 0%音量开始，在另一侧线性增加到 100%，而在中间的音量为 50%。 以下是线性平移的实现：

```cpp
// Linear panning
void MyChannel::UpdatePan() {
  float position = pan * 0.5f;
  leftGain = 0.5f - position;
  rightGain = position + 0.5f;
}
```

另一种方法通常在平移时产生更平滑的过渡，它是使用**恒定功率平移**，其中每个通道的音量遵循圆形曲线，每个通道的音量大约在中间的 71%。 我们以前已经讨论过恒功率平移，因为它是 FMOD 用来平移单声道声音的平移类型。 以下是恒定功率平移的一个实现，无需详细说明所涉及的数学运算：

```cpp
#include <math.h>

#define PI_4 0.78539816339      // PI/4
#define SQRT2_2 0.70710678118   // SQRT(2)/2

// Constant-power panning
void MyChannel::UpdatePan() {
  double angle = pan * PI_4;
  leftGain = (float)(SQRT2_2 * (cos(angle) - sin(angle)));
  rightGain = (float)(SQRT2_2 * (cos(angle) + sin(angle)));
}
```

# 混合多种声音

到目前为止，我们一次只播放一种声音，但是要扩展我们正在做的同时播放多个声音是相当容易的。 将多个声音组合成单个输出的行为称为**音频混合**，它可以通过将所有音频信号相加并将结果钳制到可用范围来实现。 查看我们的`WriteSoundData()`方法，我们所需要做的就是更改写入数据数组的代码行，以便将样本添加到现有值中，而不是完全替换它们：

```cpp
void MyChannel::WriteSoundData(PCM16* data, int count) {
  if(sound == 0 || paused) return;
  for (int i = 0; i < count; i += 2) {
    if(position >= sound->count) {
      if(loop) {
        position = 0;
      } else {
        Stop();
        return;
      }
    }
    float value = sound->data[(int)position] * volume;
    data[i] = (PCM16)(value * leftGain + data[i]);
    data[i+1] = (PCM16)(value * rightGain + data[i+1]);
    position += pitch;
  }
}  
```

在我们的主应用程序中，我们现在可以创建多个实例，并在所有实例上调用`WriteSoundData()`，而不是只有一个通道实例：

```cpp
std::vector<MyChannel> channels;

FMOD_RESULT F_CALLBACK 
WriteSoundData(FMOD_SOUND *sound, void *data, unsigned int length) {
  // Clear output
  memset(data, 0, length);

  // Get data in the correct format and calculate sample count
  PCM16* pcmData = (PCM16*)data;
  int pcmDataCount = length / 2;

  // Tell every channel to write to the output
  for(int i = 0; i < channels.size(); ++ i)
    channels[i].WriteSoundData(pcmData, pcmDataCount);

  return FMOD_OK;
}
```

# 实现延迟效果

我们已经在[第 4 章](4.html "Chapter 4. 3D Audio")、*3D Audio*中讨论过，DSP Effects是修改音频数据以实现特定目标的算法。 现在我们将看到一个如何实现简单延迟效果的示例。 基本延迟效果的工作方式是保留单独的数据缓冲区，并存储已在其中播放的音频数据。 缓冲区的大小决定了原始声音和回声播放之间需要多长时间。 然后，我们只需要将正在播放的音频数据与存储在缓冲区中的旧信号的一部分混合在一起，这就会产生延迟。 让我们来看一下下面的`MyDelay`类定义，它封装了该效果：

```cpp
class MyDelay {
public:
  MyDelay(float time, float decay);
  ~MyDelay();
  void WriteSoundData(PCM16* data, int count);

private:
  PCM16* buffer;
  int size;
  int position;
  float decay;
};
```

`MyDelay`类构造函数接受两个参数`time`和`decay`。 第一个参数控制声音和第一次回声之间所需的秒数。 第二个参数控制每次回声过程中损失的能量。

该类存储 PCM16 样本的缓冲区，我们在构造函数中对其进行初始化，以便它可以以 44100 Hz 的采样率存储相当于`time`秒的数据。 此缓冲区开始时完全用零填充。 它还包含将用于在缓冲区中循环的`position`变量：

```cpp
MyDelay::MyDelay(float time, float decay) : position(0), decay(decay)
{
  size = (int)(time * 44100);
  buffer = new PCM16[size];
  memset(buffer, 0, size * 2);
}
```

析构函数删除构造函数中分配的所有数据：

```cpp
MyDelay::~MyDelay() {
  delete[] buffer;
}
```

最后，`WriteSoundData()`方法完成所有工作。 它首先获取输出中的每个样本，并将其与存储在缓冲器中当前位置处的样本的一部分混合。 接下来，我们获取这个个新值，并将其写回输出和缓冲区。 最后，我们将 Position 变量递增到下一个样本，绕过缓冲区的末尾：

```cpp
void MyDelay::WriteSoundData(PCM16* data, int count) {
  for (int i = 0; i < count; ++ i) {
    // Mix sample with the one stored in the buffer at position
    data[i] = (PCM16)(data[i] + buffer[position] * decay);

    // Record this new value in the buffer at position
    buffer[position] = data[i];

    // Increment buffer position wrapping around
    ++ position;
    if(position >= size)
      position = 0;
  }
}
```

要测试这个效果，只需在主应用程序中创建一个它的实例，然后在音频回调结束时调用`WriteSoundData()`方法：

```cpp
// When the application starts
MyDelay* delay = new MyDelay(1.0f, 0.50f);

// Inside the audio callback
for(int i = 0; i < channels.size(); ++ i)
  channels[i].WriteSoundData(pcmData, pcmDataCount);
delay->WriteSoundData(pcmData, pcmDataCount);
```

# 合成声音

在我们结束本章之前，同样值得注意的是，并不是每个声音都需要来自音频文件。 也可以仅使用数学公式从头开始生成声音。 我们称这个过程为过程，**声音合成**，就是关于这个主题的整本书。

某些声波在声音合成中特别常见，因为它们很容易计算。 我们以前已经讨论过其中的一种声波，即正弦波。 其他常见的示例有方波、锯齿波和三角波，所有这些都如下图所示：

![Synthesizing a sound](img/9099OT_06_02.jpg)

现在，我们将通过创建一个类`MyOscillator`来了解如何合成这些声波中的每一个。 该类的用例与前面描述的`MyDelay`类基本相同；只需创建它的一个实例，并从音频回调调用`WriteSoundData()`方法使其播放即可：

```cpp
#include <math.h>
#define PI 3.14159265359
#define TWO_PI 6.28318530718

class MyOscillator {
 public:
  MyOscillator();
  void SetVolume(double value) { volume = value; }  
  void SetFrequency(double frequency);
  void WriteSoundData(PCM16* data, int count);

 private:
  double phase;
  double increment;
  double volume;
};
```

该类包含三个成员变量`phase`，它描述我们沿着声波走了多远，`increment`，它取决于声音的频率，并描述我们应该将每个样本之间的相位推进多少，以及`volume`，它可以通过`SetVolume()`方法改变。 请注意，我们对所有内容都使用双精度，而不是浮点数，因为声音合成在计算中往往需要更高的精度。

类构造函数所做的全部工作就是将相位初始化为 0，将音量初始化为 1，并通过使用默认值 440 Hz 调用`SetFrequency()`来设置增量：

```cpp
MyOscillator::MyOscillator() : phase(0.0), volume(0.5) {
  SetFrequency(440.0);
}
```

`SetFrequency()`方法使用以下公式计算正确的增量值。 在本例中，我们将采样率硬编码为 44100 Hz，但可能有一个参数来控制采样率：

```cpp
void MyOscillator::SetFrequency(double frequency) {
  increment = frequency / 44100.0 * TWO_PI;
}
```

像往常一样，大部分工作都在`WriteSoundData()`方法中处理。 首先，我们计算当前相位的声波的值，并将其缩放到 PCM16 样本的正确范围内(乘以 32767，这是可以存储在有符号短片中的最大数字)。 接下来，我们将此结果写入音频输出，将其与已有的任何内容混合在一起。 最后，我们递增相位，并对其进行换行，使其始终保持在 0 到 2 PI 范围内：

```cpp
void WriteSoundData(PCM16* data, int count) {
  for(int i = 0; i < count; i += 2) {
    // Calculate sample value
    double value = sine_wave(phase) * 32767.0 * volume;

    // Mix sample with output
    data[i] = (PCM16)(data[i] + value);
    data[i+1] = (PCM16)(data[i+1] + value);

    // Increment phase
    phase += increment;

    // Wrap phase to the 0-2PI range
    if(phase >= TWO_PI)
      phase -= TWO_PI;
  }
}
```

实际的音频数据是由前面代码中突出显示的`sine_wave()`方法生成的。 此方法所做的全部工作就是对相位值调用标准`sin()`函数并返回结果。 根据我们要播放的声波类型，我们可以很容易地将此方法与以下任一实现互换：

```cpp
double sine_wave(double phase) {
  return sin(phase);
}

double square_wave(double phase) {
  return phase <= PI ? 1.0 : -1.0;
}

double downward_sawtooth_wave(double phase) {
  return 1.0 - 2.0 * (phase / TWO_PI);
}
double upward_sawtooth_wave(double phase) {
  return 2.0 * (phase / TWO_PI) - 1.0;
}

double triangle_wave(double phase) {
  double result = upward_sawtooth_wave(phase);
  if(result < 0.0)
    result = -result;
  return 2.0 * (result - 0.5);
}
```

# 摘要

在本章中，我们了解了如何直接处理音频数据的位和字节，如何从规范的 wav 文件加载音频数据，如何仅使用低级操作播放和控制音频数据，如何实现简单的延迟效果，以及如何合成一些基本的声波。