# *第 10 章*：JIT 编译

LLVM 核心库附带了**ExecutionEngine**组件，该组件允许在内存中编译和执行 IR 代码。 使用该组件，我们可以及时构建**(**JIT**)编译器，从而允许直接执行 IR 代码。 JIT 编译器的工作方式更像是解释器，因为不需要将目标代码存储在辅助存储上。**

在本章中，您将了解 JIT 编译器的应用，以及 LLVM JIT 编译器的工作原理。 您将学习 LLVM 动态编译器和解释器，还将学习如何自己实现 JIT 编译器工具。 您还将了解如何将 JIT 编译器用作静态编译器的一部分，以及与之相关的挑战。

本章将介绍以下主题：

*   了解 LLVM 的 JIT 实现和用例概述
*   使用 JIT 编译进行直接执行
*   利用 JIT 编译器进行代码评估

在本章结束时，您将了解如何使用预配置的类或适合您需要的自定义版本来开发 JIT 编译器。 您还将获得在传统静态编译器中使用 JIT 编译器的知识。

# 技术要求

本章的代码文件位于[https://github.com/PacktPublishing/Learn-LLVM-12/tree/master/Chapter10](https://github.com/PacktPublishing/Learn-LLVM-12/tree/master/Chapter10)

您可以在[https://bit.ly/3nllhED](https://bit.ly/3nllhED)上找到动作视频中的代码。

# 了解 LLVM 的 JIT 实现和用例概述

到目前为止，我们只研究了提前(**AOT**)的**编译器。 这些编译器编译整个应用。 只有编译完成后，应用才能运行。 如果编译是在应用运行时执行的，则编译器是 JIT 编译器。 JIT 编译器有一些有趣的用例：**

*   **虚拟机的实现**：使用 AOT 编译器可以将编程语言转换为字节码。 在运行时，使用 JIT 编译器将字节代码编译成机器码。 这种方法的优点是字节码是独立于硬件的，多亏了 JIT 编译器，与 AOT 编译器相比没有性能损失。 今天，Java 和 C#都在使用这种模型，但是这个想法非常古老：1977 年的 USCD Pascal 编译器已经使用了类似的方法。
*   **表达式求值**：电子表格应用可以使用JIT 编译器编译经常执行的表达式。 例如，这可以加快金融模拟的速度。 LLVM 调试器 LLDB 使用该方法在调试时计算源表达式。
*   **数据库查询**：数据库从数据库查询创建执行计划。 执行计划描述了对表和列的操作，这些操作在执行时会导致查询答案。 可以使用 JIT 编译器将执行计划转换为机器码，从而加快查询的执行速度。

LLVM 的静态编译模型并不像您想象的那样远离 JIT 模型。 LLVM 静态编译器`llc`将 LLVM IR 编译成机器码，并将结果作为目标文件保存在磁盘上。 如果目标文件不是存储在磁盘上，而是存储在内存中，代码会是可执行的吗？ 不是直接的，因为对全局函数和全局数据的引用使用重新定位而不是绝对地址。

从概念上讲，重定位描述了如何计算地址，例如，作为对已知地址的偏移量。 如果我们像链接器和动态加载器那样将重新定位解析为地址，那么我们就可以执行目标代码。 运行静态编译器以将 IR 代码编译为内存中的目标文件，对内存中的目标文件执行链接步骤，然后运行代码将生成 JIT 编译器。 LLVM 核心库中的 JIT 实现就是基于这一思想的。

在 LLVM 的发展历史中，有几个 JIT 实现，具有不同的特性集。 最新的JIT API 是**on Request 编译**(**ORC**)引擎。 如果您想知道缩写：在**ELF**(**可执行和链接格式**)和**DWARF**(**调试标准**)之后，首席开发人员打算再发明一个基于托尔金世界的缩略语：ELF(**可执行和链接格式**)和**DWARF**(**调试标准**)已经有了。

ORC 引擎构建并扩展了在内存目标文件上使用静态编译器和动态链接器的思想。 该实现使用*分层*方法。 这两个基本级别如下：

1.  编译层
2.  链路层

在编译器层的顶部可以有一层，为*惰性编译*提供支持。 **转换层**可以堆叠在惰性编译层的上面或下面，允许开发人员添加任意转换，或者简单地通知某些事件。 这种分层方法的优势在于，JIT 引擎*可以针对不同的需求进行自定义*。 例如，高性能虚拟机可能选择预先编译所有内容，而不使用惰性编译器。 其他虚拟机将强调启动时间和对用户的响应能力，并在惰性编译器的帮助下实现这一点。

较旧的 MCJIT 引擎仍然可用。 该 API 派生自一个更老的、已经删除的 JIT 引擎。 随着时间的推移，API 变得有点臃肿，并且缺乏 ORC API 的灵活性。 我们的目标是删除此实现，因为 ORC 引擎现在提供了 MCJIT 引擎的所有功能。 新的开发应该使用 ORC API。

在下一节中，我们先看一下 LLVM 解释器和动态编译器`lli`，然后再开始实现 JIT 编译器。

# 使用 JIT 编译直接执行

在考虑 JIT 编译器时，首先想到的是直接运行 LLVMIR。 这就是`lli`工具、LLVM 解释器和动态编译器所做的事情。 我们将在下一节中探索`lli`工具，随后我们自己实现一个类似的工具。

## 探索 lli 工具

让我们用一个非常简单的示例来尝试`lli`工具。 将以下源存储为`hello.ll`文件。 它相当于一个 C hello world 应用。 它从 C 库声明`printf()`函数的原型。 常量`hellostr`包含要打印的消息。 在`main()`函数中，通过`getelementptr`指令计算消息第一个字符的指针，并将该值传递给`printf()`函数。 应用总是返回`0`。 完整的源代码如下：

```cpp
declare i32 @printf(i8*, ...)
@hellostr = private unnamed_addr constant [13 x i8] c"Hello                                                   world\0A\00"
define i32 @main(i32 %argc, i8** %argv) {
  %res = call i32 (i8*, ...) @printf(                  i8* getelementptr inbounds ([13 x i8],                          [13 x i8]* @hellostr, i64 0, i64 0))
  ret i32 0
}
```

此 LLVM IR 文件非常通用，因此对所有平台都有效。 我们可以在以下命令的帮助下，使用`lli`工具直接执行 IR：

```cpp
$ lli hello.ll
Hello world
```

这里的有趣之处在于如何找到`printf()`函数。 IR 代码被编译成机器码，并触发对`printf`符号的查找。 在 IR 中找不到此符号，因此将在当前进程中搜索它。 `lli`工具动态链接到 C 库，在那里可以找到符号。

当然，`lli`工具不会链接到您创建的库。 为了能够使用这些函数，`lli`工具支持加载共享库和对象。 下面的 C 源代码只打印一条友好的消息：

```cpp
#include <stdio.h>
void greetings() {
  puts("Hi!");
}
```

存储在`greetings.c`文件中，我们使用它来研究如何使用`lli`工具加载对象。 将此源代码编译为共享库。 `–fPIC`选项指示 clang 生成与位置无关的代码，这是共享库所必需的。 在给定`–shared`选项的情况下，编译器创建`greetings.so`共享库：

```cpp
$ clang –fPIC –shared –o greetings.so greetings.c
```

我们还将该文件编译为`greetings.o`目标文件：

```cpp
$ clang –c –o greetings.o greetings.c
```

我们现在有两个文件，`greetings.so`共享库和`greetings.o`对象文件，我们将把它们加载到`lli`工具中。

我们还需要一个调用`greetings()`函数的 LLVM IR 文件。 为此，创建`main.ll`文件，该文件包含对函数的单个调用：

```cpp
declare void @greetings(...)
define dso_local i32 @main(i32 %argc, i8** %argv) {
  call void (...) @greetings()
  ret i32 0
}
```

如果您尝试像以前一样执行 IR，则`lli`工具无法找到问候语符号，并将简单地崩溃：

```cpp
$ lli main.ll
PLEASE submit a bug report to https://bugs.llvm.org/ and include the crash backtrace.
```

`greetings()`函数是在外部文件中定义的，要修复崩溃，我们必须告诉`lli`工具需要加载哪个附加文件。 为了使用共享库，您必须使用`–load`选项，该选项将共享库的路径作为参数：

```cpp
$ lli –load ./greetings.so main.ll
Hi!
```

如果包含共享库的目录不在动态加载器的搜索路径中，指定共享库的路径很重要。 如果省略，则将找不到库。

或者，我们可以使用`–extra-object`选项指示`lli`工具加载目标文件：

```cpp
$ lli –extra-object greetings.o main.ll
Hi!
```

其他支持的选项有`–extra-archive`(加载存档)和`–extra-module`(加载另一个位码文件)。 这两个选项都需要文件路径作为参数。

现在您知道了如何使用`lli`工具直接执行 LLVM IR。 在下一节中，我们将实现我们自己的 JIT 工具。

## 用 LLJIT 实现我们自己的 JIT 编译器

`lli`工具只不过是 LLVMAPI 的薄薄包装器。 在第一部分中，我们了解到 ORC 引擎使用分层方法。 `ExecutionSession`类表示正在运行的 JIT 程序。 除其他项外，该类还保存已使用的`JITDylib`实例。 `JITDylib`实例是一个符号表，将符号名称映射到地址。 例如，这可以是 LLVM IR 文件中定义的符号，也可以是加载的共享库的符号。

要执行 LLVM IR，我们不需要自己创建 JIT 堆栈。 实用程序`LLJIT`类提供此功能。 在从旧的 MCJIT 实现迁移时，您也可以使用这个类。 这个类本质上提供了相同的功能。 在下一个小节中，我们从 JIT 引擎的初始化开始实现。

### 初始化 JIT 引擎以编译 LLVM IR

我们首先实现设置 JIT 引擎的函数，编译 LLVM IR 模块，并执行该模块中的`main()`函数。 稍后，我们将使用此核心功能构建一个小型 JIT 工具。 这是`jitmain()`函数：

1.  该功能需要具有 IR 的 LLVM 模块才能执行。 还需要用于此模块的 LLVM 上下文类，因为上下文类包含重要的类型信息。 目标是调用`main()`函数，因此我们还传递了常用的`argc`和`argv`参数：

    ```cpp
    Error jitmain(std::unique_ptr<Module> M,
                  std::unique_ptr<LLVMContext> Ctx, int 
                  argc,
                  char *argv[]) {
    ```

2.  我们使用`LLJITBuilder`类创建一个`LLJIT`实例。 如果发生错误，则返回错误。 错误的一个可能来源是平台尚不支持 JIT 编译：

    ```cpp
      auto JIT = orc::LLJITBuilder().create();
      if (!JIT)
        return JIT.takeError();
    ```

3.  然后，我们将模块添加到主`JITDylib`实例。 如果进行了配置，那么 JIT 编译将利用多个线程。 因此，我们需要将模块和上下文包装在一个`ThreadSafeModule`实例中。 如果发生错误，则返回错误：

    ```cpp
      if (auto Err = (*JIT)->addIRModule(
              orc::ThreadSafeModule(std::move(M),
                                    std::move(Ctx))))
        return Err;
    ```

4.  与`lli`工具一样，我们也支持 C 库中的符号。 `DefinitionGenerator`类公开符号，`DynamicLibrarySearchGenerator`子类公开在共享库中找到的名称。 该类提供了两个工厂方法。 `Load()`方法可用于加载共享库，而`GetForCurrentProcess()`方法则公开当前进程的符号。 我们使用后一个函数。 符号名称可以有前缀，具体取决于平台。 我们检索数据布局并将前缀传递给`GetForCurrentprocess()`函数。 然后以正确的方式对待符号名称，我们不需要关心它。 像往常一样，我们从函数返回，以防出现错误：

    ```cpp
      const DataLayout &DL = (*JIT)->getDataLayout();
      auto DLSG = orc::DynamicLibrarySearchGenerator::
          GetForCurrentProcess(DL.getGlobalPrefix());
      if (!DLSG)
        return DLSG.takeError();
    ```

5.  然后，我们将生成器添加到主`JITDylib`实例。 如果需要查找符号，还会搜索加载的共享库中的符号：

    ```cpp
      (*JIT)->getMainJITDylib().addGenerator(
          std::move(*DLSG));
    ```

6.  接下来，我们查找`main`符号。 此符号必须位于命令行上给出的 IR 模块中。 查找触发该 IR 模块的编译。 如果 IR 模块内引用了其他符号，则使用上一步中添加的生成器来解析它们。 结果属于`JITEvaluatedSymbol`类：

    ```cpp
      auto MainSym = (*JIT)->lookup("main");
      if (!MainSym)
        return MainSym.takeError();
    ```

7.  我们向返回的 JIT 符号询问函数的地址。 我们将此地址转换为 C`main()`函数的原型：

    ```cpp
      auto *Main = (int (*)(
          int, char **))MainSym->getAddress();
    ```

8.  现在我们可以调用 IR 模块中的`main()`函数，并传递该函数期望的`argc`和`argv`参数。 我们忽略返回值：

    ```cpp
      (void)Main(argc, argv);
    ```

9.  我们报告函数执行成功：

    ```cpp
      return Error::success();
    }
    ```

这说明了使用 JIT 编译是多么容易。 除了公开当前进程的符号或来自共享库的符号之外，还有许多其他可能的方法来公开名称。 `StaticLibraryDefinitionGenerator`类公开在静态存档中找到的符号，并且可以按照与`DynamicLibrarySearchGenerator`类相同的方式使用。 `LLJIT`类还有一个`addObjectFile()`方法来公开目标文件的符号。 如果现有的实现不能满足您的需要，您也可以提供您自己的`DefinitionGenerator`实现。 在下一个小节中，您将把实现扩展到 JIT 编译器中。

### 创建 JIT 编译器实用程序

可以很容易地将`jitmain()`函数扩展为一个小工具，我们接下来要做的就是这样做。 源代码保存在`JIT.cpp`文件中，是一个简单的 JIT 编译器：

1.  我们必须包括几个头文件。 `LLJIT.h`头定义了`LLJIT`类，以及 ORC API 的核心类。 我们包含`IRReader.h`头，因为它定义了读取 LLVM IR 文件的函数。 `CommandLine.h`头允许我们解析 LLVM 样式的命令行选项。 最后，工具的基本初始化需要`InitLLVM.h`标头，本机目标的初始化需要`TargetSelect.h`标头：

    ```cpp
    #include "llvm/ExecutionEngine/Orc/LLJIT.h"
    #include "llvm/IRReader/IRReader.h"
    #include "llvm/Support/CommandLine.h"
    #include "llvm/Support/InitLLVM.h"
    #include "llvm/Support/TargetSelect.h"
    ```

2.  我们将`llvm`命名空间添加到当前作用域：

    ```cpp
    using namespace llvm;
    ```

3.  我们的 JIT 工具在命令行上正好需要一个输入文件，我们用`cl::opt<>`类声明：

    ```cpp
    static cl::opt<std::string>
        InputFile(cl::Positional, cl::Required,
                  cl::desc("<input-file>"));
    ```

4.  要读取 IR 文件，我们调用`parseIRFile()`函数。 该文件可以是文本 IR 表示形式，也可以是位码文件。 该函数返回指向创建的模块的指针。 错误处理略有不同，因为可以解析文本 IR 文件，这在语法上不一定是正确的。 在出现语法错误的情况下，`SMDiagnostic`实例保存错误信息。 打印错误消息，并退出应用：

    ```cpp
    std::unique_ptr<Module>
    loadModule(StringRef Filename, LLVMContext &Ctx,
               const char *ProgName) {
      SMDiagnostic Err;
      std::unique_ptr<Module> Mod =
          parseIRFile(Filename, Err, Ctx);
      if (!Mod.get()) {
        Err.print(ProgName, errs());
        exit(-1);
      }
      return std::move(Mod);
    }
    ```

5.  函数`jitmain()`放在这里：

    ```cpp
    Error jitmain(…) { … }
    ```

6.  然后我们添加`main()`函数，该函数初始化工具和本机目标，并解析命令行：

    ```cpp
    int main(int argc, char *argv[]) {
      InitLLVM X(argc, argv);
      InitializeNativeTarget();
      InitializeNativeTargetAsmPrinter();
      InitializeNativeTargetAsmParser();
      cl::ParseCommandLineOptions(argc, argv,
                                  "JIT\n");
    ```

7.  接下来，初始化 LLVM 上下文类：

    ```cpp
      auto Ctx = std::make_unique<LLVMContext>();
    ```

8.  然后，我们加载命令行中命名的 IR 模块：

    ```cpp
      std::unique_ptr<Module> M =
          loadModule(InputFile, *Ctx, argv[0]);
    ```

9.  然后我们可以调用`jitmain()`函数。 为了处理错误，我们使用`ExitOnError`实用程序类。 此类打印错误消息，并在发生错误时退出应用。 我们还设置了一个带有应用名称的横幅，该横幅打印在错误消息

    ```cpp
      ExitOnError ExitOnErr(std::string(argv[0]) + ": ");
      ExitOnErr(jitmain(std::move(M), std::move(Ctx),
                        argc, argv));
    ```

    之前
10.  如果控制流达到这一点，则表示 IR 已成功执行。 我们返回`0`表示成功：

    ```cpp
      return 0;
    }
    ```

这已经是完整的实现了！ 我们只需要添加构建描述，这是下一个小节的主题。

### 添加 CMake 内部版本描述

为了编译这个源文件，我们还需要创建一个带有构建描述的`CMakeLists.txt`文件，该文件保存在`JIT.cpp`文件旁边：

1.  我们将所需的最低 CMake 版本设置为 LLVM 所需的数量，并将项目命名为`jit`：

    ```cpp
    cmake_minimum_required (VERSION 3.13.4)
    project ("jit")
    ```

2.  需要加载 LLVM 包，我们将 LLVM 提供的 CMake 模块的目录添加到搜索路径中。 然后我们包含`ChooseMSVCCRT`模块，它确保使用与 LLVM 相同的 C 运行时：

    ```cpp
    find_package(LLVM REQUIRED CONFIG)
    list(APPEND CMAKE_MODULE_PATH ${LLVM_DIR})
    include(ChooseMSVCCRT)
    ```

3.  我们还需要从 LLVM 添加定义和包含路径。 使用的 LLVM 组件通过函数调用映射到库名称：

    ```cpp
    add_definitions(${LLVM_DEFINITIONS})
    include_directories(SYSTEM ${LLVM_INCLUDE_DIRS})
    llvm_map_components_to_libnames(llvm_libs Core OrcJIT
                                              Support 
                                              native)
    ```

4.  最后，我们定义了可执行文件的名称、要编译的源文件以及要链接到的库：

    ```cpp
    add_executable(JIT JIT.cpp)
    target_link_libraries(JIT ${llvm_libs})
    ```

5.  这就是 JIT 工具所需的一切。 创建并切换到构建目录，然后运行以下命令创建并编译应用：

    ```cpp
    $ cmake –G Ninja <path to source directory>
    $ ninja
    ```

这将编译`JIT`工具。 您可以从本章开头用`hello.ll`文件检查功能：

```cpp
$ JIT hello.ll
Hello world
```

创建 JIT 编译器出奇地简单！

该示例使用 LLVM IR 作为输入，但这不是必需的。 `LLJIT`类使用`IRCompileLayer`类，负责将 IR 编译为机器码。 您可以定义自己的层，它接受您需要的输入，例如 Java 字节码。

使用预定义的 LLJIT 类很方便，但限制了我们的灵活性。 在下一节中，我们将了解如何使用 ORC API 提供的层实现 JIT 编译器。

## 从头开始构建 JIT 编译器类

使用 ORC 的分层方法，很容易构建针对需求定制的 JIT 编译器。 没有放之四海而皆准的 JIT 编译器，本章的第一节给出了一些例子。 让我们来看看如何设置 JIT 编译器。

ORC API 使用堆叠在一起的层。 最低级别是对象链接层，由`llvm::orc::RTDyldObjectLinkingLayer`类表示。 它负责链接内存中的对象并将其转换为可执行代码。 此任务所需的内存由`MemoryManager`接口的实例管理。 有默认实现，但如果需要，我们也可以使用自定义版本。

对象链接层上方是编译层，负责创建内存中的目标文件。 `llvm::orc::IRCompileLayer`类将 IR 模块作为输入，并将其编译为目标文件。 `IRCompileLayer`类是`IRLayer`类的子类，后者是接受 LLVM IR 的层实现的泛型类。

这两层已经构成了 JIT 编译器的核心。 他们添加一个 LLVM IR 模块作为输入，该模块在内存中编译和链接。 要添加更多功能，我们可以在这两个层的顶部添加更多层。 例如，`CompileOnDemandLayer`类拆分模块，因此只编译请求的函数。 这可以用来实现延迟编译。 `CompileOnDemandLayer`类也是`IRLayer`类的子类。 以一种非常通用的方式，`IRTransformLayer`类(也是`IRLayer`类的子类)允许我们对模块应用转换。

另一个重要的类是`ExecutionSession`类。 此类表示正在运行的 JIT 程序。 基本上，这意味着该类管理`JITDylib`符号表，提供符号查找功能，并跟踪使用的资源管理器。

JIT 编译器的通用配方如下：

1.  初始化`ExecutionSession`类的实例。
2.  初始化层，至少由`RTDyldObjectLinkingLayer`类和`IRCompileLayer`类组成。
3.  Create the first `JITDylib` symbol table, usually with `main` or a similar name.

    其用法与上一节中的`LLJIT`类非常相似：

4.  将 IR 模块添加到符号表。
5.  查找符号、关联函数的触发编译，可能还有整个模块。
6.  执行该函数。

在下一个小节中，我们将基于泛型配方实现一个 JIT 编译器类。

### 创建 JIT 编译器类

为了使 JIT 编译器类的实现简单，我们将所有内容放入`JIT.h`头文件中。 类的初始化稍微复杂一些。 由于要处理可能的错误，我们需要一个工厂方法来预先创建一些对象，然后才能调用构造函数。 创建类的步骤如下：

1.  我们首先用`JIT_H`预处理器定义

    ```cpp
    #ifndef JIT_H
    #define JIT_H
    ```

    保护头文件不会有多个包含
2.  需要一堆包含文件。 它们中的大多数都提供了一个与头文件同名的类。 `Core.h`头提供了几个基本类，包括`ExecutionSession`类。 `ExecutionUtils.h`头提供了`DynamicLibrarySearchGenerator`类来搜索库中的符号，我们已经在*使用 LLJIT*实现我们自己的 JIT 编译器一节中使用了这个类。 `CompileUtils.h`头提供了`ConcurrentIRCompiler`类：

    ```cpp
    #include "llvm/Analysis/AliasAnalysis.h"
    #include "llvm/ExecutionEngine/JITSymbol.h"
    #include "llvm/ExecutionEngine/Orc/CompileUtils.h"
    #include "llvm/ExecutionEngine/Orc/Core.h"
    #include "llvm/ExecutionEngine/Orc/ExecutionUtils.h"
    #include "llvm/ExecutionEngine/Orc/IRCompileLayer.h"
    #include "llvm/ExecutionEngine/Orc/IRTransformLayer.h"
    #include     "llvm/ExecutionEngine/Orc/JITTargetMachineBuilder.h"
    #include "llvm/ExecutionEngine/Orc/Mangling.h"
    #include     "llvm/ExecutionEngine/Orc/RTDyldObjectLinkingLayer.h"
    #include     "llvm/ExecutionEngine/Orc/TargetProcessControl.h"
    #include "llvm/ExecutionEngine/SectionMemoryManager.h"
    #include "llvm/Passes/PassBuilder.h"
    #include "llvm/Support/Error.h"
    ```

3.  我们的新类是`JIT`类：

    ```cpp
    class JIT {
    ```

4.  私有数据成员反映 ORC 层和助手类。 `ExecutionSession`、`ObjectLinkingLayer`、`CompileLayer`、`OptIRLayer`和`MainJITDylib`实例表示正在运行的 JIT 程序、层和符号表，如前所述。 `TargetProcessControl`实例用于与 JIT 目标流程交互。 这可以是相同的进程、同一台计算机上的另一个进程或不同计算机上的远程进程(可能具有不同的体系结构)。 需要`DataLayout`和`MangleAndInterner`类以正确的方式破坏符号名称。 符号名称是内部化的，这意味着所有相同的名称都有相同的地址。 要检查两个符号名称是否相等，只需比较地址就足够了，这是一个非常快的操作：

    ```cpp
      std::unique_ptr<llvm::orc::TargetProcessControl> 
        TPC;
      std::unique_ptr<llvm::orc::ExecutionSession> ES;
      llvm::DataLayout DL;
      llvm::orc::MangleAndInterner Mangle;
      std::unique_ptr<llvm::orc::RTDyldObjectLinkingLayer>
          ObjectLinkingLayer;
      std::unique_ptr<llvm::orc::IRCompileLayer>
          CompileLayer;
      std::unique_ptr<llvm::orc::IRTransformLayer>
          OptIRLayer;
      llvm::orc::JITDylib &MainJITDylib;
    ```

5.  The initialization is split into three parts. In C++, a constructor cannot return an error. The simple and recommended solution is to create a static factory method, which can do the error handling prior to constructing the object. The initialization of the layers is more complex, so we introduce factory methods for them, too.

    在`create()`工厂方法中，我们首先创建一个`SymbolStringPool`实例，该实例用于实现字符串内部化，并由几个类共享。 为了控制当前进程，我们创建了一个`SelfTargetProcessControl`实例。 如果我们希望以不同的进程为目标，则需要更改此实例。

    然后，我们构造一个`JITTargetMachineBuilder`实例，对于该实例，我们需要知道 JIT 流程的目标三元组。 接下来，我们向目标机器构建器查询数据布局。 例如，如果构建器无法基于提供的三元组实例化目标计算机，则此步骤可能会失败，因为对此目标的支持未编译到 LLVM 库中：

    ```cpp
    public:
      static llvm::Expected<std::unique_ptr<JIT>> create() {
        auto SSP =
            std::make_shared<llvm::orc::SymbolStringPool>();
        auto TPC =
            llvm::orc::SelfTargetProcessControl::Create(SSP);
        if (!TPC)
          return TPC.takeError();
        llvm::orc::JITTargetMachineBuilder JTMB(
            (*TPC)->getTargetTriple());
        auto DL = JTMB.getDefaultDataLayoutForTarget();
        if (!DL)
          return DL.takeError();
    ```

6.  此时，我们已经处理了所有可能失败的呼叫。 现在我们可以初始化`ExecutionSession`实例了。 最后，使用所有实例化对象调用`JIT`类的构造函数，并将结果返回给调用方：

    ```cpp
        auto ES =
            std::make_unique<llvm::orc::ExecutionSession>(
                std::move(SSP));
        return std::make_unique<JIT>(
            std::move(*TPC), std::move(ES), 
            std::move(*DL),
            std::move(JTMB));
      }
    ```

7.  `JIT`类的构造函数将传递的参数移动到私有数据成员。 Layer 对象是通过调用带有`create`前缀的静态工厂名称来构造的。 每个`layer`工厂方法都需要一个对`ExecutionSession`实例的引用，从而将层连接到正在运行的 JIT 会话。 除了位于层堆栈底部的对象链接层之外，每个层还需要引用前一层，以说明堆叠顺序：

    ```cpp
      JIT(std::unique_ptr<llvm::orc::TargetProcessControl>
              TPCtrl,
          std::unique_ptr<llvm::orc::ExecutionSession> ExeS,
          llvm::DataLayout DataL,
          llvm::orc::JITTargetMachineBuilder JTMB)
          : TPC(std::move(TPCtrl)), ES(std::move(ExeS)),
            DL(std::move(DataL)), Mangle(*ES, DL),
            ObjectLinkingLayer(std::move(
                createObjectLinkingLayer(*ES, JTMB))),
            CompileLayer(std::move(createCompileLayer(
                *ES, *ObjectLinkingLayer, 
                 std::move(JTMB)))),
            OptIRLayer(std::move(
                createOptIRLayer(*ES, *CompileLayer))),
            MainJITDylib(ES->createBareJITDylib("<main>")) {
    ```

8.  在构造函数的主体中，我们添加生成器来搜索当前进程中的符号。 `GetForCurrentProcess()`方法是特殊的，因为返回值包装在`Expected<>`模板中，这表明也可以返回`Error`对象。 但我们知道不会发生错误-当前进程最终会运行！ 因此，我们使用`cantFail()`函数解开结果，如果发生错误，该函数将终止应用：

    ```cpp
        MainJITDylib.addGenerator(llvm::cantFail(
            llvm::orc::DynamicLibrarySearchGenerator::
                GetForCurrentProcess(DL.getGlobalPrefix())));
      }
    ```

9.  要创建 Object链接层，我们需要提供一个内存管理器。 我们在这里坚持默认的`SectionMemoryManager`类，但如果需要，我们也可以提供不同的实现：

    ```cpp
      static std::unique_ptr<
          llvm::orc::RTDyldObjectLinkingLayer>
      createObjectLinkingLayer(
          llvm::orc::ExecutionSession &ES,
          llvm::orc::JITTargetMachineBuilder &JTMB) {
        auto GetMemoryManager = []() {
          return std::make_unique<
              llvm::SectionMemoryManager>();
        };
        auto OLLayer = std::make_unique<
            llvm::orc::RTDyldObjectLinkingLayer>(
            ES, GetMemoryManager);
    ```

10.  在 Windows 上使用的 COFF 对象文件格式有一点复杂。 此文件格式不允许将函数标记为已导出。 这随后会导致对象链接层内部检查失败：将存储在符号中的标志与 IR 中的标志进行比较，这会因为缺少导出标记而导致不匹配。 解决方案是仅覆盖此文件格式的标志。 这将完成对象层的构造，并将对象返回给调用方：

    ```cpp
        if (JTMB.getTargetTriple().isOSBinFormatCOFF()) {
          OLLayer
             ->setOverrideObjectFlagsWithResponsibilityFlags(
                  true);
          OLLayer
             ->setAutoClaimResponsibilityForObjectSymbols(
                  true);
        }
        return std::move(OLLayer);
      }
    ```

11.  要初始化编译器层，需要一个`IRCompiler`实例。 `IRCompiler`实例负责将 IR 模块编译成目标文件。 如果我们的 JIT 编译器不使用线程，那么我们可以使用`SimpleCompiler`类，它使用给定的目标机器编译 IR 模块。 `TargetMachine`类不是线程安全的，同样，`SimpleCompiler`类也不是线程安全的。 为了支持多线程编译，我们使用`ConcurrentIRCompiler`类，它为每个要编译的模块创建一个新的`TargetMachine`实例。 这种方法解决了多线程的问题：

    ```cpp
      static std::unique_ptr<llvm::orc::IRCompileLayer>
      createCompileLayer(
          llvm::orc::ExecutionSession &ES,
          llvm::orc::RTDyldObjectLinkingLayer &OLLayer,
          llvm::orc::JITTargetMachineBuilder JTMB) {
        auto IRCompiler = std::make_unique<
            llvm::orc::ConcurrentIRCompiler>(
            std::move(JTMB));
        auto IRCLayer =
            std::make_unique<llvm::orc::IRCompileLayer>(
                ES, OLLayer, std::move(IRCompiler));
        return std::move(IRCLayer);
      }
    ```

12.  Instead of compiling the IR module directly to machine code, we install a layer that optimizes the IR first. This is a deliberate design decision: We turn our JIT compiler into an optimizing JIT compiler, which produces faster code that takes longer to produce, meaning a delay for the user. We do not add lazy compilation, so entire modules are compiled when just a symbol is looked up. This can add up to a significant time before the user sees the code executing.

    笔记 / 便条 / 票据 / 注解

    请注意，引入延迟编译并不是在所有情况下都是正确的解决方案。

    惰性编译是通过将每个函数移动到自己的模块中来实现的，该模块在查找函数名时进行编译。 这可以防止过程间优化(如*内联*)，因为内联传递需要访问调用的函数体来内联它们。 因此，用户可以看到延迟编译的启动速度更快，但是生成的代码并不是最优的。 这些设计决策取决于预期用途。 在这里，我们决定使用快速代码，接受较慢的启动时间。 优化层被实现为变换层。 `IRTransformLayer`类将转换委托给一个函数，在我们的示例中，委托给`optimizeModule`函数：

    ```cpp
      static std::unique_ptr<llvm::orc::IRTransformLayer>
      createOptIRLayer(
          llvm::orc::ExecutionSession &ES,
          llvm::orc::IRCompileLayer &CompileLayer) {
        auto OptIRLayer =
            std::make_unique<llvm::orc::IRTransformLayer>(
                ES, CompileLayer,
                optimizeModule);
        return std::move(OptIRLayer);
      }
    ```

13.  `optimizeModule()`函数是 IR 模块上的转换示例。 该函数将模块转换为参数，并返回转换后的模块。 因为 JIT 可能会使用多个线程运行，所以 IR 模块包装在一个`ThreadSafeModule`实例中：

    ```cpp
      static llvm::Expected<llvm::orc::ThreadSafeModule>
      optimizeModule(
          llvm::orc::ThreadSafeModule TSM,
          const llvm::orc::MaterializationResponsibility
              &R) {
    ```

14.  为了优化 IR，我们回顾一下[*第 8 章*](08.html#_idTextAnchor126)，*优化 IR*中的*向编译器添加优化管道*一节中的一些信息。 我们需要一个`PassBuilder`实例来创建优化管道。 首先，我们定义两个分析管理器，然后在 Pass 构建器中注册它们。 然后，我们使用`O2`级别的默认优化管道填充`ModulePassManager`实例。 这又是一个设计决策：`O2`级别已经生成了快速的机器代码，但是比`O3`级别更快。 然后，我们在模块上运行管道。 最后，将优化后的模块返回给调用者：

    ```cpp
        TSM.withModuleDo([](llvm::Module &M) {
          bool DebugPM = false;
          llvm::PassBuilder PB(DebugPM);
          llvm::LoopAnalysisManager LAM(DebugPM);
          llvm::FunctionAnalysisManager FAM(DebugPM);
          llvm::CGSCCAnalysisManager CGAM(DebugPM);
          llvm::ModuleAnalysisManager MAM(DebugPM);
          FAM.registerPass(
              [&] { return PB.buildDefaultAAPipeline(); });
          PB.registerModuleAnalyses(MAM);
          PB.registerCGSCCAnalyses(CGAM);
          PB.registerFunctionAnalyses(FAM);
          PB.registerLoopAnalyses(LAM);
          PB.crossRegisterProxies(LAM, FAM, CGAM, MAM);
          llvm::ModulePassManager MPM =
              PB.buildPerModuleDefaultPipeline(
                  llvm::PassBuilder::OptimizationLevel::O2,
                  DebugPM);
          MPM.run(M, MAM);
        });
        return std::move(TSM);
      }
    ```

15.  `JIT`类的客户端需要一种方法来添加 IR 模块，我们为它提供了`addIRModule()`函数。 记住我们创建的层堆栈：我们必须将 IR模块添加到顶层，否则我们会意外地绕过某些层。 这将是一个不易发现的编程错误：如果`OptIRLayer`成员被`CompileLayer`成员替换，那么我们的`JIT`类仍然可以工作，但不能作为优化 JIT 使用，因为我们已经绕过了这一层。 对于这个小的实现来说，这没有什么好担心的，但在大型 JIT 优化中，我们会引入一个函数来返回顶级层：

    ```cpp
      llvm::Error addIRModule(
          llvm::orc::ThreadSafeModule TSM,
          llvm::orc::ResourceTrackerSP RT = nullptr) {
        if (!RT)
          RT = MainJITDylib.getDefaultResourceTracker();
        return OptIRLayer->add(RT, std::move(TSM));
      }
    ```

16.  同样，我们的 JIT 类的客户端需要一种查找符号的方法。 我们将此委托给`ExecutionSession`实例，传入对主符号表的引用以及请求符号的损坏和内部化名称：

    ```cpp
      llvm::Expected<llvm::JITEvaluatedSymbol>
      lookup(llvm::StringRef Name) {
        return ES->lookup({&MainJITDylib},
                          Mangle(Name.str()));
      }
    ```

将 JIT 编译器组装在一起非常容易。 初始化该类有点棘手，因为它涉及`JIT`类的工厂方法和构造函数调用，以及每层的工厂方法。 这个发行版是由 C++ 中的限制造成的，尽管代码本身很简单。

在下一个小节中，我们将使用新的 JIT 编译器类来实现命令行实用程序。

### 使用我们新的 JIT 编译器类

我们的新 JIT 编译器类的接口类似于*使用 LLJIT*实现我们自己的 JIT 编译器一节中使用的`LLJIT`类。 为了测试我们的新实现，我们从上一节复制`LIT.cpp`类并进行以下更改：

1.  为了能够使用我们的新类，我们包含了`JIT.h`头文件。 这将替换不再需要的`llvm/ExecutionEngine/Orc/LLJIT.h`头文件，因为我们不再使用 LLJIT 类。
2.  在`jitmain()`函数内部，我们将对`orc::LLJITBuilder().create()`的调用替换为对新的`JIT::create()`方法的调用。
3.  同样，在`jitmain()`函数中，我们删除了添加`DynamicLibrarySearchGenerator`类的代码。 准确地说，这个生成器集成在 JIT 类中。

这已经是需要改变的一切了！ 我们可以像上一节一样编译和运行更改后的应用，得到相同的结果。 在幕后，新类使用固定的优化级别，因此对于足够大的模块，我们可以注意到启动和运行时的差异。

手头有一个 JIT 编译器可以激发新的想法。 在下一节中，我们将了解如何使用 JIT 编译器作为静态编译器的一部分，以便在编译时计算代码。

# 利用 JIT 编译器进行代码评估

编译器编写者使付出了巨大的努力来产生最优的代码。 一种简单但有效的优化是用该运算的结果值替换对两个常量的算术运算。 为了能够执行计算，嵌入了常量表达式解释器。 要得到相同的结果，解释器必须实现与生成的机器码相同的规则！ 当然，这可能是细微错误的根源。

另一种方法是使用相同的代码生成方法将常量表达式编译为 IR，然后让 JIT 编译并执行 IR。 这个想法甚至可以更进一步。 在数学中，函数总是对相同的输入产生相同的结果。 对于计算机语言中的函数，情况并非如此。 `rand()`函数就是一个很好的例子，它为每个调用返回一个随机值。 计算机语言中的函数与数学中的函数具有相同的特征，称为**纯函数**。 在表达式的优化期间，我们可以 JIT 编译和执行纯函数，这些纯函数只有常量参数，并用 JIT 执行返回的结果替换对函数的调用。 实际上，我们将函数的执行从运行时移到了编译时！

关于交叉编译的思考

使用 JIT 编译器作为静态编译器的一部分是一个有趣的选择。 但是，如果编译器要支持交叉编译，那么这种方法应该经过深思熟虑。 造成麻烦的候选对象通常是浮点类型。 C 中`long double`类型的精度通常取决于硬件和操作系统。 一些系统使用 128 位浮点，而其他系统仅使用 64 位浮点。 80 位浮点类型仅在 x86 平台上可用，通常仅在 Windows 上使用。 用不同的精度执行相同的浮点运算可能会导致巨大的差异。 这种情况下不能使用 JIT 编译求值。

很难判断一个函数是否是纯函数。 常见的解决方案是应用启发式方法。 如果函数不通过指针或使用聚合类型间接读取或写入堆内存，而只调用其他纯函数，则该函数是纯函数。 开发人员可以帮助编译器，并标记纯函数，例如，使用特殊的关键字或符号。 在语义分析阶段，编译器随后可以检查违规。

在下一个小节中，我们将进一步研究在编译时尝试 JIT 执行函数时对语言语义的影响。

## 识别语言语义

困难的部分确实是在语言语义级别上决定语言的哪些部分适合在编译时进行评估。 排除对堆内存的访问是非常严格的。 例如，一般而言，它排除了字符串处理。 当分配的内存超过 JIT 执行函数的生存期时，堆内存的使用就会出现问题。 这是一种程序状态，可能会影响其他结果，因此很危险。 另一方面，如果存在对`malloc()`和`free()`函数的匹配调用，则内存仅用于内部计算。 在这种情况下，堆内存的使用将是安全的。 但确切地说，这一条件并不容易证明。

在类似的级别上，JIT 执行的函数内的无限循环可能会冻结编译器。 艾伦·图灵(Alan Turing)在 1936 年证明，没有一台机器可以决定一个函数是否会产生结果，或者它是否会陷入无穷无尽的循环。 必须采取一些预防措施来避免这种情况，例如，JIT 执行的函数终止之前的运行时限制。

最后，该功能被允许的越多，就必须在安全性上投入更多的精力，因为编译器现在执行其他人编写的代码。 想象一下，这段代码从互联网下载并运行文件，或者试图擦除硬盘：由于 JIT 执行的函数允许太多状态，我们还需要考虑这样的场景。

这个想法并不新鲜。 D 编程语言有一个称为**编译时函数执行**的功能。 引用编译器**DMD**通过在 AST 级别解释函数来实现此功能。 基于 LLVM 的 LDC 编译器有一个实验性特性，可以使用 LLVM JIT 引擎进行编译。 您可以在 https://dlang.org/.上找到有关该语言和编译器的更多信息

忽略语义挑战，实现并不是那么困难。 在*从头开始构建 JIT 编译器类*一节中，我们使用`JIT`类开发了一个 JIT 编译器。 我们在类中提供一个 IR 模块，我们可以从这个模块中查找和执行函数。 查看`tinylang`编译器实现，我们可以清楚地识别对常量的访问，因为 AST 中有一个`ConstantAccess`节点。 例如，代码如下所示：

```cpp
  if (auto *Const = llvm::dyn_cast<ConstantAccess>(Expr)) {
    // Do something with the constant.
  }
```

我们可以执行以下操作，而不是解释表达式中的运算来派生常量的值：

1.  创建新的红外线模块。
2.  在模块中创建 IR 函数，返回预期类型的值。
3.  使用现有的`emitExpr()`函数为表达式创建 IR，并使用最后一条指令返回计算值。
4.  JIT-执行函数以计算值。

这值得实施吗？ 作为优化管道的一部分，LLVM 执行常量传播和函数内联。 在 IR 构造过程中，诸如 4+5 这样的简单表达式已被替换为结果。 计算最大公约数等小函数是内联的。 如果所有参数都是常量值，则通过常量传播将计算结果替换为内联代码。

基于这种观察，只有在编译时有足够的语言特性可供执行时，此方法的实现才有用。 如果是这样，那么使用给定的草图就可以相当容易地实现它。

了解如何利用 LLVM 的 JIT 编译器组件使您能够以全新的方式使用 LLVM。 除了实现 Java VM 之类的 JIT 编译器之外，JIT 编译器还可以嵌入到其他应用中。 这允许创造性的方法，例如在静态编译器中使用它，您在本节中将看到这一点。

# 摘要

在本章中，您学习了如何开发 JIT 编译器。 您从 JIT 编译器的可能应用开始，并探索了 LLVM 动态编译器和解释器`lli`。 使用预定义的`LLJIT`类，您自己构建了一个类似于`lli`的工具。 为了能够利用 ORC API 的分层结构，您实现了一个优化`JIT`类。 掌握了所有这些知识之后，您探索了在静态编译器中使用 JIT 编译器的可能性，一些语言可以从中受益。

在下一章中，您将研究如何将新 CPU 架构的后端添加到 LLVM。