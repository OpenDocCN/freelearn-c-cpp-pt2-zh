Designing Microservices

随着微服务的日益普及，我们想把本书的一整章献给他们。在讨论架构时，您可能会在某个时候听到: “我们应该为此使用微服务吗？”本章将向您展示如何将现有应用程序迁移到微服务体系结构，以及如何构建利用微服务的新应用程序。

本章将介绍以下主题:

*   潜入微服务
*   构建微服务
*   观察微服务
*   连接微服务
*   扩展微服务

# 技术要求

本章介绍的大多数示例不需要任何特定的软件。对于`redis-cpp`库，请检查[https://github.com/tdv/ redis-cpp](https://github.com/tdv/redis-cpp)。

本章中出现的代码已放在 GitHub 上，https://github.com/PacktPublishing/ 软件架构与 Cpp/tree/master/Chapter13。

# 潜入微服务

虽然微服务与任何特定的编程语言或技术无关，但实现微服务时的常见选择是 Go 语言。这并不意味着其他语言不适合微服务开发-恰恰相反。C 的低计算和内存开销使其成为微服务的理想候选者。

但是首先，我们将从微服务的一些优缺点的详细视图开始。之后，我们将重点介绍通常与微服务相关的设计模式 (与[第 4 章](04.html)、*体系结构和系统设计*中所涵盖的一般设计模式相对)。

## 微服务的好处

您可能经常听到最高级的微服务。的确，他们可以带来一些好处，这里有一些好处。

### 模块化

由于整个应用程序被拆分成许多相对较小的模块，因此更容易理解每个微服务的作用。这种理解的自然结果是，测试单个微服务也更容易。每个微服务通常都有有限的范围，这也有助于测试。毕竟，仅测试日历应用程序比测试整个**个人信息管理** (**PIM**) 套件更容易。

然而，这种模块化需要付出一定的代价。您的团队可能对单个微服务有更好的了解，但同时他们可能会发现很难掌握整个应用程序的组成方式。虽然不必了解形成应用程序的微服务的所有内部细节，但组件之间的关系数量之多提出了认知挑战。使用这种体系结构方法时，使用微服务合同是很好的做法。

### 可伸缩性

扩展范围有限的应用程序更容易。原因之一是潜在的瓶颈较少。

扩展工作流程的较小部分也更具成本效益。想象一个负责管理交易会的整体应用程序。一旦系统开始显示性能问题，扩展的唯一方法就是引入一台更大的机器以使整体运行。这称为垂直缩放。

使用微服务，第一个优点是您可以水平扩展，即引入更多的机器，而不是更大的机器 (通常更便宜)。第二个优势来自这样一个事实，即您只需要扩展应用程序中存在性能问题的那些部分。这也有助于节省基础设施上的资金。

### 灵活性

如果设计得当，微服务不太容易受到供应商锁定的影响。当您决定要切换其中一个第三方组件时，您不必一次完成整个痛苦的迁移。微服务设计考虑到您需要使用接口，因此唯一需要修改的部分是您的微服务和第三方组件之间的接口。

组件也可能一个接一个地迁移，有些仍在使用旧提供商的软件。这意味着您可以同时在许多地方分离引入突破性变化的风险。更重要的是，您可以将其与金丝雀部署模式相结合，以更粒度的方式管理风险。

这种灵活性不仅仅与单一服务有关。它也可能意味着不同的数据库，不同的排队和消息传递解决方案，甚至完全不同的云平台。虽然不同的云平台通常提供不同的服务和 api 来使用它们，但使用微服务架构，您可以开始逐块迁移工作负载，并在新平台上独立测试它。

当由于性能问题、可伸缩性或可用依赖关系而需要重写时，重写一个微服务比单块要快得多。

### 与遗留系统的集成

微服务不一定是全有或全无的方法。如果您的应用程序经过了良好的测试，并且迁移到微服务可能会带来很多风险，那么完全拆除工作解决方案就没有压力。最好只拆分需要进一步开发的部分，并将其作为原始整体将使用的微服务引入。

通过遵循这种方法，您将获得与微服务相关的敏捷发布周期的好处，同时避免从头开始创建新的体系结构并基本上重建整个应用程序。如果某些东西已经运行良好，那么最好专注于如何在不破坏好的部分的情况下添加新功能，而不是从头开始。这里要小心，因为从头开始经常被用作自我提升!

### 分布式开发

开发团队规模较小且集中的时代早已一去不复返了。即使在传统的基于办公的公司中，远程工作和分布式开发也是事实。IBM、微软和英特尔等巨头都有来自不同地点的人在一个项目上合作。

微服务允许更小、更敏捷的团队，这使得分布式开发变得更加容易。当不再需要促进 20 人或更多的人之间的交流时，也更容易建立需要更少外部管理的自组织团队。

## 微服务的缺点

即使您认为由于微服务的好处而可能需要微服务，也请记住，它们也有一些严重的缺点。总之，它们绝对不适合所有人。较大的公司通常可以抵消这些弊端，但较小的公司通常没有这种奢侈。

### 依赖成熟的 DevOps 方法

构建和测试微服务应该比在大型单片应用程序上执行类似操作快得多。但是为了实现敏捷开发，这种构建和测试需要更频繁地执行。

虽然在处理 monolith 时手动部署应用程序可能是明智的，但如果将相同的方法应用于微服务，则会导致很多问题。

为了在开发中接受微服务，您必须确保您的团队具有 DevOps 思维方式，并了解构建和运行微服务的要求。仅仅将代码交给其他人而忘记它是不够的。

DevOps 的心态将帮助您的团队尽可能地实现自动化。在没有连续集成/连续交付管道的情况下开发微服务可能是软件体系结构中最糟糕的想法之一。这种方法将带来微服务的所有其他缺点，而不会带来大部分好处。

### 更难调试

微服务需要引入可观察性。没有它，当某些东西破裂时，您永远不确定从哪里开始寻找潜在的根本原因。可观察性是一种推断应用程序状态的方法，而无需运行调试器或日志到您的工作负载正在运行的计算机。

日志聚合、应用度量、监控和分布式跟踪的组合是管理基于微服务的体系结构的先决条件。一旦你考虑到自动缩放和自我修复甚至可能阻止你访问单个服务，如果它们开始崩溃，这一点尤其正确。

### 额外开销

微服务应该是精益和敏捷的。这通常是真的。但是，基于微服务的体系结构通常需要额外的开销。第一层开销与用于微服务通信的附加接口有关。RPC 库，API 提供者和使用者不仅要乘以微服务的数量，还要乘以其副本的数量。然后是辅助服务，比如数据库、消息队列等等。这些服务还包括可观察性设施，这些设施通常由存储设施和收集数据的单个收集器组成。

通过更好的扩展来优化的成本可能会被运行整个服务团队所需的成本所抵消，这些服务团队不会带来直接的业务价值。更重要的是，你可能很难向利益相关者证明这些成本 (基础设施和开发开销)。

## 微服务的设计模式

许多通用的设计模式也适用于微服务。还有一些通常与微服务相关联的设计模式。此处介绍的模式对于绿地项目以及从整体应用程序的迁移都很有用。

### 分解模式

这些模式与微服务的分解方式有关。我们希望确保体系结构稳定，服务松散耦合。我们还希望确保服务具有凝聚力和可测试性。最后，我们希望自治团队完全拥有一项或多项服务。

#### 按业务能力分解

分解模式之一需要按业务能力进行分解。业务能力与企业为了创造价值所做的事情有关。业务能力的例子有商户管理和客户管理。业务能力通常是按层次结构组织的。

应用此模式时的主要挑战是正确识别业务功能。这需要了解业务本身，并且可能会从与业务分析师的合作中受益。

#### 按子域分解

不同的分解模式与**域驱动设计** (**DDD**) 方法有关。要定义服务，需要标识 DDD 子域。就像业务能力一样，识别子域需要了解业务上下文。

这两种方法的主要区别在于，通过业务能力分解，重点更多地放在业务的组织 (其结构) 上，而通过子域分解，重点放在业务试图解决的问题上。

### 每个服务模式的数据库

在每个软件体系结构中，存储和处理数据都是一个复杂的问题。错误的选择可能会影响可伸缩性、性能或维护成本。对于微服务，由于我们希望微服务松散耦合，因此增加了复杂性。

这导致了一种设计模式，其中每个微服务都连接到自己的数据库，因此它独立于其他服务引入的任何更改。虽然这种模式增加了一些开销，但它的额外好处是您可以单独优化每个微服务的架构和索引。

由于数据库往往是相当庞大的基础设施，这种方法可能不可行，因此在微服务之间共享数据库是可以理解的权衡。

### 部署策略

使用在多个主机上运行的微服务，您可能会想知道哪个是分配资源的更好方法。让我们比较两种可能的方法。

#### Single service for host

使用这种模式，我们允许每个主机仅提供特定类型的微服务。主要好处是，您可以调整机器以更好地适应所需的工作负载，并且服务被很好地隔离。当您提供超大内存或快速存储时，您将确保它仅用于需要它的微服务。该服务也无法消耗比供应的资源更多的资源。

这种方法的缺点是某些主机可能未得到充分利用。一种可能的解决方法是使用仍然满足微服务需求的尽可能小的机器，并在必要时对其进行扩展。但是，此解决方法不能解决主机本身的额外开销问题。

#### 每个主机多个服务

相反的方法是每个主机托管多个服务。这有助于优化机器的利用率，但也有一些缺点。首先，不同的微服务可能需要不同的优化，因此将它们托管在单个主机上仍然是不可能的。更重要的是，使用这种方法，您将失去对主机分配的控制，因此一个微服务中的问题可能会导致一个联合定位的微服务中断，即使后者不会受到影响。

另一个问题是微服务之间的依赖冲突。当微服务没有相互隔离时，部署必须考虑不同的可能依赖关系。这种模式也不太安全。

### 可观察性模式

在上一节中，我们提到微服务是有代价的。此价格包括引入可观察性的要求，否则可能会失去调试应用程序的能力。以下是一些与可观察性相关的模式。

#### 日志聚合

微服务像单片应用程序一样使用日志记录。日志不是在本地存储日志，而是聚合并转发到中央设施。这样，即使服务本身已关闭，日志也可用。以集中方式存储日志还有助于关联来自不同微服务的数据。

#### 应用指标

要根据数据做出决策，首先需要一些数据来采取行动。收集应用程序指标有助于了解实际用户使用的应用程序行为，而不是在综合测试中使用的应用程序行为。收集这些指标的方法是 push (应用程序主动调用性能监控服务) 和 pull (性能监控服务定期检查配置的端点)。

#### 分布式跟踪

分布式跟踪不仅有助于调查性能问题，还有助于更好地了解实际流量下的应用程序行为。与日志记录 (从单个点收集信息) 不同，跟踪涉及单个事务的整个生命周期，从它源自用户操作的点开始。

#### 健康检查 api

由于微服务通常是自动化的目标，因此它们需要具有传达其内部状态的能力。即使该过程存在于系统中，也并不意味着该应用程序可以运行。开放的网络端口也是如此; 应用程序可能正在侦听，但尚未能够响应。运行状况检查 api 为外部服务提供了一种确定应用程序是否准备好处理工作负载的方法。自我修复和自动缩放使用健康检查来确定何时需要干预。基本前提是，当应用程序按预期运行时，给定的端点 (例如`/health`) 返回 HTTP 代码`200`，如果发现任何问题，则返回不同的代码 (或根本不返回)。

现在，您已经知道了所有的优点、缺点和模式，我们将向您展示如何拆分单片应用程序，并将其部分转化为微服务。所提出的方法不仅限于微服务; 它们在其他情况下也可能有用，包括单片应用程序。

# 构建微服务

关于单片应用有很多意见。一些建筑师认为，巨石本质上是邪恶的，因为它们不能很好地缩放，紧密耦合并且难以维护。还有其他人声称，巨石带来的性能好处抵消了它们的缺点。事实是，紧密耦合的组件在网络，处理能力和内存方面所需的开销要比其松散耦合的组件少得多。

由于每个应用程序都有独特的业务需求，并且在涉及利益相关者的独特环境中运行，因此没有关于哪种方法更适合的通用规则。更令人困惑的是，在最初从 monoliths 迁移到微服务之后，一些公司开始将微服务整合到 macroservices 中。这是因为事实证明，维护数千个单独的软件实例的负担太大，无法处理。

选择一种架构而不是另一种架构应始终来自业务需求和对不同替代方案的仔细分析。将意识形态放在实用主义之前通常会导致组织内部大量浪费。当一个团队不惜一切代价试图坚持一个给定的方法，而不考虑不同的解决方案或不同的外部意见时，这个团队就不再履行其义务，为正确的工作提供正确的工具。

如果您正在开发或维护整体，则可以考虑提高其可扩展性。本节介绍的技术旨在解决此问题，同时如果您决定这样做，还可以使您的应用程序更容易迁移到微服务。

瓶颈的三个主要原因如下:

*   记忆
*   存储
*   计算

我们将向您展示如何处理它们中的每一个，以开发基于微服务的可扩展解决方案。

## 外包内存管理

帮助微服务扩展的方法之一是将其某些任务外包。可能会阻碍扩展工作的一项任务是内存管理和缓存数据。

对于单个单片应用程序，将缓存的数据直接存储在进程内存中不是问题，因为无论如何，进程将是唯一访问缓存的进程。但是有了一个过程的多个副本，这种方法开始显示出一些问题。

如果一个副本已经计算了一块工作负载并将其存储在本地缓存中，该怎么办？另一个副本不知道这个事实，必须再次计算它。这样，您的应用程序既浪费了计算时间 (因为同一任务必须执行多次) 又浪费了内存 (因为结果也分别与每个副本一起存储)。

为了缓解此类挑战，请考虑切换到外部内存存储，而不是在应用程序内部管理缓存。使用外部解决方案的另一个好处是，缓存的生命周期不再与应用程序的生命周期绑定。您可以重新启动并部署应用程序的新版本，并且已存储在缓存中的值将被保留。

这也可能导致更短的启动时间，因为您的应用程序不再需要在启动期间执行计算。内存缓存的两种流行解决方案是 Memcached 和 Redis。

### 记忆缓存

2003 年发布的 Memcached 是两者的较旧产品。这是一个通用的分布式键值存储。该项目的最初目标是通过将缓存的值存储在内存中来卸载 web 应用程序中使用的数据库。Memcached 是按设计分布的。从 1.5.18 版本开始，可以在不丢失缓存内容的情况下重新启动 Memcached 服务器。通过使用 RAM 磁盘作为临时存储空间，这是可能的。

它使用一个简单的 API，可以通过 telnet 或 netcat 或使用许多流行编程语言的绑定来操作。没有任何专门针对 C 的绑定，但是可以使用 C/C`libmemcached`库。

### Redis

Redis 是一个比 Memcached 2009 年发布的初始版本更新的项目。此后，Redis 在许多情况下取代了 Memcached 的用法。就像 Memcached 一样，它是一个分布式的，通用的，内存中的键值存储。

与 Memcached 不同，Redis 还具有可选的数据持久性。虽然 Memcached 在键和值上是简单字符串，但 Redis 还支持其他数据类型，例如以下内容:

*   字符串列表
*   字符串集
*   字符串的排序集
*   键和值为字符串的哈希表
*   地理空间数据 (自 Redis 3.2 以来)
*   超日志

Redis 的设计使其成为缓存会话数据、缓存网页和实现排行榜的绝佳选择。除此之外，它还可以用于消息排队。流行的 Python 分布式任务队列库 Celery 使用 Redis 作为可能的代理之一，与 RabbitMQ 和 Apache SQS 一起使用。

微软、亚马逊、谷歌和阿里巴巴都提供基于 Redis 的托管服务作为其云平台的一部分。

C ++ 中有许多 Redis 客户端的实现。两个有趣的是使用 C 17 编写的`redis-cpp`库 ([https://github.com/tdv/ redis-cpp](https://github.com/tdv/redis-cpp)) 和使用 Qt 工具包编写的 QRedisClient ([https://github.com/uglide/qredisclient](https://github.com/uglide/qredisclient))。

以下从官方文档中获取的`redis-cpp`用法示例说明了如何使用它来设置和获取存储中的一些数据:

```
#include <cstdlib>
#include <iostream>

#include <redis-cpp/execute.h>
#include <redis-cpp/stream.h>

int main() {
  try {
    auto stream = rediscpp::make_stream("localhost", "6379");

    auto const key = "my_key";

    auto response = rediscpp::execute(*stream, "set", key,
                                      "Some value for 'my_key'", "ex", 
                                      "60");

    std::cout << "Set key '" << key << "': " 
              << response.as<std::string>()
              << std::endl;

    response = rediscpp::execute(*stream, "get", key);
    std::cout << "Get key '" << key << "': " 
              << response.as<std::string>()
              << std::endl;
  } catch (std::exception const &e) {
    std::cerr << "Error: " << e.what() << std::endl;
    return EXIT_FAILURE;
  }
  return EXIT_SUCCESS;
}
```

如您所见，该库处理处理不同的数据类型。该示例将值设置为字符串列表。

### 哪个内存缓存更好？

对于大多数应用程序来说，如今 Redis 将是更好的选择。它有一个更好的用户社区，有很多不同的实现，并且得到了很好的支持。除此之外，它还具有快照，复制，事务和 pub/sub 模型。可以使用 Redis 嵌入 Lua 脚本，并且对地理空间数据的支持使其成为支持地理位置的 web 和移动应用程序的绝佳选择。

但是，如果您的主要目标是在 web 应用程序中缓存数据库查询的结果，则 Memcached 是一种更简单的解决方案，开销要少得多。这意味着它应该更好地使用资源，因为它不必存储类型元数据或在不同类型之间执行转换。

## 外包存储

引入和扩展微服务时的另一个可能限制是存储。传统上，本地块设备已用于存储不属于数据库的对象 (例如静态 pdf 文件，文档或图像)。即使在如今，块存储在本地块设备和网络文件系统 (例如 NFS 或 CIFS) 中仍然非常流行。

虽然 NFS 和 CIFS 是**网络连接存储** (**NAS**) 的领域，但也存在与在不同级别上运行的概念相关的协议: **存储区域网络** (**SAN**)。一些流行的是 iSCSI，**网络块设备** (**NBD**)，以太网 ATA，光纤通道协议和以太网光纤通道。

另一种方法具有为分布式计算设计的群集文件系统: GlusterFS，CephFS 或 Lustre。但是，所有这些都作为块设备将相同的 POSIX 文件 API 暴露给用户。

作为 Amazon Web 服务的一部分，已经提出了关于存储的新观点。Amazon**简单存储服务** (**S3**) 是对象存储。API 提供对存储在存储空间中的对象的访问。这与传统的文件系统不同，因为文件，目录或 inode 之间没有区别。有桶和键指向对象，对象是服务存储的二进制数据。

## 外包计算

微服务的原则之一是，流程应仅负责完成工作流的单个部分。从 monoliths 迁移到微服务的自然步骤是定义可能的长时间运行的任务并将其拆分为各个流程。

这是任务队列背后的概念。任务队列处理管理任务的整个生命周期。您无需自己使用任务队列来实现线程处理或多处理，而是将任务委派给要执行的任务，然后由任务队列异步处理。该任务可以在与原始过程相同的计算机上执行，但也可以在具有专用要求的计算机上运行。

任务及其结果是异步的，因此主进程中没有阻塞。web 开发中流行的任务队列的示例有用于 Python 的 Celery，用于 Ruby 的 Sidekiq，用于 Node.js 的 Kue 和用于 Go 的 Machinery。所有这些都可以与 Redis 一起用作经纪人。不幸的是，没有任何类似的成熟解决方案可用于 C。

如果您正在认真考虑采用此路由，则一种可能的方法是直接在 Redis 中实现任务队列。Redis 及其 API 提供了必要的原语来支持这种行为。另一种可能的方法是使用现有任务队列中的一个，例如芹菜，并通过直接调用 Redis 来调用它们。但是，不建议这样做，因为它取决于任务队列的实现细节，而不是文档化的公共 API。另一种方法是使用 SWIG 或类似方法提供的绑定来接口任务队列。

# 观察微服务

您构建的每个微服务都需要遵循一般的体系结构设计模式。微服务与传统应用程序之间的主要区别在于前者需要实现可观察性。

本节主要介绍一些可观测性的方法。我们在这里描述了几种开源解决方案，您可能会在设计系统时发现它们很有用。

## 日志记录

即使您从未设计过微服务，日志记录也是您应该熟悉的主题。日志 (或日志文件) 存储有关系统中发生的事件的信息。该系统可能意味着您的应用程序、您的应用程序运行的操作系统或您用于部署的云平台。这些组件中的每一个都可以提供日志。

日志存储为单独的文件，因为它们提供了发生的所有事件的永久记录。当系统变得无响应时，我们希望查询日志并找出中断的可能根本原因。

这意味着日志也提供了审计跟踪。因为事件是按时间顺序记录的，所以我们可以通过检查记录的历史状态来了解系统的状态。

为了帮助调试，日志通常是人类可读的。日志有二进制格式，但是使用文件存储日志时，这种格式很少见。

### 使用微服务进行日志记录

这种日志记录的方法本身与传统方法没有太大区别。微服务通常将日志打印到`stdout`，而不是使用文本文件将日志存储在本地。然后使用统一的日志记录层来检索日志并对其进行处理。要实现日志记录，您需要一个日志记录库，您可以根据需要进行配置。

### 用 spdlog 登录 C

C ++ 流行且快速的日志记录库之一是`spdlog`。它是使用 C ++ 11 构建的，既可以用作仅头库，也可以用作静态库 (这减少了编译时间)。

`spdlog`的一些有趣的功能包括以下内容:

*   格式化
*   多个水槽:
    *   旋转文件
    *   Console
    *   系统日志
    *   自定义 (作为单一功能实现)
*   多线程和单线程版本
*   可选异步模式

`spdlog`中可能缺少的一个功能是对 Logstash 或 Fluentd 的直接支持。如果要使用这些聚合器之一，仍然可以使用文件接收器输出配置`spdlog`，并使用 Filebeat 或 Fluent Bit 将文件内容转发到相应的聚合器。

### 统一日志记录层

在大多数情况下，我们将无法控制我们使用的所有微服务。其中一些将使用一个日志库，而另一些将使用不同的日志库。最重要的是，格式将完全不同，它们的轮换策略也将完全不同。更糟糕的是，我们仍然希望将操作系统事件与应用程序事件相关联。这就是统一日志记录层发挥作用的地方。

统一日志记录层的目的之一是收集来自不同来源的日志。这种统一的日志记录层工具提供了许多集成，并了解不同的日志记录格式和传输 (例如文件，HTTP 和 TCP)。

统一日志记录层还能够过滤日志。我们可能希望进行过滤以满足合规性，匿名化客户的个人详细信息或保护我们服务的实施详细信息。

为了便于以后查询日志，统一日志记录层还可以执行格式之间的转换。即使您使用的不同服务以 JSON，CSV 和 Apache 格式存储日志，统一日志记录层解决方案也能够将它们全部转换为 JSON 以赋予它们结构。

统一日志记录层的最终任务是将日志转发到其下一个目的地。根据系统的复杂性，下一个目的地可能是存储设施或其他过滤、转换和转发设施。

以下是一些有趣的组件，可让您构建统一日志记录层。

#### Logstash

Logstash 是最流行的统一日志记录层解决方案之一。目前，它由 Elasticsearch 背后的公司 Elastic 拥有。如果您听说过麋鹿堆栈 (现在称为弹性堆栈)，则 Logstash 是首字母缩写中的 “L”。

Logstash 是用 Ruby 编写的，然后已经移植到 JRuby。不幸的是，这意味着它相当资源密集型。因此，不建议在每台计算机上运行 Logstash。相反，它主要用作日志转发器，其轻量级 Filebeat 部署到每台计算机并仅执行集合。

#### 文件节拍

Filebeat 是 Beats 产品系列的一部分。他们的目的是提供一种可以直接与应用程序一起使用的 Logstash 的轻量级替代方案。

这样，Beats 提供了较低的开销，可以很好地扩展，而集中式 Logstash 安装则执行所有繁重的工作，包括翻译，过滤和转发。

除 Filebeat 外，Beats 系列的其他产品如下:

*   性能指标
*   网络数据的 Packetbeat
*   审计数据的审计节拍
*   用于正常运行时间监控的心跳

#### Fluentd

Fluentd 是 Logstash 的主要竞争对手。它也是一些云提供商选择的工具。

由于其模块化的方法与插件的使用，你可以找到插件的数据源 (如 Ruby 应用程序，Docker 容器，SNMP，或 MQTT 协议)，数据输出 (如弹性堆栈，sql 数据库，Sentry，Datadog，或 Slack)，以及其他几种过滤器和中间件。

Fluentd 在资源上应该比 Logstash 轻，但它仍然不是大规模运行的完美解决方案。与 Fluentd 一起使用的 Filebeat 的对应部分称为 Fluent Bit。

#### 流利的位

Fluent Bit 用 C 编写，并提供了一种更快，更轻的解决方案，可插入 Fluentd。作为日志处理器和转发器，它还具有许多输入和输出集成功能。

除了日志收集外，Fluent Bit 还可以监视 Linux 系统上的 CPU 和内存指标。它可以与 Fluentd 一起使用，也可以直接转发到 Elasticsearch 或 InfluxDB。

#### 矢量

虽然 Logstash 和 Fluentd 是稳定、成熟和尝试的解决方案，但在统一测井层空间中也有更新的命题。

其中之一是 Vector，它旨在在一个工具中处理所有可观察性数据。为了区别于竞争对手，它侧重于性能和正确性。这也体现在技术的选择上。Vector 将 Rust 用于引擎，将 Lua 用于脚本编写 (与 Logstash 和 Fluentd 使用的自定义域特定语言相反)。

在撰写本文时，它还没有达到稳定的 1.0 版本，因此在这一点上，它不应该被认为可以生产。

### 日志聚合

日志聚合解决了另一个因数据过多而产生的问题: 如何存储和访问日志。尽管统一日志记录层即使在机器中断的情况下也可以使用日志，但日志聚合的任务是帮助我们快速找到所需的信息。

允许存储、索引和查询大量数据的两种可能的产品是 Elasticsearch 和 Loki。

#### Elasticsearch

Elasticsearch 是最受欢迎的自托管日志聚合解决方案。这是 (前) 麋鹿栈中的 "E"。它具有基于 Apache Lucene 的出色搜索引擎。

作为其利基市场的事实上的标准，Elasticsearch 具有许多集成，并且在社区和商业服务中都得到了大力支持。一些云提供商将 Elasticsearch 作为托管服务提供，这使得在应用程序中引入 Elasticsearch 变得更加容易。除此之外，制造 Elasticsearch 的公司 Elastic 提供的托管解决方案与任何特定的云提供商无关。

#### 洛基

Loki 旨在解决 Elasticsearch 中发现的一些缺点。Loki 的重点领域是水平可伸缩性和高可用性。它是作为云原生解决方案从头开始构建的。

Loki 的设计选择受到普罗米修斯和 Grafana 的启发。这并不奇怪，因为它是由负责 Grafana 的团队开发的。

虽然 Loki 应该是一个稳定的解决方案，但它并不像 Elasticsearch 那样受欢迎，这意味着一些集成可能会丢失，文档和社区支持不会与 Elasticsearch 处于同一水平。Fluentd 和 Vector 都有支持 Loki 进行日志聚合的插件。

### 日志可视化

我们要考虑的日志记录堆栈的最后一块是日志可视化。这有助于我们查询和分析日志。它以可访问的方式显示数据，因此所有相关方 (例如运营商，开发人员，QA 或企业) 都可以对其进行检查。

日志可视化工具使我们能够创建仪表板，使读取我们感兴趣的数据变得更加容易。这样，我们就能够探索事件，搜索相关性，并从简单的用户界面中找到外围数据。

有两大产品致力于日志可视化。

#### 基巴纳

Kibana 是麋鹿栈的最终元素。它在 Elasticsearch 之上提供了一种更简单的查询语言。即使您可以使用 Kibana 查询和可视化不同类型的数据，但它主要集中在日志上。

与 ELK 堆栈的其余部分一样，它目前是可视化日志的事实上的标准。

#### Grafana

Grafana 是另一个数据可视化工具。直到最近，它主要集中在性能指标的时间序列数据上。但是，随着 Loki 的引入，它现在也可能用于日志。

它的优势之一是它的构建考虑了可插拔的后端，因此很容易切换存储以满足您的需求。

## 监控

监控是从系统中收集与性能相关的指标的过程。与警报配合使用时，监视可帮助我们了解系统何时按预期运行以及何时发生事件。

我们最感兴趣的三种指标如下:

*   可用性，这使我们知道哪些资源已启动并正在运行，哪些资源已崩溃或无响应。
*   资源利用率使我们深入了解了工作负载如何适应系统。
*   性能，这向我们展示了在哪里以及如何提高服务质量。

监控的两种模式是推拉。在前者中，每个受监视的对象 (机器，应用程序和网络设备) 都会定期将数据推送到中心点。在后者中，对象在配置的端点处显示数据，并且监视代理定期抓取数据。

拉动模型使其更易于扩展。这样，多个对象就不会阻塞监视代理连接。相反，多个代理可以在准备就绪时收集数据，从而更好地利用可用资源。

具有 C 客户端库功能的两个监视解决方案是 Prometheus 和 InfluxDB。Prometheus 是基于拉的模型的示例，它专注于收集和存储时间序列数据。InfluxDB 默认使用推送模型。除了监控之外，它在物联网，传感器网络和家庭自动化中也很受欢迎。

Prometheus 和 InfluxDB 通常与 Grafana 一起用于可视化数据和管理仪表板。两者都内置了警报，但也可以通过 Grafana 与外部警报系统集成。

## 追踪

跟踪提供的信息通常比事件日志的信息低。另一个重要的区别是，跟踪存储每个事务的 ID，因此很容易可视化整个工作流。此 ID 通常称为跟踪 ID、事务 ID 或相关 ID。

与事件日志不同，跟踪并不意味着是人类可读的。它们由示踪剂处理。在实现跟踪时，需要使用与系统的所有可能元素集成的跟踪解决方案: 前端应用程序，后端应用程序和数据库。这样，追踪有助于查明性能滞后的确切原因。

### 开放跟踪

分布式跟踪的标准之一是 OpenTracing。该标准是由开源跟踪器之一 Jaeger 的作者提出的。

除了 Jaeger 之外，OpenTracing 还支持许多不同的跟踪器，并且它支持许多不同的编程语言。最重要的包括以下内容:

*   走
*   C
*   C #
*   Java
*   JavaScript
*   目标-C
*   PHP
*   蟒蛇
*   红宝石

OpenTracing 最重要的特性是它与供应商无关。这意味着，一旦我们检测了我们的应用程序，我们就不需要修改整个代码库来切换到不同的跟踪器。这样，它可以防止供应商锁定。

### 耶格

Jaeger 是一种示踪剂，可以与各种后端一起使用，包括 Elasticsearch，Cassandra 和 Kafka。

它与 OpenTracing 本机兼容，这并不奇怪。由于它是一个云计算基础毕业的项目，它有很好的社区支持，这也转化为与其他服务和框架的良好集成。

### OpenZipkin

OpenZipkin 是 Jaeger 的主要竞争对手。它已经在市场上销售了更长的时间。尽管这应该意味着它是一个更成熟的解决方案，但与 Jaeger 相比，它的受欢迎程度正在逐渐减弱。特别是，OpenZipkin 中的 C 没有积极维护，这可能会导致将来的维护问题。

## 集成可观测性解决方案

如果您不想自己构建可观察性层，则可能会考虑一些流行的商业解决方案。它们都以软件即服务模式运行。我们在这里不做详细的比较，因为他们的供品在本书撰写后可能会发生巨大的变化。

这些服务如下:

*   Datadog
*   Splunk
*   蜂窝

在本节中，您已经看到了在微服务中实现可观察性。接下来，我们将继续学习如何连接微服务。

# 连接微服务

微服务之所以如此有用，是因为它们可以以许多不同的方式与其他服务连接，从而创造新的价值。但是，由于没有微服务的标准，因此没有一种连接到它们的方法。

这意味着大多数时候，当我们想要使用特定的微服务时，我们必须学习如何与之交互。好消息是，尽管可以在微服务中实现任何通信方法，但大多数微服务都遵循一些流行的方法。

如何连接微服务只是围绕它们设计架构时的相关问题之一。另一个是连接什么和在哪里。这就是服务发现发挥作用的地方。通过服务发现，我们让微服务使用自动方法来发现和连接到应用程序中的其他服务。

这三个问题，如何、什么、在哪里，将是我们的下一个话题。我们将介绍现代微服务使用的一些最流行的通信和发现方法。

## 应用程序编程接口 (api)

就像软件库一样，微服务经常会暴露 api。这些 api 使得与微服务通信成为可能。由于典型的通信方式利用计算机网络，因此最流行的 API 形式是 web API。

在上一章中，我们已经介绍了 web 服务的一些可能方法。如今，微服务通常使用基于**表示状态转移** (**REST**) 的 web 服务。

## 远程过程调用

尽管诸如 REST 之类的 web api 允许轻松调试和出色的互操作性，但与数据转换和使用 HTTP 进行传输有关的开销很大。

对于某些微服务而言，这种开销可能太大，这就是轻量级**远程过程调用** (**RPCs**) 的原因。

### 阿帕奇节俭

Apache Thrift 是一种接口描述语言和二进制通信协议。它被用作 RPC 方法，允许创建以多种语言构建的分布式和可扩展服务。

它支持几种二进制协议和传输方法。本机数据类型用于每种编程语言，因此即使在现有的代码库中也很容易引入。

### gRPC

如果你真的关心性能，通常你会发现基于文本的解决方案对你不起作用。休息，无论多么优雅和容易理解，对于你的需求来说可能太慢了。如果是这种情况，您应该尝试围绕二进制协议构建您的 API。其中一个越来越受欢迎的是 gRPC。

gRPC，顾名思义，是一种最初由 Google 开发的 RPC 系统。它使用 HTTP/2 进行传输，并使用协议缓冲区作为**接口描述语言** (**IDL**)，用于多种编程语言之间的互操作性，以及用于数据序列化。可以为此使用替代技术，例如 FlatBuffers。gRPC 可以同步和异步方式使用，并允许创建简单服务和流式服务。

假设您已经决定使用`protobufs`，我们的 Greeter 服务定义可以是这样的:

```
service Greeter {
 rpc Greet(GreetRequest) returns (GreetResponse);
}

message GreetRequest {
 string name = 1;
}

message GreetResponse {
 string reply = 1;
}
```

使用`protoc`编译器，您可以从此定义创建数据访问代码。假设您希望为我们的迎宾员拥有一个同步服务器，则可以通过以下方式创建服务:

```
class Greeter : public Greeter::Service {
  Status sendRequest(ServerContext *context, const GreetRequest 
*request,
                     GreetReply *reply) override {
    auto name = request->name();
    if (name.empty()) return Status::INVALID_ARGUMENT;
    reply->set_result("Hello " + name);
    return Status::OK;
  }
};
```

然后，您必须为它构建并运行服务器:

```
int main() {
  Greeter service;
  ServerBuilder builder;
  builder.AddListeningPort("localhost", grpc::InsecureServerCredentials());
  builder.RegisterService(&service);

  auto server(builder.BuildAndStart());
  server->Wait();
}
```

就这么简单。现在让我们看一下使用此服务的客户端:

```
  #include <grpcpp/grpcpp.h>

  #include <string>

  #include "grpc/service.grpc.pb.h"

  using grpc::ClientContext;
  using grpc::Status;

  int main() {
    std::string address("localhost:50000");
    auto channel =
        grpc::CreateChannel(address, grpc::InsecureChannelCredentials());
    auto stub = Greeter::NewStub(channel);

    GreetRequest request;
    request.set_name("World");

    GreetResponse reply;
    ClientContext context;
    Status status = stub->Greet(&context, request, &reply);

    if (status.ok()) {
      std::cout << reply.reply() << '\n';
    } else {
      std::cerr << "Error: " << status.error_code() << '\n';
    }
  }
```

这是一个简单的同步示例。要使其异步工作，您需要添加标签和`CompletionQueue`，如 gRPC 网站上所述。

gRPC 的一个有趣的功能是它可用于 Android 和 iOS 上的移动应用程序。这意味着，如果您在内部使用 gRPC，则不必提供额外的服务器来转换来自移动应用程序的流量。

在本节中，您将学习微服务使用的最流行的通信和发现方法。接下来，我们将看到如何扩展微服务。

# 扩展微服务

微服务的一个重要好处是，它们比整片更有效地扩展。在相同的硬件基础架构下，从理论上讲，您可以从微服务中获得比 monoliths 更高的性能。

实际上，好处并不那么简单。微服务和相关助手还提供了开销，对于较小规模的应用程序，其性能可能低于最佳整体。

请记住，即使 “在纸上” 看起来不错，也并不意味着它会飞。如果要将架构决策基于可伸缩性或性能，则最好准备计算和实验。这样，你就会根据数据来行动，而不仅仅是情绪。

## 每个主机部署扩展单个服务

对于每个主机部署的单个服务，扩展微服务需要添加或删除托管微服务的其他计算机。如果您的应用程序在云架构 (公共或私有) 上运行，则许多提供商会提供称为自动缩放组的概念。

自动缩放组定义将在所有分组实例上运行的基本虚拟机映像。只要达到临界阈值 (例如，80% CPU 使用)，就会创建一个新实例并将其添加到组中。由于自动缩放组在负载平衡器后面运行，因此增加的流量将在现有实例和新实例之间分配，从而减少了每个实例的平均负载。当流量激增消退时，缩放控制器会关闭多余的机器，以保持低成本。

不同的度量可以充当缩放事件的触发器。CPU 负载是最容易使用的负载之一，但可能不是最准确的负载。其他指标 (例如队列中的消息数量) 可能更适合您的应用程序。

这是 scaler 策略的 Terraform 配置的摘录:

```
autoscaling_policy {
    max_replicas = 5
    min_replicas = 3

    cooldown_period = 60

    cpu_utilization {
      target = 0.8
    }
}
```

这意味着在任何给定时间，将至少有三个实例在运行，最多有五个实例。一旦 CPU 负载达到所有组实例的至少 80% 平均值，缩放器将触发。发生这种情况时，将启动一个新实例。新机器运行至少 60 秒 (冷却时间) 后，才会收集新机器的指标。

## 每个主机部署扩展多个服务

这种扩展模式也适用于每个主机部署的多个服务。正如你可能想象的那样，这不是最有效的方法。仅基于单个服务的减少吞吐量来扩展整个服务集，类似于扩展 monoliths。

如果您正在使用此模式，则扩展微服务的更好方法是使用 orchestrator。如果您不想使用容器，Nomad 是一个很好的选择，可以与许多不同的执行驱动程序一起使用。对于容器化的工作负载，Docker Swarm 或 Kubernetes 都会为您提供帮助。编排器是我们将在接下来的两章中再次讨论的主题。

# 摘要

微服务是软件体系结构的新趋势。只要您确保了解危害并做好准备，它们可能会很合适。本章解释了有助于引入微服务的通用设计和迁移模式。我们还涵盖了高级主题，例如可观察性和连接性，这些主题在建立基于微服务的体系结构时至关重要。

到目前为止，您应该能够将应用程序设计并分解为单个微服务。然后，每个微服务都能够处理单个工作负载。

虽然微服务本身是有效的，但它们与容器结合起来特别受欢迎。容器是下一章的主题。

# 问题

1.  为什么微服务可以帮助您更好地利用系统资源？
2.  微服务和巨石如何共存 (在一个不断发展的系统中)？
3.  哪些类型的团队从微服务中受益最大？
4.  为什么在引入微服务时，必须有一个成熟的 DevOps 方法？
5.  什么是统一日志记录层？
6.  日志记录和跟踪有什么不同？
7.  为什么 REST 不是连接微服务的最佳选择？
8.  微服务的部署策略是什么？他们每个人的好处是什么？

# 进一步阅读

*   *Mastering Distributed Tracing* : [https://www.packtpub.com/product/ mastering-distributed-tracing/9781788628464](https://www.packtpub.com/product/mastering-distributed-tracing/9781788628464)
*   *使用 Kubernetes 的动手微服务*: [https://www.packtpub.com/product/ 使用 kubernetes 的动手微服务/9781789805468](https://www.packtpub.com/product/hands-on-microservices-with-kubernetes/9781789805468)
*   马丁·福勒的*微服务*: [https://martinfowler.com/articles/microservices.html](https://martinfowler.com/articles/microservices.html)
*   微服务架构: [https://microservices.io/](https://microservices.io/)