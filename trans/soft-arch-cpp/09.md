Continuous Integration and Continuous Deployment

在前面的关于构建和包装的章节中，我们了解了我们的应用程序可以使用的不同构建系统和不同的包装系统。**持续集成** (**CI**) 和**持续部署** (**CD**) 使我们能够利用构建和包装的知识来提高服务质量和我们正在开发的应用程序的健壮性。

CI 和 CD 都依赖于良好的测试覆盖率。CI 主要使用单元测试和集成测试，而 CD 更多地依赖于烟雾测试和端到端测试。您在[第 8 章](08.html)，*编写可测试代码*中详细了解了测试的不同方面。有了这些知识，您就可以构建 CI/CD 管道了。

在本章中，我们将介绍以下主题:

*   理解 CI
*   审查代码更改
*   探索测试驱动自动化
*   作为代码管理部署
*   建筑部署代码
*   建立 CD 管道
*   使用不可变的基础设施

# 技术要求

本章的示例代码可在[https://github.com/PacktPublishing/ Software-Architecture-w 同-Cpp/tree/master/Chapter09](https://github.com/PacktPublishing/Software-Architecture-with-Cpp/tree/master/Chapter09)找到。

要理解本章中解释的概念，您需要进行以下安装:

*   免费 GitLab 帐户
*   Ansible 版本 2.8
*   Terraform 版本 0.12
*   Packer version 1.4

# 理解 CI

CI 是缩短集成周期的过程。在传统软件中，许多不同的功能可以单独开发，并且只能在发布之前进行集成，而在使用 CI 开发的项目中，集成一天可以进行几次。通常，开发人员进行的每个更改都在提交到中央存储库的同时进行测试和集成。

由于测试是在开发之后进行的，因此反馈循环要快得多。这使开发人员可以更轻松地修复错误 (因为他们通常仍然记得更改的内容)。与发布前的传统测试方法相比，CI 节省了大量工作并提高了软件质量。

## 提前发布，经常发布

你听过 “放早，放常” 的说法吗？这是一种强调发布周期短的重要性的软件开发理念。反过来，较短的发布周期在计划，开发和验证之间提供了更短的反馈循环。当某物破裂时，应尽早破裂，以使修复问题的成本相对较小。

埃里克·雷蒙德 (Eric S. Raymond) (也称为 ESR) 在他的 1997 论文《*大教堂和集市*中推广了这种哲学。还有一本同名的书，其中包含作者的这篇文章和其他文章。考虑到 ESR 在开源运动中的活动，“尽早发布，经常发布” 的口头禅成为开源项目运作方式的代名词。

几年后，同样的原则超越了开源项目。随着人们对敏捷方法 (例如 Scrum) 的兴趣日益浓厚，“提前发布，经常发布” 的口头禅成为以产品增量结束的开发冲刺的代名词。当然，这个增量是一个软件版本，但是通常，在 sprint 期间还会发生许多其他版本。

您如何实现如此短的发行周期？一个答案是尽可能依赖自动化。理想情况下，对代码存储库的每个提交都应以发行版的方式结束。此版本是否最终面对客户是另一回事。重要的是，每次代码更改都可以产生可用的产品。

当然，对于任何开发人员来说，向公众构建和发布每一项承诺都是一项乏味的工作。即使一切都是照本宣科的，这也会给通常的琐事增加不必要的开销。这就是为什么您希望设置一个 CI 系统来为您和您的开发团队自动化发布。

## CI 的优点

CI 是整合几个开发人员的工作的概念，至少是每天。正如已经讨论过的，有时它可能意味着一天几次。进入存储库的每个提交都是单独集成和验证的。生成系统检查代码是否可以生成而没有错误。打包系统可以创建一个包，该包准备保存为工件，或者甚至在以后使用 CD 时部署。最后，自动测试检查是否没有发生与更改相关的已知回归。现在让我们详细看看它的优点:

*   CI 可以快速解决问题。如果其中一个开发人员在行尾忘记了分号，则 CI 系统上的编译器将在该错误代码到达其他开发人员之前立即捕获该错误，从而阻碍了他们的工作。当然，开发人员应始终在提交代码之前构建更改并对其进行测试，但是在开发人员的计算机上可能会忽略较小的错别字，并且无论如何都会进入共享存储库。
*   使用 CI 的另一个好处是，它可以防止常见的 “在我的机器上工作” 的借口。如果开发人员忘记提交必要的文件，则 CI 系统将无法构建更改，从而再次阻止更改进一步传播并对整个团队造成恶作剧。一个开发人员环境的特殊配置也不再是一个问题。如果更改建立在两台机器上，即开发人员的计算机和 CI 系统，我们可以肯定地认为它也应该建立在其他机器上。

## 门控机制

如果我们希望 CI 为我们带来超越简单构建软件包的价值，我们需要一种门控机制。这种门控机制将使我们能够从不良代码中识别出良好的代码更改，从而使我们的应用程序免受修改的影响。为此，我们需要一套全面的测试。这样的套件使我们能够自动识别更改是否有问题，并且我们能够快速完成更改。

对于单个组件，单元测试起着门控机制的作用。CI 系统可以丢弃任何未通过单元测试的更改或未达到特定代码覆盖率阈值的任何更改。在构建单个组件时，CI 系统还可以使用集成测试来进一步确保更改是稳定的，不仅可以自己进行，而且可以正确地一起进行操作。

## 使用 GitLab 实现管道

在本章中，我们将使用流行的开源工具来构建完整的 CI/CD 管道，该管道包括门控机制，自动化部署以及基础架构自动化的概念。

第一个这样的工具是 GitLab。您可能听说过它作为 Git 托管解决方案，但实际上，它远远不止这些。GitLab 有几个发行版，即:

*   您可以在自己的场所托管的开源解决方案
*   自托管付费版本，在开源社区版本上提供其他功能
*   最后，在[https://gitlab.com](https://gitlab.com)下托管的**软件即服务** (**SaaS**托管报价

对于本书的要求，每个发行版都具有所有必要的功能。因此，我们将专注于 SaaS 版本，因为这需要最少的准备。

尽管[https://gitlab.com](https://gitlab.com)主要针对开源项目，但如果您不想与全世界共享您的工作，也可以创建私有项目和存储库。这使我们能够在 GitLab 中创建一个新的私有项目，并使用我们已经在[第 7 章](07.html)，*构建和打包*中演示过的代码填充它。

许多现代 CI/CD 工具可以代替 GitLab CI/CD 工作。例子包括 GitHub 动作、Travis CI、CircleCI 和 Jenkins。我们选择了 GitLab，因为它可以在 SaaS 形式和内部部署中使用，因此应该容纳许多不同的用例。

然后，我们将使用以前的构建系统在 GitLab 中创建简单的 CI 管道。这些管道在 YAML 文件中描述为一系列步骤和元数据。一个示例管道构建所有需求，以及来自[第 7 章](07.html)，*构建和包装*的示例项目，如下所示:

```cpp
# We want to cache the conan data and CMake build directory
cache:
  key: all
  paths:
    - .conan
    - build

# We're using conanio/gcc10 as the base image for all the subsequent commands
default:
  image: conanio/gcc10

stages:
  - prerequisites
  - build

before_script:
  - export CONAN_USER_HOME="$CI_PROJECT_DIR"

# Configure conan
prerequisites:
  stage: prerequisites
  script:
    - pip install conan==1.34.1
    - conan profile new default || true
    - conan profile update settings.compiler=gcc default
    - conan profile update settings.compiler.libcxx=libstdc++11 default
    - conan profile update settings.compiler.version=10 default
    - conan profile update settings.arch=x86_64 default
    - conan profile update settings.build_type=Release default
    - conan profile update settings.os=Linux default
    - conan remote add trompeloeil https://api.bintray.com/conan/trompeloeil/trompeloeil || true

# Build the project
build:
  stage: build
  script:
    - sudo apt-get update && sudo apt-get install -y docker.io
    - mkdir -p build
    - cd build
    - conan install ../ch08 --build=missing
    - cmake -DBUILD_TESTING=1 -DCMAKE_BUILD_TYPE=Release ../ch08/customer
    - cmake --build .
```

将上述文件保存为 Git 存储库的根目录中的`.gitlab-ci.yml`将自动启用 GitLab 中的 CI，并在随后的每次提交中运行管道。

# 审查代码更改

代码审查既可以与 CI 系统一起使用，也可以不使用它们。他们的主要目的是仔细检查代码中引入的每个更改，以确保它是正确的，它符合应用程序的体系结构，并遵循项目的准则和最佳实践。

在没有 CI 系统的情况下使用时，通常是审阅者的任务是手动测试更改并验证其是否按预期工作。CI 减轻了这种负担，让软件开发人员专注于代码的逻辑结构。

## 自动门控机制

自动化测试只是门控机制的一个例子。当它们的质量足够高时，它们可以保证代码根据设计工作。但是，正确工作的代码与良好的代码之间仍然存在差异。到目前为止，正如你从本书中学到的那样，如果代码满足几个值，它可以被认为是好的。功能正确只是其中之一。

还有其他工具可以帮助您实现所需的代码库标准。前几章已经介绍了其中的一些内容，因此我们不再赘述。请记住，在 CI/CD 管道中使用短绒、代码格式化器和静态分析是一个很好的做法。虽然静态分析可以充当门控机制，但您可以对进入中央存储库的每个提交应用 linting 和格式化，以使其与代码库的其余部分保持一致。你会在附录中找到更多关于短绒和格式化器的信息。

理想情况下，这种机制只需要检查代码是否已经格式化，因为格式化步骤应该由开发人员在将代码推送到存储库之前完成。当使用 Git 作为版本控制系统时，Git Hooks 的机制可以防止提交代码，而无需在其上运行必要的工具。

但是自动分析只能让你走到这一步。您可以检查代码在功能上是否完整，没有已知的错误和漏洞，并且符合编码标准。这是手动检查的地方。

## 代码审查-手动门控机制

对代码更改的手动检查通常称为代码审查。代码审查的目的是识别问题，包括特定子系统的实现和对应用程序整体体系结构的遵守。自动性能测试可能会或可能不会发现给定功能的潜在问题。而人眼通常能发现问题的次优解。无论是错误的数据结构还是计算复杂度不必要的高算法，一个好的架构师都应该能够查明问题所在。

但执行代码审查不仅仅是架构师的角色。同行评审，即作者的同行进行的代码评审，也在开发过程中占有一席之地。这样的评论是有价值的，不仅仅是因为它们允许同事在彼此的代码中发现错误。更重要的方面是，许多队友突然意识到其他人在做什么。这样，当团队中有缺席 (无论是因为长时间的会议、假期还是工作轮换) 时，另一名团队成员可以代替失踪的人。即使他们不是该主题的专家，其他每个成员至少都知道有趣的代码在哪里，每个人都应该能够记住代码的最后更改。这既意味着它们发生的时间，也意味着这些变化的范围和内容。

随着更多的人意识到应用程序内部是如何出现的，他们也更有可能找出一个组件的最新变化与一个新发现的错误之间的相关性。即使您团队中的每个人都可能有不同的经验，但当每个人都完全了解代码时，他们可以集中资源。

因此，代码审查可以检查更改是否适合所需的体系结构以及其实现是否正确。我们称这样的代码审查为架构审查，或专家审查。

另一种类型的代码审查，即同行审查，不仅有助于发现错误，还可以提高团队内部对其他成员正在做什么的认识。如有必要，在处理与外部服务集成的更改时，您还可以执行不同类型的专家审查。

由于每个接口都是潜在问题的根源，因此应将接近接口级别的更改视为特别危险。我们建议您用来自界面另一端的专家来补充通常的同行评审。例如，如果您正在编写生产者的代码，请消费者进行审查。这样，您可以确保不会错过一些您可能认为不太可能的重要用例，但另一方会不断使用。

## 代码审查的不同方法

您通常会异步进行代码审查。这意味着所审查的更改的作者与审阅者之间的交流不会实时发生。相反，每个参与者都在任何给定时间发布他们的评论和建议。一旦没有更多评论，作者将对原始更改进行重新设计，并再次对其进行审查。这可以需要尽可能多的回合，直到每个人都同意不需要进一步的更正。

当更改特别有争议并且异步代码审查花费太多时间时，同步进行代码审查是有益的。这意味着召开一次会议 (面对面或远程)，以解决对前进道路的任何反对意见。尤其是当更改由于在实施更改时获得的新知识而与初始决策之一相矛盾时，就会发生这种情况。

有一些专门针对代码审查的工具。通常，您会希望使用存储库服务器中内置的工具，该工具包括以下服务:

*   GitHub
*   比特桶
*   GitLab
*   格里特

以上所有内容都提供 Git 托管和代码审查。他们中的一些人走得更远，提供了一个完整的 CI/CD 管道、问题管理、维基等等。

当您使用代码托管和代码审查的组合包时，默认工作流程是将更改作为单独的分支推送，然后要求项目的所有者在称为拉取请求 (或合并请求) 的过程中合并更改。尽管名称精美，但拉取请求或合并请求会通知项目所有者您有希望与主分支合并的代码。这意味着审阅者应该审阅您的更改，以确保一切正常。

## 使用拉取请求 (合并请求) 进行代码审查

创建拉取请求或将请求与 GitLab 等系统合并非常容易。首先，当我们从命令行将新分支推送到中央存储库时，我们可以观察到以下消息:

```cpp
remote:
remote: To create a merge request for fix-ci-cd, visit:
remote:   https://gitlab.com/hosacpp/continuous-integration/merge_requests/new?merge_request%5Bsource_branch%5D=fix-ci-cd
remote:                         
```

如果您以前启用了 CI (通过添加`.gitlab-ci.yml`文件)，您还将看到新推送的分支已经历 CI 过程。这甚至在您打开合并请求之前就会发生，这意味着您可以推迟标记您的同事，直到您从 CI 获得每个自动检查都已通过的信息。

打开合并请求的两种主要方法如下:

*   通过按照推送消息中提到的链接
*   通过导航到 GitLab UI 中的合并请求并选择创建合并请求按钮或新合并请求按钮

当您提交合并请求时，完成所有相关字段后，您将看到 CI 管道的状态也是可见的。如果管道失败，则无法合并更改。

# 探索测试驱动自动化

CI 主要集中在整合部分。这意味着构建不同子系统的代码，并确保它们协同工作。虽然不严格要求测试来实现这一目的，但在没有测试的情况下运行 CI 似乎是一种浪费。没有自动测试的 CI 可以更轻松地将细微的错误引入代码，同时给人一种错误的安全感。

这就是为什么 CI 经常与持续测试齐头并进的原因之一，我们将在下一节中介绍。

## 行为驱动的发展

到目前为止，我们已经设法建立了一条可以称为连续建设的管道。我们对代码所做的每一次更改最终都会被编译，但是我们不再对其进行进一步测试。现在是时候介绍连续测试的做法了。低级别的测试还将充当一种门控机制，以自动拒绝所有不满足要求的更改。

如何检查给定的变更是否满足要求？最好通过根据这些要求编写测试来实现。方法之一是遵循**行为驱动开发** (**BDD**)。BDD 的概念是鼓励敏捷项目中不同参与者之间更深层次的协作。

与传统方法不同，在传统方法中，测试由开发人员或 QA 团队使用 BDD 编写，测试由以下人员协作创建:

*   开发人员
*   质量保证工程师
*   业务代表。

为 BDD 指定测试的最常见方法是使用 Cucumber 框架，该框架使用简单的英语短语来描述系统任何部分的期望行为。这些句子遵循特定的模式，然后可以将其转换为工作代码，并与选择的测试框架集成在一起。

Cucumber 框架中有对 C 的官方支持，它基于 c 制造，Boost，GTest 和 GMock。在用 cucumber 格式 (使用一种称为 Gherkin 的特定于域的语言) 指定所需的行为之后，我们还需要提供所谓的步骤定义。步骤定义是与 cucumber 规范中描述的操作相对应的实际代码。例如，考虑以下用小黄瓜表达的行为:

```cpp
# language: en
Feature: Summing
In order to see how much we earn,
Sum must be able to add two numbers together

Scenario: Regular numbers
  Given I have entered 3 and 2 as parameters
  When I add them
  Then the result should be 5
```

我们可以将其保存为`sum.feature`文件。为了用测试生成有效的 C 代码，我们将使用适当的步骤定义:

```cpp
#include <gtest/gtest.h>
#include <cucumber-cpp/autodetect.hpp>

#include <Sum.h>

using cucumber::ScenarioScope;

struct SumCtx {
  Sum sum;
  int a;
  int b;
  int result;
};

GIVEN("^I have entered (\\d+) and (\\d+) as parameters$", (const int a, const int b)) {
    ScenarioScope<SumCtx> context;

    context->a = a;
    context->b = b;
}

WHEN("^I add them") {
    ScenarioScope<SumCtx> context;

    context->result = context->sum.sum(context->a, context->b);
}

THEN("^the result should be (.*)$", (const int expected)) {
    ScenarioScope<SumCtx> context;

    EXPECT_EQ(expected, context->result);
}
```

从头开始构建应用程序时，遵循 BDD 模式是一个好主意。本书旨在展示您可以在这样的绿地项目中使用的最佳实践。但这并不意味着您不能在现有项目中尝试我们的示例。可以在项目生命周期内的任何给定时间添加 CI 和 CD。由于尽可能频繁地运行测试总是一个好主意，因此仅出于连续测试的目的使用 CI 系统几乎总是一个好主意。

如果您没有行为测试，则无需担心。您可以稍后添加它们，目前，只需专注于您已经拥有的那些测试。无论是单元测试还是端到端测试，任何可以帮助您评估应用程序状态的东西都是门控机制的良好候选者。

## CI 的编写测试

对于 CI，最好关注单元测试和集成测试。它们在尽可能低的水平上工作，这意味着它们通常执行速度快，需求最小。理想情况下，所有单元测试都应该是自包含的 (没有像工作数据库那样的外部依赖关系)，并且能够并行运行。这样，当问题出现在单元测试能够捕获它的级别上时，违规代码将在几秒钟内被标记出来。

有些人说单元测试只在解释语言或具有动态打字的语言中有意义。论点是，C 已经通过类型系统和编译器检查错误代码内置了测试。虽然类型检查确实可以捕获一些需要使用动态类型语言进行单独测试的错误，但这不应该被用作不编写单元测试的借口。毕竟，单元测试的目的不是验证代码是否可以毫无问题地执行。我们编写单元测试，以确保我们的代码不仅可以执行，而且可以满足我们所有的业务需求。

作为一个极端的例子，看看下面的两个函数。两者在语法上都是正确的，并且使用适当的打字。但是，仅通过查看它们，您可能就可以猜测哪个是正确的，哪个不是。单元测试有助于捕捉这种不当行为:

```cpp
int sum (int a, int b) {
 return a+b;
}
```

前面的函数返回提供的两个参数的和。下面的一个只返回第一个参数的值:

```cpp
int sum (int a, int b) {
  return a;
}
```

即使类型匹配并且编译器不会抱怨，此代码也不会执行其任务。为了区分有用的代码和错误的代码，我们使用测试和断言。

## 连续测试

已经建立了一个简单的 CI 管道，通过测试扩展它非常容易。由于我们已经在构建和测试过程中使用 cmado 和 CTest，因此我们需要做的就是在执行测试的管道中添加另一个步骤。这一步可能看起来像这样:

```cpp
# Run the unit tests with ctest
test:
  stage: test
  script:
    - cd build
    - ctest .
```

因此，整个管道将显示如下:

```cpp
cache:
  key: all
  paths:
    - .conan
    - build

default:
  image: conanio/gcc9

stages:
  - prerequisites
  - build
 - test # We add another stage that tuns the tests

before_script:
  - export CONAN_USER_HOME="$CI_PROJECT_DIR"

prerequisites:
  stage: prerequisites
  script:
    - pip install conan==1.34.1
    - conan profile new default || true
    - conan profile update settings.compiler=gcc default
    - conan profile update settings.compiler.libcxx=libstdc++11 default
    - conan profile update settings.compiler.version=10 default
    - conan profile update settings.arch=x86_64 default
    - conan profile update settings.build_type=Release default
    - conan profile update settings.os=Linux default
    - conan remote add trompeloeil https://api.bintray.com/conan/trompeloeil/trompeloeil || true

build:
  stage: build
  script:
    - sudo apt-get update && sudo apt-get install -y docker.io
    - mkdir -p build
    - cd build
    - conan install ../ch08 --build=missing
    - cmake -DBUILD_TESTING=1 -DCMAKE_BUILD_TYPE=Release ../ch08/customer
    - cmake --build .

# Run the unit tests with ctest
test:
 stage: test
 script:
 - cd build
 - ctest .
```

这样，每个提交不仅会受到构建过程的影响，还会受到测试。如果其中一个步骤失败，我们将被通知哪个步骤是失败的根源，我们可以在仪表板中看到哪些步骤成功。

# 作为代码管理部署

经过测试和批准的更改，现在是时候将它们部署到其中一个操作环境了。

有许多工具可以帮助部署。我们决定提供 Ansible 的示例，因为除了功能 Python 安装 (大多数 UNIX 系统已经有) 之外，这不需要在目标计算机上进行任何设置。为什么是 Ansible？它在配置管理领域非常流行，并且由值得信赖的开源公司 (Red Hat) 进行备份。

## 使用 Ansible

为什么不使用已经可用的东西，例如 Bourne shell 脚本或 PowerShell？对于简单的部署，shell 脚本可能是更好的方法。但是随着我们的部署过程变得更加复杂，使用 shell 的条件语句来处理每个可能的初始状态变得更加困难。

处理初始状态之间的差异实际上是 Ansible 特别擅长的事情。与使用命令式形式 (移动此文件，编辑该文件，运行特定命令) 的传统 shell 脚本不同，Ansible playbooks 在被称为 “声明式” 形式 (确保文件在此路径中可用，确保文件包含指定的行，确保程序正在运行，确保程序成功完成)。

这种声明性方法也有助于实现幂等性。幂等性是函数的特征，这意味着多次应用该函数将获得与单个应用完全相同的结果。如果 Ansible playbook 的第一次运行对配置进行了一些更改，则每次后续运行都将在所需状态下开始。这可以防止 Ansible 执行任何额外的更改。

换句话说，当您调用 Ansible 时，它将首先评估您希望配置的所有计算机的当前状态:

*   如果其中任何一项需要进行任何更改，则 Ansible 将仅运行达到所需状态所需的任务。
*   如果不需要修改特定的东西，Ansible 不会碰它。只有当期望状态和实际状态不同时，您才会看到 Ansible 采取行动将实际状态收敛到剧本内容所描述的期望状态。

## Ansible 如何与 CI/CD 管道相匹配

Ansible 的幂等性使其成为在 CI/CD 管道中使用的一个很好的目标。毕竟，即使两次运行之间没有任何变化，多次运行相同的 Ansible 剧本也没有风险。如果您将 Ansible 用于部署代码，则创建 CD 只是准备适当的验收测试 (例如冒烟测试或端到端测试) 的问题。

声明式方法可能需要改变您对部署的思考方式，但收益是值得的。除了运行 playbooks 之外，您还可以使用 Ansible 在远程计算机上执行一次性命令，但是我们不会介绍这个用例，因为它对部署没有真正的帮助。

你可以用一个 shell 做的一切，你可以用 Ansible 的`shell`模块做。这是因为，在 playbooks 中，您编写任务，指定它们使用的模块及其各自的参数。一个这样的模块是前面提到的`shell`模块，它简单地在远程机器上的外壳中执行提供的参数。但是，使 Ansible 不仅方便而且跨平台 (至少在涉及不同的 UNIX 发行版时) 的原因是模块的可用性，可以操纵诸如用户管理，包管理和类似实例之类的通用概念。

## 使用组件创建部署代码

除了标准库中提供的常规模块外，还存在允许代码重用的第三方组件。您可以单独测试此类组件，这也使您的部署代码更加健壮。这样的组件称为角色。它们包含一组任务，以使机器适合担任特定角色，例如`webserver`，`db`或`docker`。虽然有些角色为机器提供特定服务做准备，但其他角色可能更抽象，例如流行的`ansible-hardening`角色。这是由 OpenStack 团队创建的，这使得使用此角色进入安全的计算机变得更加困难。

当您开始了解 Ansible 使用的语言时，所有的剧本都不再只是脚本。反过来，它们将成为部署过程的文档。您可以通过运行 Ansible 逐字使用它们，也可以读取所描述的任务并手动执行所有操作，例如在脱机计算机上。

在您的团队中使用 Ansible 进行部署存在一个风险。一旦你开始使用它，你必须确保团队中的每个人都能够使用它并修改相关的任务。DevOps 是整个团队必须遵循的一种做法; 它不能仅部分实施。当应用程序的代码发生较大变化，需要在部署端进行适当的更改时，负责应用程序更改的人员也应提供部署代码中的更改。当然，这是您的测试可以验证的东西，因此门控机制可以拒绝不完整的更改。

Ansible 的一个值得注意的方面是，它可以在推和拉模型中运行:

*   推送模型是当您在自己的机器上或在 CI 系统中运行 Ansible 时。然后，Ansible 通过例如 SSH 连接连接到目标计算机，并在目标计算机上执行必要的步骤。
*   在拉动模型中，整个过程由目标机启动。Ansible 的组件`ansible-pull`直接在目标计算机上运行，并检查代码存储库以确定是否对特定分支进行了任何更新。刷新本地剧本后，Ansible 照常执行所有步骤。这一次，控制组件和实际执行都发生在同一台机器上。在大多数情况下，您将希望定期运行`ansible-pull`，例如，在 cron 作业中。

# 建筑部署代码

在最简单的形式中，使用 Ansible 进行部署可能包括将单个二进制文件复制到目标计算机，然后运行该二进制文件。我们可以通过以下 Ansible 代码来实现这一点:

```cpp
tasks:
  # Each Ansible task is written as a YAML object
  # This uses a copy module
  - name: Copy the binaries to the target machine
    copy:
      src: our_application
      dest: /opt/app/bin/our_application
  # This tasks invokes the shell module. The text after the `shell:` key
  # will run in a shell on target machine
  - name: start our application in detached mode
    shell: cd /opt/app/bin; nohup ./our_application </dev/null >/dev/null 2>&1 &
```

每一项任务都以连字符开始。对于每个任务，您需要指定其使用的模块 (例如`copy`模块或`shell`模块) 以及其参数 (如果适用)。任务也可能具有`name`参数，这使得单独引用任务变得更加容易。

# 建立 CD 管道

我们已经达到了可以使用本章中了解到的工具安全地构建 CD 管道的地步。我们已经知道 CI 是如何运作的，以及它如何帮助拒绝不适合发布的更改。关于测试自动化的部分提出了使拒绝过程更健壮的不同方法。通过烟雾测试或端到端测试，我们可以超越 CI，并检查整个部署的服务是否满足要求。有了部署代码，我们不仅可以自动化部署过程，还可以在测试开始失败时准备回滚。

## 持续部署和持续交付

巧合的是，缩写 CD 可以表示两种不同的含义。持续交付和持续部署的概念非常相似，但是它们有一些细微的区别。在整本书中，我们都在关注持续部署的概念。这是一个自动化过程，当一个人将更改推入中央存储库并完成更改成功部署到生产环境并通过所有测试时，该过程就开始了。因此，我们可以说这是一个端到端的过程，因为开发人员的工作在没有人工干预的情况下一直传到客户手中 (当然是在代码审查之后)。您可能听说过 GitOps 一词与这种方法有关。由于所有操作都是自动化的，因此推送到 Git 中的指定分支会触发部署脚本。

持续交付不会走那么远。与 CD 一样，它具有能够发布最终产品并对其进行测试的管道，但是最终产品永远不会自动交付给客户。它可以先交付给 QA，也可以交付给企业内部使用。理想情况下，一旦内部客户端接受交付的工件，就可以在生产环境中部署它。

## 构建示例 CD 管道

让我们再次使用 GitLab CI 作为示例来构建我们的管道，将所有这些技能放在一起。在测试步骤之后，我们将再添加两个步骤，一个步骤创建软件包，另一个步骤使用 Ansible 部署此软件包。

我们需要的包装步骤如下:

```cpp
# Package the application and publish the artifact
package:
  stage: package
  # Use cpack for packaging
  script:
    - cd build
    - cpack .
  # Save the deb package artifact
  artifacts:
    paths:
      - build/Customer*.deb
```

当我们添加包含工件定义的软件包步骤时，我们将能够从仪表板下载它们。

有了这个，我们可以调用 Ansible 作为部署步骤的一部分:

```cpp
# Deploy using Ansible
deploy:
  stage: deploy
  script:
    - cd build
    - ansible-playbook -i localhost, ansible.yml
```

最终的管道将如下所示:

```cpp
cache:
  key: all
  paths:
    - .conan
    - build

default:
  image: conanio/gcc9

stages:
  - prerequisites
  - build
  - test
 - package
 - deploy

before_script:
  - export CONAN_USER_HOME="$CI_PROJECT_DIR"

prerequisites:
  stage: prerequisites
  script:
    - pip install conan==1.34.1
    - conan profile new default || true
    - conan profile update settings.compiler=gcc default
    - conan profile update settings.compiler.libcxx=libstdc++11 default
    - conan profile update settings.compiler.version=10 default
    - conan profile update settings.arch=x86_64 default
    - conan profile update settings.build_type=Release default
    - conan profile update settings.os=Linux default
    - conan remote add trompeloeil https://api.bintray.com/conan/trompeloeil/trompeloeil || true

build:
  stage: build
  script:
    - sudo apt-get update && sudo apt-get install -y docker.io
    - mkdir -p build
    - cd build
    - conan install ../ch08 --build=missing
    - cmake -DBUILD_TESTING=1 -DCMAKE_BUILD_TYPE=Release ../ch08/customer
    - cmake --build .

test:
  stage: test
  script:
    - cd build
    - ctest .

# Package the application and publish the artifact
package:
 stage: package
 # Use cpack for packaging
 script:
 - cd build
 - cpack .
 # Save the deb package artifact
 artifacts:
 paths:
 - build/Customer*.deb

# Deploy using Ansible
deploy:
 stage: deploy
 script:
 - cd build
 - ansible-playbook -i localhost, ansible.yml
```

要查看整个示例，请从原始来源的*技术要求*部分转到存储库。

# 使用不可变的基础设施

如果您对 CI/CD 管道有足够的信心，则可以更进一步。您可以部署*系统*的工件，而不是部署应用程序的工件。有什么区别？我们将在以下各节中了解这一点。

## 什么是不可变的基础设施？

以前，我们专注于如何使应用程序的代码可在目标基础结构上部署。CI 系统创建了软件包 (例如容器)，然后这些软件包由 CD 进程部署。每次管道运行时，基础架构都保持不变，但软件有所不同。

关键是，如果你正在使用云计算，你可以像对待任何其他工件一样对待基础设施。您可以将整个**虚拟机** (**VM**) 部署为 AWS EC2 实例，而不是部署容器。您可以预先构建这样的 VM 映像，作为 CI 过程的另一个元素。这样，版本化的 VM 映像以及部署它们所需的代码就变成了您的工件，而不是容器本身。

HashiCorp 撰写的两种工具恰好处理了这种情况。Packer 有助于以可重复的方式创建 VM 映像，将所有指令存储为代码，通常以 JSON 文件的形式。Terraform 是作为代码工具的基础结构，这意味着它用于提供所有必要的基础结构资源。我们将使用 Packer 的输出作为 Terraform 的输入。这样，Terraform 将创建一个由以下组成的整个系统:

*   实例组
*   负载平衡器
*   VPCs
*   使用包含我们自己代码的虚拟机时的其他云元素

这一节的标题可能会让你感到困惑。为什么它被称为**不可变基础设施**而我们显然主张在每次提交后改变整个基础设施？如果您学习过函数语言，那么不变性的概念可能会更清晰。

可变对象是我们可以更改其状态的对象。在基础架构中，这很容易理解: 您可以登录虚拟机并下载最新版本的代码。状态不再与您干预之前相同。

不可变对象是我们无法更改其状态的对象。这意味着我们没有办法登录机器和改变东西。一旦我们从映像部署虚拟机，它就会保持这样的状态，直到我们销毁它。这听起来可能非常麻烦，但实际上，它解决了软件维护的一些问题。

## 不可变基础设施的好处

首先，不可变的基础设施使得配置漂移的概念过时。没有配置管理，因此也不会出现漂移。升级也要安全得多，因为我们不能最终处于半生不熟的状态。这是既不是以前的版本也不是下一个版本的状态，而是介于两者之间的状态。部署过程提供了二进制信息: 要么机器已创建并运行，要么没有。没有别的办法了。

为了使不可变的基础结构在不影响正常运行时间的情况下工作，您还需要以下内容:

*   负载平衡
*   一定程度的冗余

毕竟，升级过程包括关闭整个实例。你不能依赖这台机器的地址或任何特定于那台机器的东西。相反，您需要至少有第二个来处理工作负载，而您用更新的版本替换另一个。当你完成升级一台机器时，你可以用另一台重复同样的过程。这样，您将拥有两个升级的实例，而不会丢失服务。这种策略被称为滚动升级。

正如您可以从流程中意识到的那样，在处理无状态服务时，不可变的基础架构效果最好。当您的服务具有某种形式的持久性时，事情就变得很难正确实施。在这种情况下，通常必须将持久性级别拆分为一个单独的对象，例如，包含所有应用程序数据的 NFS 卷。这样的卷可以在实例组中的所有计算机上共享，并且出现的每台新计算机都可以访问先前运行的应用程序留下的公共状态。

## 使用 Packer 构建实例映像

考虑到我们的示例应用程序已经是无状态的，我们可以继续在其之上构建一个不可变的基础结构。由于工件打包程序生成的是 VM 映像，因此我们必须决定要使用的格式和构建器。让我们将我们的示例集中在 Amazon Web 服务上，同时要记住，类似的方法也可以与其他受支持的提供商一起使用。一个简单的 Packer 模板可能是这样的:

```cpp
{
  "variables": {
    "aws_access_key": "",
    "aws_secret_key": ""
  },
  "builders": [{
    "type": "amazon-ebs",
    "access_key": "{{user `aws_access_key`}}",
    "secret_key": "{{user `aws_secret_key`}}",
    "region": "eu-central-1",
    "source_ami": "ami-0f1026b68319bad6c",
    "instance_type": "t2.micro",
    "ssh_username": "admin",
    "ami_name": "Project's Base Image {{timestamp}}"
  }],
  "provisioners": [{
    "type": "shell",
    "inline": [
      "sudo apt-get update",
      "sudo apt-get install -y nginx"
    ]
  }]
}
```

前面的代码将使用 EBS 构建器为 Amazon Web 服务构建映像。该图像将驻留在`eu-central-1`区域，并将基于`ami-5900cc36`，这是 Debian Jessie 图像。我们希望构建器是一个`t2.micro`实例 (这是 AWS 中的 VM 大小)。为了准备我们的图像，我们运行两个`apt-get`命令。

我们还可以重用先前定义的 Ansible 代码，而不是使用 Packer 来配置我们的应用程序，我们可以代替 Ansible 作为配置器。我们的代码将显示如下:

```cpp
{
  "variables": {
    "aws_access_key": "",
    "aws_secret_key": ""
  },
  "builders": [{
    "type": "amazon-ebs",
    "access_key": "{{user `aws_access_key`}}",
    "secret_key": "{{user `aws_secret_key`}}",
    "region": "eu-central-1",
    "source_ami": "ami-0f1026b68319bad6c",
    "instance_type": "t2.micro",
    "ssh_username": "admin",
    "ami_name": "Project's Base Image {{timestamp}}"
  }],
  "provisioners": [{
 "type": "ansible",
 "playbook_file": "./provision.yml",
 "user": "admin",
 "host_alias": "baseimage"
 }],
 "post-processors": [{
 "type": "manifest",
 "output": "manifest.json",
 "strip_path": true
 }]
}
```

更改在`provisioners`块中，并且还添加了一个新块`post-processors`。这次，我们使用的不是 shell 命令，而是为我们运行 Ansible 的不同配置器。后处理器在这里以机器可读的格式产生构建的结果。一旦 Packer 完成构建所需的工件，它将返回其 ID 并将其保存在`manifest.json`中。对于 AWS，这将意味着一个 AMI ID，然后我们可以将其提供给 Terraform。

## 用 Terraform 协调基础设施

使用 Packer 创建图像是第一步。之后，我们想部署映像以使用它。我们可以使用 Terraform 基于 Packer 模板中的映像构建 AWS EC2 实例。

示例 Terraform 代码如下所示:

```cpp
# Configure the AWS provider
provider "aws" {
  region = var.region
  version = "~> 2.7"
}

# Input variable pointing to an SSH key we want to associate with the 
# newly created machine
variable "public_key_path" {
  description = <<DESCRIPTION
Path to the SSH public key to be used for authentication.
Ensure this keypair is added to your local SSH agent so provisioners can
connect.
Example: ~/.ssh/terraform.pub
DESCRIPTION

  default = "~/.ssh/id_rsa.pub"
}

# Input variable with a name to attach to the SSH key
variable "aws_key_name" {
  description = "Desired name of AWS key pair"
  default = "terraformer"
}

# An ID from our previous Packer run that points to the custom base image
variable "packer_ami" {
}

variable "env" {
  default = "development"
}

variable "region" {
}

# Create a new AWS key pair cotaining the public key set as the input 
# variable
resource "aws_key_pair" "deployer" {
  key_name = var.aws_key_name

  public_key = file(var.public_key_path)
}

# Create a VM instance from the custom base image that uses the previously created key
# The VM size is t2.xlarge, it uses a persistent storage volume of 60GiB,
# and is tagged for easier filtering
resource "aws_instance" "project" {
  ami = var.packer_ami

  instance_type = "t2.xlarge"

  key_name = aws_key_pair.deployer.key_name

  root_block_device {
    volume_type = "gp2"
    volume_size = 60
  }

  tags = {
    Provider = "terraform"
    Env = var.env
    Name = "main-instance"
  }
}
```

这将创建一个密钥对和一个使用此密钥对的 EC2 实例。EC2 实例基于作为变量提供的 AMI。在调用 Terraform 时，我们会将此变量设置为指向 Packer 生成的图像。

# 摘要

到现在为止，您应该已经了解了在项目开始时实施 CI 如何从长远来看可以帮助您节省时间。它还可以减少进行中的工作，尤其是与 CD 配对时。在本章中，我们介绍了有用的工具，可以帮助您实现这两个过程。

我们已经展示了 GitLab CI 如何允许我们在 YAML 文件中编写管道。我们已经讨论了代码审查的重要性，并解释了各种形式的代码审查之间的区别。我们介绍了 Ansible，它有助于配置管理和部署代码的创建。最后，我们尝试了 Packer 和 Terraform，将我们的重点从创建应用程序转移到创建系统。

本章的知识并非 c 语言独有。您可以在使用任何技术以任何语言编写的项目中使用它。您应该记住的重要一点是: 所有应用程序都需要测试。编译器或静态分析器不足以验证您的软件。作为一名架构师，你不仅要考虑你的项目 (应用程序本身)，还要考虑产品 (你的应用程序将在其中工作的系统)。交付工作代码已经不够了。了解基础架构和部署过程至关重要，因为它们是现代系统的新组成部分。

下一章重点介绍软件的安全性。我们将介绍源代码本身，操作系统级别以及与外部服务以及与最终用户的可能交互。

# 问题

1.  CI 在开发过程中以什么方式节省时间？
2.  您是否需要单独的工具来实现 CI 和 CD？
3.  什么时候在会议中执行代码审查有意义？
4.  在 CI 期间，您可以使用哪些工具来评估代码的质量？
5.  谁参与指定 BDD 方案？
6.  你什么时候会考虑使用不可变的基础设施？你什么时候能排除它？
7.  您如何描述 Ansible、Packer 和 Terraform 之间的差异？

# 进一步阅读

*   持续集成/持续部署/持续交付:

[https://www.packtpub.com/virtualization-and-cloud/hands-continuous-integration-and-delivery](https://www.packtpub.com/virtualization-and-cloud/hands-continuous-integration-and-delivery)

[https://www.packtpub.com/virtualization-and-cloud/cloud-native-continuous-integration-and-delivery](https://www.packtpub.com/virtualization-and-cloud/cloud-native-continuous-integration-and-delivery)

*   Ansible:

[https://www.packtpub.com/virtualization-and-cloud/mastering-ansible-third-edition](https://www.packtpub.com/virtualization-and-cloud/mastering-ansible-third-edition)

[https://www.packtpub.com/application-development/hands-infrastructure-automation-ansible-video](https://www.packtpub.com/application-development/hands-infrastructure-automation-ansible-video)

*   Terraform:

[https://www.packtpub.com/networking-and-servers/getting-started-terraform-second-edition](https://www.packtpub.com/networking-and-servers/getting-started-terraform-second-edition)

[https://www.packtpub.com/big-data-and-business-intelligence/hands-infrastructure-automation-terraform-aws-video](https://www.packtpub.com/big-data-and-business-intelligence/hands-infrastructure-automation-terraform-aws-video)

*   黄瓜:

[https://www.packtpub.com/web-development/cucumber-cookbook](https://www.packtpub.com/web-development/cucumber-cookbook)

*   GitLab:

[https://www.packtpub.com/virtualization-and-cloud/gitlab-quick-start-guide](https://www.packtpub.com/virtualization-and-cloud/gitlab-quick-start-guide)

[https://www.packtpub.com/application-development/hands-auto-devops-gitlab-ci-video](https://www.packtpub.com/application-development/hands-auto-devops-gitlab-ci-video)