Architectural and System Design

模式帮助我们处理复杂性。在单个软件组件的级别上，您可以使用软件模式，例如本书的四位作者所描述的软件模式 (更好地称为*四人帮*) *设计模式: 可重用的面向对象软件的元素*。当我们向上移动并开始查看不同组件之间的架构时，知道何时以及如何应用架构模式会走很长一段路。

对于不同的场景，有无数的这样的模式是有用的。事实上，要了解所有这些，你需要读的不仅仅是一本书。话虽如此，我们为本书选择了几种适合实现各种建筑目标的模式。

在本章中，我们将向您介绍一些与建筑设计相关的概念和谬误; 我们将展示何时使用上述模式，以及如何设计易于部署的高质量组件。

本章将介绍以下主题:

*   不同的服务模型以及何时使用它们
*   如何避免分布式计算的谬误
*   CAP 定理的结果以及如何实现最终的一致性
*   使您的系统容错和可用
*   集成您的系统
*   实现规模绩效
*   部署您的系统
*   管理您的 api

在本章结束时，您将了解如何设计体系结构，以提供几个重要的品质，如容错、可伸缩性和可部署性。在此之前，让我们先了解一下分布式架构的两个固有方面。

# 技术要求

本章的代码需要以下工具来构建和运行:

*   码头工人
*   Docker Compose

本章的源代码片段可以在[https://github.com/PacktPublishing/ Software-Architecture-w 同-Cpp/tree/master/Chapter04](https://github.com/PacktPublishing/Software-Architecture-with-Cpp/tree/master/Chapter04)找到。

# 了解分布式系统的特殊性

有许多类型的不同的软件系统，每种软件系统都适用于不同的场景，为不同的需求而构建，并使用不同的假设集。编写和部署经典的独立桌面应用程序与编写和部署需要通过网络与许多其他人通信的微服务完全不同。

在本节中，我们将介绍可用于部署软件的各种模型，人们在创建分布式系统时应避免的常见错误，以及人们成功创建此类系统需要做出的一些妥协。

## 不同的服务模式以及何时使用它们

让我们首先从服务模型开始。在设计更大的系统时，您需要决定您将管理多少基础架构，以及您可以在现有构建块上构建多少基础架构。有时，您可能希望利用现有软件，而无需手动部署应用程序或备份数据，例如，通过使用 Google Drive 通过其 API 作为应用程序的存储。其他时候，您可以依靠现有的云平台 (例如 Google 的 App Engine) 来部署解决方案，而无需担心提供语言运行时或数据库。如果您可以决定以自己的方式部署所有内容，则可以利用云提供商的基础架构，也可以使用公司的基础架构。

让我们讨论不同的模型，以及每个模型在哪里有用。

### 内部模型

经典的方式，也是云前时代唯一可用的方式，就是在自己的前提下部署所有内容。您需要购买所需的所有硬件和软件，并确保它将为您的需求提供足够的容量。如果你在一家初创公司工作，这可能是一笔不小的前期费用。随着用户群的增长，您需要购买和设置更多的资源，以便您的服务能够应对偶尔出现的负载峰值。所有这些意味着您需要预测解决方案的增长并主动采取行动，因为您无法根据当前负载自动扩展。

即使在云时代，部署本地部署仍然很有用，并且经常在野外发现。有时，由于数据隐私问题或合规性问题，您处理的数据不应该甚至不能离开公司的场所。其他时候，您需要尽可能少的延迟，并且需要自己的数据中心才能这样做。有时您可能会计算成本，并决定在您的情况下，内部部署将比云解决方案便宜。最后但并非最不重要的一点是，您的公司可能已经拥有了可以使用的现有数据中心。

部署内部部署并不意味着您需要一个整体系统。通常，公司会在内部部署自己的私有云。这有助于通过更好地利用可用基础设施来降低成本。您还可以将私有云解决方案与其他服务模型之一混合使用，当您不时需要额外的容量时，这可能会很有用。这被称为**混合部署**，由所有主要的云提供商以及 OpenStack 的 Omni 项目提供。

### 基础设施即服务 (IaaS) 模型

说到其他模型，最基本的云服务模型叫做**基础设施即服务** (**IaaS**)。它也与本地最相似: 您可以将 IaaS 视为拥有虚拟数据中心的一种方式。顾名思义，云提供商为您提供了他们托管的基础架构的一部分，其中包括三种类型的资源:

*   计算，如虚拟机、容器或裸机 (不包括操作系统)
*   网络，除了网络本身之外，还包括 DNS 服务器、路由和防火墙
*   存储，包括备份和恢复功能

提供所有软件仍然取决于您: 操作系统，中间件和您的应用程序。

IaaS 可以用于各种场景，从托管网站 (可能比传统的网络托管更便宜)，通过存储 (例如，亚马逊的 S3 和冰川服务)，到高性能计算和大数据分析 (需要巨大的计算能力)。一些公司使用它来在需要时快速设置和清除测试和开发环境。

使用 IaaS 而不是内部部署基础架构可以是一种廉价的方法来测试新想法，同时节省配置所需的时间。

如果您的服务观察到使用率的峰值，例如在周末期间，您可能希望利用云的自动扩展功能: 在需要时扩展，然后再扩展以节省资金。

所有流行的云服务提供商都提供 IaaS 解决方案。

一个类似的概念，有时被认为是 IaaS 的子集，是**容器作为服务** (**CaaS**)。在 CaaS 中，该服务为您提供了用于构建自己的容器集群的容器和编排功能，而不是裸机系统和虚拟机。CaaS 产品可以在谷歌云平台和 AWS 等平台上找到。

### 平台作为服务 (PaaS) 模型

如果基础设施本身不足以满足您的需求，则可以使用**平台即服务** (**PaaS**) 模型。在此模型中，云服务提供商不仅管理基础设施 (就像在 IaaS 中一样)，还管理操作系统、任何所需的中间件和运行时-您将在其上部署软件的平台。

通常，PaaS 解决方案将为您提供应用程序版本控制功能、服务监控和发现、数据库管理、商业智能，甚至开发工具。

使用 PaaS，您可以覆盖整个开发流程: 从构建和测试到部署、更新和管理您的服务。然而，PaaS 解决方案比 IaaS 产品成本更高。另一方面，通过提供的整个平台，您可以减少开发软件部分的成本和时间，并轻松地为遍布全球的开发团队提供相同的设置。

所有主要的云提供商都有自己的产品，例如，谷歌应用引擎或 Azure 应用服务。也有独立的，如 Heroku。

除了更通用的 PaaS 之外，还有**通信平台即服务** (**CPaaS**)，在该平台中，您可以将整个通信后端 (包括音频和视频) 集成到您的解决方案中。这项技术允许您轻松提供支持视频的服务台，或者只是将实时聊天集成到您的应用程序中。

### 软件作为服务 (SaaS) 模型

有时您可能不想自己开发软件组件，而只想使用现有的组件。**软件即服务** (**SaaS**) 基本上给你一个托管的应用程序。使用 SaaS，您无需担心基础架构或构建在其上的平台，甚至无需担心软件本身。提供商负责安装、运行、更新和维护整个软件堆栈，以及备份、许可和扩展。

在 SaaS 模型中，您可以获得各种各样的软件。示例从办公套件 (例如 office 365 和 Google Docs) 到消息传递软件 (例如 Slack)，通过**客户关系管理** (**CRM**) 系统，甚至涵盖游戏解决方案 (例如云游戏服务)，允许您玩云上托管的资源匮乏的视频游戏。

通常，要访问此类服务，您只需要一个浏览器，因此这可能是为员工提供远程工作功能的重要一步。

您可以创建自己的 SaaS 应用程序，并通过您愿意部署的方式将其提供给用户，或者通过 AWS Marketplace 等方式。

### **功能为服务 (**FaaS) 模型和无服务器架构

随着 cloud-native 的出现，另一个越来越流行的模型是**作为服务的功能** (**FaaS**)。如果您想实现无服务器架构，这可能会有所帮助。使用 FaaS，您将获得一个平台 (类似于 PaaS)，您可以在该平台上运行短暂的应用程序或功能。

使用 PaaS，您通常总是需要运行至少一个服务实例，而在 FaaS 中，您只能在实际需要它们时才可以运行它们。运行您的函数可以使处理请求的时间更长 (以秒为单位; 您毕竟需要启动该函数)。但是，可以缓存其中一些请求以减少延迟和成本。说到成本，如果你长时间运行这些功能，FaaS 可能会比 PaaS 贵得多，所以在设计你的系统时，你必须做数学运算。

如果正确使用，FaaS 会将服务器从开发人员中抽象出来，可以降低成本，并且可以为您提供更好的可扩展性，因为它可以基于事件而不是资源。此模型通常用于运行预先安排或手动触发的任务，处理批处理或数据流以及处理传入的，不那么紧急的请求。FaaS 的一些流行提供商是 AWS Lambda、Azure 功能和谷歌云功能。

现在我们已经介绍了云中常见的服务模型，让我们讨论一下人们在设计分布式系统时做出的一些错误假设。

## 避免分布式计算的谬误

当刚接触分布式计算的人们开始设计这样的系统时，他们往往会忘记或忽略这样的系统的几个方面。尽管它们最早是在 90 年代被注意到的，但今天它们仍然保持最新状态。

谬误将在以下小节中讨论。让我们快速了解一下它们中的每一个。

### 网络可靠

网络设备专为长年无瑕运行而设计。尽管如此，许多事情仍然会导致数据包丢失，包括因无线网络信号不佳而断电，配置错误，有人被电缆绊倒，甚至动物咬电线。例如，谷歌不得不用凯夫拉尔保护他们的水下电缆，因为它们被鲨鱼咬了 (是的，真的)。您应该始终假设数据可能会在网络上的某个地方丢失。即使没有发生，软件问题仍然可能发生在电线的另一侧。

要解决此类问题，请确保您具有自动重试失败的网络请求的策略以及处理常见网络问题的方法。重试时，尽量不要重载对方，不要多次提交同一事务。您可以使用消息队列为您存储和重试发送。

诸如断路器之类的模式也会有所帮助，我们将在本章后面介绍这些模式。哦，请确保不要只是无限地等待，每个失败的请求都会占用资源。

### 延迟为零

即使在正常情况下，您正在运行的网络和服务也必须花费一些时间来响应。有时，它们将需要更长的时间，尤其是在承受比平均水平更大的负载时。有时，您的请求可能需要几秒钟才能完成，而不是几毫秒。

尝试设计您的系统，使其不会等待太多细粒度的远程呼叫，因为每个这样的呼叫都可以增加您的总处理时间。即使在本地网络中，对 1 条记录的 10,000 请求也比对 1 条 10,000 记录的请求慢得多。为了减少网络延迟，请考虑批量发送和处理请求。您还可以尝试通过在等待结果时执行其他处理任务来隐藏小呼叫的成本。

处理延迟的其他方法是引入缓存，在 publisher-subscriber 模型中推送数据而不是等待请求，或者通过使用**内容传输网络** (**CDN**s) 来部署更接近客户。

### 带宽是无限的

在将新服务添加到您的体系结构中时，请确保您注意它将使用多少流量。有时，您可能希望通过压缩数据或引入限制策略来减少带宽。

这种谬误也与移动设备有关。如果信号微弱，往往网络会成为瓶颈。这意味着移动应用程序使用的数据量通常应保持较低水平。使用[第 2 章](02.html)*中描述的*后端为前端*模式，建筑风格，*通常可以帮助节省宝贵的带宽。

如果您的后端需要在某些组件之间传输大量数据，请尝试确保这些组件紧密结合在一起: 不要在单独的数据中心中运行它们。对于数据库，这通常归结为更好的复制。诸如 CQRS (在本章后面讨论) 之类的模式也很方便。

### 网络是安全的

这是一个危险的谬论。链的强度仅与其最薄弱的环节一样强，不幸的是，分布式系统中有许多环节。以下是使这些链接更牢固的几种方法:

*   确保始终将安全补丁应用于您使用的每个组件，基础架构，操作系统和其他组件。
*   培训您的人员，并尝试保护您的系统免受人为因素的影响; 有时是流氓员工破坏了系统。
*   如果您的系统在线，它将受到攻击，并且有可能在某一时刻发生漏洞。一定要有一份关于如何应对此类事件的书面计划。
*   你可能听说过深度防御原则。它归结为对系统的不同部分 (您的基础架构、应用程序等) 进行不同的检查，以便当发生违规时，其范围和相关的损坏将受到限制。
*   使用防火墙、证书、加密和适当的身份验证。

有关安全性的更多信息，请参阅[第 10 章](10.html)，*代码和部署中的安全性*。

### 拓扑不会改变

在微服务时代，这一点尤其正确。自动缩放和出现的*牛，而不是宠物*管理基础设施的方法意味着拓扑结构将不断变化。这可能会影响延迟和带宽，因此这种谬误的某些结果与前面描述的结果相同。

幸运的是，上述方法还附带了如何有效管理服务器的*群*的指南。依靠主机名和 DNS 而不是硬编码 ip 是朝着正确方向迈出的一步，而本书后面介绍的服务发现是另一步。第三个甚至更大的步骤是始终假设您的实例可能会失败并自动对此类场景做出反应。Netflix 的*混沌猴子工具*还可以帮助你测试你的准备。

### 有一个管理员

由于其性质，有关分布式系统的知识通常是分布式的。不同的人员负责此类系统及其基础架构的开发，配置，部署和管理。不同的组件经常由不同的人升级，不一定是同步的。还有所谓的公交因素，简而言之就是关键项目成员被公交车撞的风险因素。

我们如何处理这一切？答案由几个部分组成。其中之一是 DevOps 文化。通过促进开发和运营之间的紧密协作，人们可以共享有关系统的知识，从而降低了总线系数。引入持续交付可以帮助升级项目并使其始终保持状态。

尝试将您的系统建模为松散耦合和向后兼容，因此组件的升级不需要其他组件也要升级。解耦的一种简单方法是在它们之间引入消息传递，因此请考虑添加一个或两个队列。它也将帮助您在升级期间停机。

最后，尝试监视您的系统并在集中的地方收集日志。系统的分散化并不意味着您现在需要手动查看十几台不同计算机的日志。**麋鹿** (**Elasticsearch，Logstash，Kibana**) 堆栈对此非常宝贵。Grafana、Prometheus、Loki 和 Jaeger 也很受欢迎，尤其是与 Kubernetes。如果您正在寻找比 Logstash 更轻巧的东西，请考虑使用 Fluentd 和 Filebeat，尤其是在处理容器时。

### 运输成本为零

这种谬误对于规划你的项目及其预算很重要。无论您是在本地还是在云中部署，为分布式系统构建和维护网络都需要花费时间和金钱-这只是您何时支付费用的问题。尝试估算设备的成本，要传输的数据 (云提供商为此收取费用) 以及所需的人力。

如果您依赖压缩，请注意，虽然这会降低网络成本，但会增加计算的价格。通常，使用二进制 api (例如基于 gRPC 的 api) 将比基于 JSON 的 api 更便宜 (并且更快)，并且仍然比 XML 便宜。如果您发送图像，音频或视频，则必须估算出这将花费您多少钱。

### 网络是同质的

即使您计划要拥有什么硬件以及要在网络上运行什么软件，也很容易至少会出现一些异构性。一些机器上稍微不同的配置，您需要与之集成的旧系统使用的不同通信协议，或者向您的系统发送请求的不同移动电话只是其中的几个例子。另一个是通过在云中使用额外的工作人员来扩展您的内部部署解决方案。

尝试限制使用的协议和格式的数量，努力使用标准协议和格式，并避免供应商锁定，以确保您的系统在这种异构环境中仍然可以正常通信。异质性也可能意味着弹性的差异。尝试使用断路器模式以及重试来处理此问题。

现在我们已经讨论了所有的谬误，让我们来讨论分布式体系结构的另一个非常重要的方面。

## CAP 定理与最终一致性

要设计跨多个节点的成功系统，您需要了解并使用某些原理。其中之一是**CAP 定理**。这是设计分布式系统时需要做出的最重要的选择之一，它的名字归功于分布式系统可以拥有的三个属性。它们如下:

*   **一致性**: 每次读取都会获得最近写入 (或错误) 后的数据。
*   **可用性**: 每个请求都会得到一个非错误响应 (不保证你会得到最新的数据)。
*   **分区容限**: 即使两个节点之间发生网络故障，整个系统也会继续工作。

本质上，该定理指出，对于分布式系统，您最多可以选择这三个属性中的两个。

只要系统正常运行，看起来所有三个属性都可以满足。但是，从谬误中我们知道，网络是不可靠的，因此会发生分区。在这种情况下，分布式系统仍应正常运行。这意味着该定理实际上使您可以在提供分区容差和一致性 (即 CP) 或分区容差和可用性 (即 AP) 之间进行选择。通常，后者是更好的选择。如果要选择 CA，则必须完全删除网络并保留单节点系统。

如果在分区下，您决定提供一致性，则在等待数据保持一致时，您将不得不返回错误或冒着超时的风险。如果选择可用性而不是一致性，则可能会返回陈旧的数据-最新的写入可能无法在分区中传播。

这两种方法都适合不同的需求。例如，如果您的系统需要原子读写，因为客户可能会赔钱，请使用 CP。如果您的系统必须继续在分区下运行，或者您可以允许最终一致性，请使用 AP。

好吧，但是最终的一致性是什么？让我们讨论一下不同级别的一致性来理解这一点。

在提供强一致性的系统中，每个写入都是同步传播的。这意味着所有读取将始终看到最新的写入，即使代价是更高的延迟或更低的可用性。这是关系型 dbmse 提供的类型 (基于 ACID 保证)，最适合需要事务的系统。

另一方面，在提供最终一致性的系统中，您只能保证在写入后，读取最终会看到更改。通常，*最终*表示几毫秒。这是由于此类系统中数据复制的异步性质，而不是上一段的同步传播。这里没有提供 ACID 保证，例如，使用 RDBMS，我们有基础语义，通常由 NoSQL 数据库提供。

为了使系统异步并最终保持一致 (通常是 AP 系统)，需要有一种解决状态冲突的方法。这样做的一种常见方法是在实例之间交换更新，并选择第一个或最后一个写入作为接受的写入。

现在让我们讨论两种相关的模式，它们可以帮助实现最终的一致性。

### Sagas 和补偿交易

当您需要执行分布式事务时，saga 模式很有用。

在微服务时代之前，如果您有一个具有一个数据库的主机，则可以依靠数据库引擎为您完成事务。在一台主机上有多个数据库的情况下，您可以使用**两阶段提交** (**2PCs**) 来执行此操作。有了 2 台 pc，你会有一个协调员，他会首先告诉所有的数据库准备，一旦他们都报告准备好了，它会告诉他们所有的事务。

现在，因为每个微服务可能都有自己的数据库 (如果你想要可扩展性，它应该是这样的)，并且它们遍布你的基础架构，你不能再依赖简单的事务和 2 台 pc (失去这种能力通常意味着你不再想要一个 RDBMS，因为 NoSQL 数据库可以快得多)。

相反，您可以使用 saga 模式。让我们在一个例子中演示它。

想象一下，您想创建一个在线仓库，该仓库跟踪它的供应量并允许通过信用卡付款。要处理订单，最重要的是其他服务，您需要三种: 一种用于处理订单，一种用于预订耗材，另一种用于向卡收费。

现在，saga 模式可以通过两种方式实现: **基于编排的** (也称为**基于事件的**) 和**基于编排的** (也称为**基于命令的**)。

#### 基于舞蹈的传奇

在第一种情况下，传奇的第一部分将是向供应服务发送事件的订单处理服务。这将尽自己的一份力量，并向支付服务发送另一个事件。然后，付款服务将向订单服务发送另一个事件。这将完成交易 (传奇)，订单现在可以愉快地发货。

如果订单服务想要跟踪交易的状态，它只需要监听所有这些事件。

当然，有时订单将无法完成，并且需要进行回滚。在这种情况下，传奇故事的每个步骤都需要单独仔细地回滚，因为其他事务可以并行运行，例如修改供应状态。这样的回滚称为**补偿事务**。

这种实现 saga 模式的方式非常简单，但是如果所涉及的服务之间存在许多依赖关系，则最好使用*编排*方法。说到这里，现在让我们就 sagas 的第二种方法说几句话。

#### 基于编排的 sagas

在这种情况下，我们需要一个消息代理来处理我们服务之间的通信，以及一个协调传奇故事的协调器。我们的订单服务将向协调器发送请求，然后协调器将向供应和支付服务发送命令。然后，每个人都将尽自己的一份力量，并通过经纪人提供的回复渠道将回复发送回协调者。

在这种情况下，协调器具有协调事务所需的所有逻辑，并且服务本身不需要知道参与该传奇的任何其他服务。

如果向协调器发送一条消息，表明其中一项服务失败，例如，如果信用卡已过期，则它将需要开始回滚。在我们的例子中，它将再次使用代理向特定服务发送适当的回滚命令。

好吧，就目前而言，最终的一致性已经足够了。现在让我们切换到与可用性相关的其他主题。

# 使您的系统容错和可用

可用性和容错性是软件质量，至少对每个体系结构都有些重要。如果系统达不到，创建软件系统有什么意义？在本节中，我们将了解这些术语的确切含义以及在解决方案中提供它们的一些技术。

## 计算系统的可用性

可用性是系统启动、运行和可访问的时间百分比。崩溃，网络故障或导致系统无法响应的极高负载 (例如，来自 DDoS 攻击) 都可能影响其可用性。

通常，争取尽可能高的可用性是一个好主意。您可能会偶然发现术语*计算 nines*，因为可用性通常被指定为 99% (两个 nines) 、99.9% (三个) 等。每增加九个就很难获得，因此在做出承诺时要小心。看看下表，看看如果您按月指定停机时间，您可以承受多少停机时间:

| 停机时间/月 | 正常运行时间 |
| --- | --- |
| 7 小时 18 分钟 | 99% (“两个 9”) |
| 43 分 48 秒 | 99.9% (“三个 9”) |
| 4 分 22.8 秒 | 99.99% (“四个 9”) |
| 26.28 秒 | 99.999% (“五个 9”) |
| 2.628 秒 | 99.9999% (“六个 9”) |
| 262.8 毫秒 | 99.99999% (“七个 9”) |
| 26.28 毫秒 | 99.999999% (“八个 9”) |
| 2.628 毫秒 | 99.9999999% (“九个九”) |

云应用的一种常见做法是提供**服务级别协议** (**SLA**)，该协议指定在给定时间段 (例如一年) 可以发生多少停机时间。云服务的 SLA 将在很大程度上取决于您构建的云服务的 SLA。

要计算需要合作的两个服务之间的复合可用性，您应该将它们的正常运行时间相乘。这意味着如果您有两个 99.99% 可用性的服务，它们的复合可用性将 99.99% * 99.99% = 99.98%。要计算冗余服务 (例如两个独立区域) 的可用性，您应该乘以它们的不可用性。例如，如果两个区域具有 99.99% 可用性，则它们的总不可用性将是 (100% - 99.99%) * (100% - 99.99%) = 0.01% * 0.01% = 0.0001%，因此它们的复合可用性是 99.9999% 的。

不幸的是，它是不可能提供 100% 的可用性。故障确实会不时发生，因此让我们学习如何使系统容忍它们。

## 构建容错系统

容错是系统检测此类故障并优雅地处理它们的能力。您的基于云的服务必须具有弹性，这一点至关重要，因为由于云的性质，许多不同的东西可能会突然消失。良好的容错性可以帮助您的服务可用性。

不同类型的问题需要不同的处理: 从预防到检测，到最大程度地减少影响。让我们从避免出现单点故障的常见方法开始。

### 冗余

最基本的预防措施之一是引入**冗余**。类似于为您的汽车提供备用轮胎的方式，您可以有一个备用服务，当您的主服务器出现故障时，该服务将接管。此步进也称为**故障转移**。

备份服务器如何知道何时介入？一种实现方法是使用*检测故障*部分中描述的心跳机制。

为了使切换更快，您可以将进入主服务器的所有消息也发送到备份服务器。这被称为**热备用**，而不是冷备用-从零初始化。在这种情况下，一个好主意是将一条消息留在后面，因此，如果*中毒的*消息杀死了主服务器，则备份可以简单地拒绝它。

前面的机制称为**主动-被动** (或**主从**) 故障转移，因为备份服务器不处理传入的流量。如果是这样，我们将有一个**活动-活动** (或**主-主**) 故障转移。有关主动-主动体系结构的更多信息，请参阅*进一步阅读*部分中的最后一个链接。

确保在发生故障转移时不会丢失任何数据。使用带有备份存储的消息队列可能会有所帮助。

#### 领导人选举

对于两个服务器来说，知道哪一个是哪个也很重要-如果两个服务器都开始表现为主实例，您可能会遇到麻烦。选择主服务器称为领导者选举模式。有几种方法可以做到这一点，例如，通过引入第三方仲裁者，通过竞相获得共享资源的独占所有权，通过选择排名最低的实例，或者通过使用诸如恶霸选举或令牌环选举之类的算法。

领导人选举也是下一个相关概念的重要组成部分: 达成共识。

#### 共识

如果您希望即使在发生网络分区或某些服务实例出现故障时系统也能运行，则需要一种使实例达成共识的方法。他们必须同意要承诺什么价值观，并且经常以什么顺序达成一致。一种简单的方法是允许每个实例对正确的状态进行投票。但是，在某些情况下，这还不足以正确或根本达成共识。另一种方法是选举一位领导者，让其传播其价值。由于手工实现此类算法并不容易，因此我们建议使用经过行业验证的流行共识协议，例如 Paxos 和 Raft。后者越来越受欢迎，因为它更简单，更容易理解。

现在让我们讨论另一种防止系统故障的方法。

### 复制

这个在数据库中特别受欢迎，它也有助于扩展它们。**复制**意味着您将与重复的数据并行运行您的服务的几个实例，所有实例都处理传入的流量。

Don't confuse replication with sharding. The latter doesn't require any data redundancy, but can often bring you great performance at scale. If you're using Postgres, we recommend you try out Citus ([https://www.citusdata.com](https://www.citusdata.com)).

在数据库方面，有两种方法可以复制。

#### 主从复制

在这种情况下，所有服务器都可以执行只读操作，但是只有一个主服务器也可以写入。数据从主服务器通过从服务器以一对多拓扑或使用树形拓扑复制。如果主机发生故障，则系统仍可以在只读模式下运行，直到纠正此故障为止。

#### 多主复制

您还可以拥有具有多个主服务器的系统。如果有两个服务器，则您有一个*主-主复制*方案。如果其中一台服务器死亡，其他服务器仍然可以正常运行。但是，现在您要么需要同步写入，要么提供更宽松的一致性保证。另外，您需要提供**负载均衡器**。

此类复制的示例包括 Microsoft 的 Active Directory，OpenLDAP，Apache 的 CouchDB 或 Postgres-XL。

现在让我们讨论两种方法来防止负载过高引起的故障。

### 基于队列的负载均衡

此策略旨在减少系统负载突然尖峰的影响。用请求淹没服务可能会导致性能问题、可靠性问题，甚至丢弃有效请求。再一次，排队可以节省一天。

为了实现这种模式，我们只需要引入一个队列，以异步添加传入的请求。您可以使用 Amazon 的 SQS、Azure 的服务总线、Apache Kafka、ZeroMQ 或其他队列来实现这一目标。

现在，而不是在传入请求中有峰值，负载将被平均。我们的服务可以从所述队列中获取请求并处理它们，甚至不知道负载增加了。就这么简单。

如果您的队列是高性能的，并且您的任务可以并行化，则此模式的附带好处将是更好的可伸缩性。

此外，如果您的服务不可用，则请求仍将添加到队列中，以便在恢复时处理所述服务，因此这可能是一种帮助提高可用性的方法。

如果请求很少出现，请考虑将服务实现为仅在队列中有项目时运行的功能，以节省成本。

请记住，当使用此模式时，总延迟将通过添加队列而增加。Apache Kafka 和 ZeroMQ 应该产生低延迟，但如果这是一个交易破坏者，还有另一种方法来处理增加的负载。

### 背压

如果负载仍然很高，您可能会承担更多的任务。如果请求不再适合内存，这可能会导致缓存丢失和交换，以及丢弃请求和其他令人讨厌的东西。如果您期望承受沉重的负荷，则施加背压可能是应对它的好方法。

从本质上讲，背压意味着我们不会在每个传入请求中对我们的服务施加更大的压力，而是将其推回到呼叫者中，以便它需要处理这种情况。有几种不同的方法可以做到这一点。

例如，我们可以阻止接收网络数据包的线程。然后，呼叫者将看到它无法将请求推送到我们的服务-相反，我们将压力向上推。

另一种方法是识别更大的负载并简单地返回错误代码，例如 503。您可以对您的架构进行建模，以便由另一项服务为您完成。一种这样的服务是特使代理 ([https://envoyproxy.io](https://envoyproxy.io))，它也可以在许多其他场合派上用场。

Envoy 可以根据预定义的配额施加反压，因此您的服务实际上永远不会过载。它还可以测量处理请求所花费的时间，并且仅在超过某个阈值时才施加背压。在许多其他情况下，将返回各种错误代码。希望呼叫者有一个计划，如果压力再次施加在他们身上，该怎么办。

现在我们知道了如何预防故障，让我们学习一下一旦故障发生就如何检测它们。

## 检测故障

正确和快速的故障检测可以为您节省很多麻烦，而且经常是金钱。有许多方法可以根据不同的需求来检测故障。让我们来看看其中的一些。

### 边卡设计模式

由于我们正在讨论 Envoy，因此值得一提的是，它是**边卡设计模式**的一个例子。这种模式在更多的情况下是有用的，而不仅仅是错误预防和检测，而 Envoy 就是一个很好的例子。

通常，sidefars 允许您向服务添加许多功能，而无需编写其他代码。同样，由于可以将物理边车附加到摩托车上，因此可以将软件边车附加到您的服务上-在这两种情况下都可以扩展所提供的功能。

边卡如何有助于检测故障？首先，通过提供健康检查功能。当谈到被动健康检查时，Envoy 可以检测服务集群中的任何实例是否开始表现不佳。这称为**离群值检测**。Envoy 可以查找连续的 5XX 错误代码，网关故障等。除了检测到此类故障实例外，它还可以弹出它们，以便整个集群保持健康。

Envoy 还提供主动运行状况检查，这意味着它可以探测服务本身，而不仅仅是观察其对传入流量的反应。

在本章中，我们将展示 sidecar 模式的其他一些用法，尤其是 Envoy。现在让我们讨论故障检测的下一个机制。

### 心跳机制

故障检测最常见的方法之一是通过**心跳机制**。**心跳**是在两个服务之间定期 (通常是几秒钟) 发送的信号或消息。

如果连续几次心跳缺失，接收服务可以考虑发送服务*死*。对于前面几节中的主备份服务对，这可能会导致发生故障转移。

实施心跳机制时，请确保它是可靠的。错误警报可能会很麻烦，因为服务可能会感到困惑，例如，关于哪个应该是新的主机。一个好主意可能是仅为心跳提供一个单独的端点，因此它不会容易受到常规端点上流量的影响。

### 漏斗计数器

另一种检测故障的方法是添加一个所谓的**漏桶**计数器。对于每个错误，计数器将增加，并且在达到特定阈值 (存储桶已满) 之后，将发出信号并处理故障。在固定的时间间隔内，计数器会减少 (因此，漏桶)。这样，只有在短时间内发生许多错误时，情况才被视为故障。

这种模式可能是有用的，如果在你的情况下，它有时有错误是正常的，例如，如果你正在处理网络。

现在我们知道了如何检测故障，让我们学习一旦故障发生该怎么办。

## 最大限度地减少故障的影响

检测到正在进行的故障需要时间，并且需要更多的宝贵资源来解决它。这就是为什么您应该努力将故障的影响降至最低的原因。这里有几个方法可以帮助。

### 重试呼叫

当您的应用程序调用另一个服务时，有时调用会失败。对于这种情况，最简单的补救措施就是重试电话。如果故障是暂时的，并且您不重试，则该故障可能会在您的系统中传播，从而造成比应有的更多的损坏。实现自动重试此类调用的方法可以为您节省很多麻烦。

还记得我们的边卡代理人吗，特使？事实证明，它可以代表您执行自动重试，从而使您免于对源进行任何更改。

例如，请参阅此示例配置重试策略，该策略可以添加到 Envoy 中的路由中:

```cpp
retry_policy:
  retry_on: "5xx"
  num_retries: 3
  per_try_timeout: 2s
```

如果 Envoy 重试调用返回错误，例如 503 HTTP 代码或映射到 5XX 代码的 gRPC 错误。将进行三次重试，如果在 2 秒内未完成，则每次重试均被视为失败。

### 避免级联故障

我们提到，如果没有重试，错误将被传播，导致整个系统的故障级联。现在让我们展示更多防止这种情况发生的方法。

#### 断路器

**断路器模式**是一个非常有用的工具。它使我们能够快速注意到服务无法处理请求，因此对它的呼叫可能会短路。这既可以发生在被叫方附近 (特使提供了这样的能力)，也可以发生在呼叫者侧 (具有从呼叫中缩短时间的额外好处)。在 Envoy 的情况下，它可以像在配置中添加以下内容一样简单:

```cpp
circuit_breakers:
  thresholds:
    - priority: DEFAULT
      max_connections: 1000
      max_requests: 1000
      max_pending_requests: 1000
```

在这两种情况下，对服务的调用引起的负载都可能下降，这在某些情况下可以帮助服务恢复正常运行。

我们如何在呼叫者侧实现断路器？一旦你打了几个电话，比如说，你漏水的桶溢出，你就可以在指定的一段时间内停止打新的电话 (例如，直到桶不再溢出)。简单有效。

#### 隔板

另一种限制断层扩散的方法是直接从牲畜饲养场获取。建造船只时，如果船体破洞，您通常不希望船充满水。为了限制此类孔的损坏，您可以将船体分成舱壁，每个舱壁都很容易隔离。在这种情况下，只有损坏的舱壁会装满水。

同样的原则也适用于限制软件体系结构中的故障影响。您可以将实例划分为组，也可以将它们使用的资源分配到组中。设置配额也可以被认为是这种模式的一个例子。

可以为不同的用户组创建单独的舱壁，如果您需要对它们进行优先级排序或为关键消费者提供不同级别的服务，这可能会很有用。

### 地质

我们将展示的最后一种方式叫做**Geodes**。名称来自地理节点。当您的服务部署在多个区域时，可以使用它。

如果一个区域发生故障，您可以将流量重定向到其他未受影响的区域。当然，这将使延迟比您向同一数据中心中的其他节点发出呼叫要高得多，但是通常将不太关键的用户重定向到远程区域比完全失败呼叫要好得多。

既然您知道如何通过系统的体系结构提供可用性和容错能力，那么让我们讨论一下如何将其组件集成在一起。

# 集成您的系统

分布式系统不仅仅是在不了解现有世界的情况下运行的应用程序的孤立实例。他们不断地相互交流，必须适当地整合在一起，以提供最大的价值。

关于集成的话题已经说了很多，所以在本节中，我们将尝试展示一些模式，以有效集成全新系统以及需要与其他现有部分共存的系统新部分，通常是遗留部分。

为了不让这一章本身成为一整本书，让我们从现有的一章推荐开始这一节。如果您对集成模式感兴趣，尤其是专注于消息传递，那么 Gregor Hohpe 和 Bobby Woolf 的*企业集成模式*书是您必读的书。

让我们简要看一下本书涵盖的两种模式。

## 管道和过滤器模式

我们将讨论的第一个集成模式称为**管道和过滤器**。它的目的是将一个大的处理任务分解为一系列较小的、独立的任务 (称为**过滤器**)，然后可以将它们连接在一起 (使用管道，如消息队列)。这种方法为您提供了可伸缩性、性能和可重用性。

假设您需要接收和处理收到的订单。你可以在一个大模块中完成，所以你不需要额外的通信，但是这样一个模块的不同功能很难测试，也很难很好地扩展它们。

相反，您可以将订单处理分成单独的步骤，每个步骤由一个不同的组件处理: 一个用于解码，一个用于验证，另一个用于订单的实际处理，然后另一个用于将其存储在某个地方。通过这种方法，您现在可以独立执行这些步骤中的每个步骤，如果需要，可以轻松地替换或禁用它们，并将它们重新用于处理不同类型的输入消息。

如果要同时处理多个订单，还可以流水线处理: 当一个线程验证消息时，另一个线程解码下一个，依此类推。

缺点是你需要使用同步队列作为你的管道，这引入了一些开销。

要扩展处理的一个步骤，您可能希望将此模式与我们列表中的下一个模式一起使用。

## 竞争消费者

竞争消费者的想法很简单: 您有一个输入队列 (或消息传递通道) 和一些消费者实例，它们同时从队列中获取和处理项目。每个消费者都可以处理消息，因此他们彼此竞争成为接收者。

通过这种方式，您可以获得可伸缩性，免费的负载平衡和弹性。加入队列后，您现在也有了**基于队列的负载均衡模式**。

如果您需要从请求中减少延迟，或者只是希望以更紧急的方式执行提交到队列的特定任务，则此模式可以毫不费力地与优先级队列集成。

This pattern can get tricky to use if the ordering is important. The order in which your consumers receive and finish to process messages may vary, so make sure that either this doesn't impact your system, or you find a way to reorder the results later on. If you need to process messages in sequence, you might not be able to use this pattern.

现在让我们看看更多的模式，这次是为了帮助我们与现有系统集成。

## 从遗留系统过渡

从头开始开发系统可能是一种幸福的体验。开发而不是维护，并且有可能使用前沿技术堆栈-不喜欢什么？不幸的是，当与现有的遗留系统集成时，这种幸福通常会结束。不过，幸运的是，有一些方法可以减轻这种痛苦。

### 反腐败层

引入**反腐败层**可以帮助您的解决方案与具有不同语义的遗留系统进行无痛集成。此附加层负责双方之间的通信。

这样的组件可以使您的解决方案具有更大的灵活性，而无需损害您的技术堆栈或架构决策。要实现这一目标，仅需要在遗留系统中进行最少的更改 (如果遗留系统不需要对新系统进行调用，则无需更改)。

例如，如果您的解决方案基于微服务，则遗留系统可以仅与反腐败层进行通信，而不是直接定位和到达每个微服务。任何翻译 (例如，由于协议版本过时) 也在附加层中完成。

请记住，添加这样的层可能会引入延迟，并且必须满足解决方案的质量属性，例如可伸缩性。

### 扼杀者图案

**扼杀器模式**允许从遗留系统逐步迁移到新系统。虽然我们刚才看到的反腐败层对两个系统之间的通信很有用，但扼杀者模式是为了向外界提供服务。

在迁移过程的早期，strangler facade 会将大多数请求路由到遗留系统中。在迁移过程中，越来越多的呼叫可以转发到新的呼叫中，而*越来越多地扼杀*遗留系统，限制了它提供的功能。作为迁移的最后一步，扼杀者以及遗留系统可以退役-新系统现在将提供所有功能:

![](assets/2bdb1d3d-9ce3-4d8c-8ca2-83df565557bf.png)]

Figure 4.1 – The strangling of a monolith. After the migration, the strangler can still be used as an entry point, or adapter, for legacy requests

对于小型系统，此模式可能会过大，并且如果数据存储应该共享或用于事件源系统，则可能会变得棘手。将其添加到解决方案中时，请务必计划实现适当的性能和可伸缩性。

说到这两个属性，现在让我们讨论一些有助于实现它们的事情。

# 实现规模绩效

在设计 C 应用程序时，性能通常是一个关键因素。虽然使用该语言可以在单个应用程序的范围内走很长一段路，但适当的高级设计对于实现最佳延迟和吞吐量也至关重要。让我们讨论几个关键的模式和方面。

## CQRS 和事件来源

有很多方法可以扩展计算，但是扩展数据访问可能很棘手。但是，当您的用户群增长时，这通常是必要的。**命令-查询责任隔离** (**CQRS**) 是一种可以在这里提供帮助的模式。

### 命令查询责任隔离

在传统的 CRUD 系统中，读取和写入都是使用相同的数据模型执行的，并且数据以相同的方式流动。名义隔离基本上意味着以两种不同的方式处理查询 (读取) 和命令 (写入)。

许多应用程序的读与写的比率都有很大的偏差-通常从数据库中读取的数据比在典型的应用程序中更新数据要多得多。这意味着尽可能快地读取可以产生更好的性能: 读取和写入现在可以分别进行优化和缩放。除此之外，如果许多写入相互竞争，或者需要维护所有写入的轨迹，或者您的一组 API 用户应该具有只读访问权限，则引入 CQRS 可以提供帮助。

具有单独的读写模型可以允许有不同的团队在双方工作。在阅读方面工作的开发人员不需要对域有深刻的了解，而域是正确执行更新所必需的。当他们发出请求时，他们只需要一个简单的调用，就可以从一个薄读层获得一个**数据传输对象** (**DTO**)，而不是通过域模型。

如果您不知道 d 是什么，请考虑从数据库中返回项目数据。如果调用者要求提供项目列表，则可以向他们提供一个仅包含项目名称和缩略图的`ItemOverview`对象。另一方面，如果他们想要特定商店的商品，您还可以提供一个包含名称、更多图片、描述和价格的`StoreItem`对象。`ItemOverview`和`StoreItem`都是 dto，从数据库中相同的`Item`对象中抓取数据。

读取层可以驻留在用于写入的数据存储的顶部，也可以是通过事件更新的不同数据存储，如下图所示:

![](assets/ff498ed0-7616-442a-b28b-510ea14f0baa.png)]

Figure 4.2 – CQRS with event sourcing

使用此处所示的方法，您可以创建任意多个不同的命令，每个命令都有自己的处理程序。通常，命令是异步的，不会向调用方返回任何值。每个处理程序都使用域对象，并将完成的更改保持不变。完成此操作后，将发布事件，事件处理程序可以使用该事件处理程序来更新读取操作使用的存储。继续我们的上一个示例，项目数据查询将从数据库中获取由事件更新的信息，例如`ItemAdded`或`ItemPriceChanged`，这些事件可以由`AddItem`或`ModifyItem`等命令触发。

使用 CQRS 可以让我们有不同的数据模型进行读写操作。例如，您可以创建存储过程和实体化视图以加快读取速度。使用不同类型的存储 (SQL 和 NoSQL) 用于读取和域存储也可能是有益的: 一种有效的数据持久化方法是使用 Apache Cassandra 集群，而使用 Elasticsearch 是快速搜索存储数据的好方法。

除了前面的优点，CQRS 也有它的缺点。由于它引入的复杂性，它通常不适合小型或要求较低的体系结构。仅将其应用于系统中会带来最大好处的部分通常很有用。您还应该注意到，在域存储之后更新读取存储意味着现在我们具有最终的一致性，而不是强一致性。

### 命令-查询分离

CQRS 实际上是基于很久以前在 Eiffel 编程语言中引入的一个更简单的想法 (引入合同的那个)。**命令-查询分离** (**CQS**) 是一种原理，它设计将 API 调用分离到命令和查询中，就像在 CQRS 中一样，但是不管规模如何。总体而言，它与客观编程和命令式编程非常有效。

如果你的函数的名字以一个*开头有*，*是*，*可以，*或者类似的词，应该只是一个查询，不修改底层状态或者有任何副作用。这带来了两个巨大的好处:

*   **关于代码的推理要容易得多**: 很明显，这样的函数在语义上只是*读*，从来没有*写*。这可以使调试时查找状态更改变得容易得多。
*   **Reduce heisenbugs**: 如果您曾经调试过一个错误，该错误在发布版本中表现出来，但在调试版本中却没有 (或相反)，那么您已经处理了一个 heisenbug。这很少是令人愉快的事情。许多这样的错误可能是由修改状态的 assert 调用引起的。遵循 CQS 消除了此类错误。

与 asserts 类似，如果您想拥有合同 (前置条件和后置条件)，则仅在其中使用查询非常重要。否则禁用某些合同检查也可能导致 heisenbugs，更不用说它有多违反直觉了。

现在让我们再说几句关于事件采购的话。

### 事件来源

正如在[第 2 章](02.html)，*体系结构样式*中介绍的那样，事件采购意味着不要总是存储应用程序的整个状态，可能要处理更新过程中的冲突，您可以只存储发生在应用程序状态上的更改。使用事件采购可以通过消除并发更新并允许所有感兴趣的各方对其状态进行逐步更改来提高应用的性能。保存已完成的操作 (例如，市场交易) 的历史记录可以允许更容易的调试 (通过稍后重放) 和审计。这也为表带来了更多的灵活性和可扩展性。当引入事件源时，一些领域模型会变得简单得多。

事件采购的一个成本最终是一致的。另一个是减慢应用程序的启动速度-除非您对状态进行定期快照，或者可以像上一节中讨论的那样使用 CQRS 中的只读存储。

好了，CQRS 和相关模式够了。现在，让我们继续讨论性能方面的另一个热门话题 (没有双关语): 缓存。

## 缓存

正确使用缓存可以产生更好的性能，更低的延迟，减少服务器负载 (因此，在云中运行的成本)，并有助于解决可扩展性问题 (所需的服务器更少)-什么是不喜欢的？

If you're here for tips on CPU caches, you can find them in [Chapter 11](11.html), *Performance*.

缓存是一个大话题，所以我们在这里只介绍它的几个方面。

缓存的工作原理是简单地将最常读取的数据存储在具有快速访问时间的非持久性存储中。有许多不同类型的缓存:

*   **客户端缓存**: 用于存储特定客户的数据，通常放在客户端的机器或浏览器上。
*   **Web 服务器缓存**: 用于加速从 web 页面读取，例如，通过可以缓存 web 服务器响应的 HTTP 加速器 (例如 Varnish)。
*   **数据库缓存**: 许多数据库引擎都有内置的、可调谐的缓存。
*   **应用程序缓存**: 用于加速应用程序，它现在可以从缓存中读取数据，而不是访问其数据库。
*   Cdn 也可以被视为高速缓存: 用于从靠近用户的位置提供内容，以减少延迟。

某些类型的缓存可以复制或部署在集群中，以提供规模化的性能。另一种方法也可以是对它们进行分片: 与分片数据库类似，您可以将缓存的不同实例用于数据的不同部分。

现在让我们通过不同的方法来更新缓存中的数据。毕竟，没有人喜欢被提供过时的数据。

### 更新缓存

有几种方法可以使缓存的数据保持新鲜。无论是您决定如何更新缓存的项目还是其他公司，都值得了解它们。在本节中，我们将讨论它们的优缺点。

#### 通过写入方法

如果您需要很强的一致性，同步更新数据库和缓存是您的有效方法。这种方法可以保护您免受数据丢失: 如果数据对用户可见，则意味着它已经写入数据库。通过写入缓存的缺点是执行更新的延迟比其他方法大。

#### 写隐藏方法

另一种方法，也称为**回写**，是为用户提供对缓存的访问权限。当用户执行更新时，缓存会将传入的更新排队，然后异步执行，从而更新数据库。这里明显的缺点是，如果出了问题，数据永远不会被写入。它也不像其他方法那样容易实现。然而，好处是用户看到的最低延迟。

#### 缓存旁

最后一种方法，也称为**延迟加载**，是关于按需填充缓存。在这种情况下，数据访问如下所示:

1.  调用缓存以检查该值是否已经存在。如果是这样，就把它退回去。
2.  到达提供值的主数据存储或服务。
3.  将值存储在缓存中并将其返回给用户。

这种类型的缓存通常使用 Memcached 或 Redis 来完成。它可以非常快速和高效-缓存仅包含请求的数据。

但是，如果经常请求不在缓存中的数据，则前三个调用会显着增加延迟。为了缓解这种情况，可以使用来自持久存储的选定数据对缓存进行启动 (初始化)。

缓存中的项目也可能变得陈旧，因此最好为每个条目设置一个生存时间。如果要更新数据，则可以通过从缓存中删除记录并在数据库中更新记录来以直写方式发生。使用具有基于时间的更新策略的多级缓存时要小心 (例如，在 DNS 缓存中)。这可能会导致长时间使用陈旧的数据。

我们已经讨论了缓存的类型和更新它们的策略，所以就目前而言，缓存已经足够了。让我们继续讨论提供可扩展体系结构的另一个方面。

# 部署您的系统

尽管部署服务听起来很容易，但如果你仔细看看，还有很多事情要考虑。本节将介绍如何执行高效的部署，在安装服务后配置服务，检查它们在部署后是否保持健康，以及如何在最大程度地减少停机时间的同时完成所有工作。

## 边卡图案

还记得本章前面的特使吗？对于高效的应用程序开发来说，这是一个非常有用的工具。您可以将 Envoy 代理与您的应用程序一起部署，而不是将基础设施服务 (如日志记录、监控或网络) 嵌入到您的应用程序中，就像在摩托车旁边部署边车一样。在一起，他们可以比没有 sidekick 的应用程序做更多的事情 (这种模式的另一个名字)。

使用 sidecar 可以加快开发速度，因为它带来的许多功能需要由您的每个微服务独立开发。因为它与您的应用程序是分开的，所以可以使用您认为最适合该工作的任何编程语言来开发 sidecar。sidecar 及其提供的所有功能都可以由独立的开发人员团队维护，并独立于您的主要服务进行更新。

由于 sidecan 位于它们增强的应用程序旁边，因此它们可以使用本地进程间通信方式。通常，它足够快，并且比从另一台主机进行通信要快得多，但是请记住，有时它可能会带来太大的负担。

即使部署了第三方服务，在其旁边部署选定的 sidecar 仍然可以提供价值: 您可以监视资源使用情况以及主机和服务的状况，以及在整个分布式系统中跟踪请求。有时，也可以通过编辑配置文件或 web 界面，根据其条件动态重新配置服务。

### 使用 Envoy 部署具有跟踪和反向代理的服务

现在让我们使用 Envoy 作为我们部署的前置代理。首先创建 Envoy 的配置文件，在我们的情况下名为`envoy-front_proxy.yaml`，并带有我们的代理地址:

```cpp
static_resources:
  listeners:
  - address:
      socket_address:
        address: 0.0.0.0
        port_value: 8080
    traffic_direction: INBOUND
```

我们已经指定了 Envoy 将监听端口`8080`上的传入流量。稍后在配置中，我们将其路由到我们的服务。现在，让我们指定我们想要使用我们的一组服务实例来处理 HTTP 请求，并在顶部添加一些跟踪功能。首先，让我们添加一个 HTTP 端点:

```cpp
    filter_chains:
      - filters:
          - name: envoy.filters.network.http_connection_manager
            typed_config:
              "@type": type.googleapis.com/envoy.extensions.filters.network.http_connection_manager.v3.HttpConnectionManager
```

现在，让我们指定请求应该分配 id，并由分布式跟踪系统 Jaeger 进行跟踪:

```cpp
              generate_request_id: true
              tracing:
                provider:
                  name: envoy.tracers.dynamic_ot
                  typed_config:
                    "@type": type.googleapis.com/envoy.config.trace.v3.DynamicOtConfig
                    library: /usr/local/lib/libjaegertracing_plugin.so
                    config:
                      service_name: front_proxy
                      sampler:
                        type: const
                        param: 1
                      reporter:
                        localAgentHostPort: jaeger:6831
                      headers:
                        jaegerDebugHeader: jaeger-debug-id
                        jaegerBaggageHeader: jaeger-baggage
                        traceBaggageHeaderPrefix: uberctx-
                      baggage_restrictions:
                        denyBaggageOnInitializationFailure: false
                        hostPort: ""
```

我们将为请求创建 id，并将 OpenTracing 标准 (`DynamicOtConfig`) 与本机 Jaeger 插件一起使用。插件将报告到在指定地址下运行的 Jaeger 实例，并添加指定的标头。

我们还需要指定来自所有域的所有流量 (请参阅`match`部分) 都应路由到我们的服务集群中:

```cpp
              codec_type: auto
              stat_prefix: ingress_http
              route_config:
                name: example_route
                virtual_hosts:
                  - name: front_proxy
                    domains:
                      - "*"
                    routes:
                      - match:
                          prefix: "/"
                        route:
                          cluster: example_service
                        decorator:
                          operation: example_operation
```

我们将在一秒钟内定义我们的`example_service`集群。请注意，进入集群的每个请求都将由预定义的操作装饰器标记。我们还需要指定使用什么路由器地址:

```cpp
            http_filters:
            - name: envoy.filters.http.router
              typed_config: {}
            use_remote_address: true
```

现在我们知道如何处理和跟踪请求，所以剩下的就是定义我们使用的集群。让我们从服务的集群开始:

```cpp
  clusters:
    - name: example_service
      connect_timeout: 0.250s
      type: strict_dns
      lb_policy: round_robin
      load_assignment:
        cluster_name: example_service
        endpoints:
          - lb_endpoints:
              - endpoint:
                  address:
                    socket_address:
                      address: example_service
                      port_value: 5678
```

每个集群可以有我们服务的多个实例 (端点)。在这里，如果我们决定添加更多端点，则将使用循环策略对传入的请求进行负载平衡。

我们也添加一个管理员界面:

```cpp
admin:
  access_log_path: /tmp/admin_access.log
  address:
    socket_address:
      address: 0.0.0.0
      port_value: 9901
```

现在让我们将配置放在一个容器中，该容器将使用 Dockerfile 运行 Envoy，我们将其命名为`Dockerfile-front_proxy`:

```cpp
FROM envoyproxy/envoy:v1.17-latest

RUN apt-get update && \
    apt-get install -y curl && \
    rm -rf /var/lib/apt/lists/*
RUN curl -Lo - https://github.com/tetratelabs/getenvoy-package/files/3518103/getenvoy-centos-jaegertracing-plugin.tar.gz | tar -xz && mv libjaegertracing.so.0.4.2 /usr/local/lib/libjaegertracing_plugin.so

COPY envoy-front_proxy.yaml /etc/envoy/envoy.yaml
```

我们还下载了我们在特使配置中使用的 Jaeger 本机插件。

现在让我们指定如何使用 Docker Compose 在几个容器中运行我们的代码。创建一个`docker-compose.yaml`文件，从前端代理服务定义开始:

```cpp
version: "3.7"

services:
  front_proxy:
    build:
      context: .
      dockerfile: Dockerfile-front_proxy
    networks:
      - example_network
    ports:
      - 12345:12345
      - 9901:9901
```

我们在这里使用我们的 Dockerfile，一个简单的网络，我们从主机上的容器中公开两个端口: 我们的服务和管理界面。现在让我们添加我们的代理将直接指向的服务:

```cpp
  example_service:
    image: hashicorp/http-echo
    networks:
      - example_network
    command: -text "It works!"
```

在我们的例子中，服务只会在一个简单的 web 服务器中显示一个预定义的字符串。

现在，让我们在另一个容器中运行 Jaeger，将其端口暴露给外界:

```cpp
  jaeger:
    image: jaegertracing/all-in-one
    environment:
      - COLLECTOR_ZIPKIN_HTTP_PORT=9411
    networks:
      - example_network
    ports:
      - 16686:16686
```

最后一步将是定义我们的网络:

```cpp
networks:
  example_network: {}
```

我们结束了。您现在可以使用`docker-compose up --build`运行服务，并将浏览器指向我们指定的端点。

使用 sidecar 代理还有一个好处: 即使您的服务将死亡，sidecar 通常仍然存在，并且可以在主服务关闭时响应外部请求。当您的服务重新部署时，例如，由于更新，这同样适用。说到这里，让我们学习如何最大程度地减少相关的停机时间。

## 零停机部署

有两种常见的方法可以最大程度地减少部署期间的停机风险: **蓝绿色部署**和**金丝雀发布**。在介绍这两个中的任何一个时，您都可以使用特使边卡。

### 蓝绿色部署

**蓝绿色部署**可以帮助您最大程度地减少停机时间和与部署应用程序相关的风险。为此，您需要两个相同的生产环境，分别称为*蓝色*和*绿色*。在绿色为客户服务的同时，您可以在蓝色中执行更新。一旦进行了更新，对服务进行了测试，并且所有服务看起来都很稳定，您可以切换流量，使其现在流向更新的 (蓝色) 环境。

如果在切换后在蓝色环境中发现任何问题，则绿色仍然存在-您可以将它们切换回去。用户可能甚至不会注意到任何更改，并且由于两个环境都已启动并正在运行，因此在切换期间不应看到停机时间。只需确保在切换过程中不会丢失任何数据 (例如，在新环境中进行的交易)。

### 金丝雀释放

在更新后不让所有服务实例失败的最简单方法通常是，不同时更新所有实例。这是蓝绿色部署的增量变体背后的关键思想，也称为**金丝雀发布**。

在 Envoy 中，您可以在配置的`routes`部分中输入以下内容:

```cpp
- match:
    prefix: "/"
  route:
    weighted_clusters:
      clusters:
      - name: new_version
        weight: 5
      - name: old_version
        weight: 95
```

您还应该记住从上面的代码片段中定义两个集群，第一个具有旧版本的服务:

```cpp
clusters:
  - name: old_version
    connect_timeout: 0.250s
    type: strict_dns
    lb_policy: round_robin
    load_assignment:
      cluster_name: old_version
      endpoints:
        - lb_endpoints:
            - endpoint:
                address:
                  socket_address:
                    address: old_version
                    port_value: 5678
```

第二个集群将运行新版本:

```cpp
- name: new_version
  connect_timeout: 0.250s
  type: strict_dns
  lb_policy: round_robin
  load_assignment:
    cluster_name: new_version
    endpoints:
      - lb_endpoints:
          - endpoint:
              address:
                socket_address:
                  address: new_version
                  port_value: 5678
```

部署更新后，只有一小部分 (此处为 5%) 用户才能看到和使用服务的新版本。如果更新后的实例保持稳定，并且没有检查和验证失败，您可以分几个步骤逐步更新越来越多的主机，直到所有主机都切换到新版本。您可以通过手动更新配置文件或使用管理端点来完成此操作。瞧!

现在让我们继续讨论我们将在这里介绍的最后一个部署模式。

## 外部配置存储

如果您正在部署一个简单的应用程序，可以将其配置与它一起部署。但是，当您希望对许多应用程序实例进行更复杂的部署时，重新部署新版本的应用程序只是为了重新配置它会很快成为负担。同时，如果您想像对待牛而不是宠物一样对待服务，则手动配置更改是不可行的。引入外部配置存储可以是克服这些障碍的一种优雅方法。

本质上，您的应用程序可以从所述存储中获取其配置，而不仅仅是依靠其本地配置文件。这使您可以为多个实例提供通用设置，并为其中一些实例调整参数，同时具有一种简单且集中的方式来监视所有配置。如果您希望仲裁器确定哪些节点将是主节点，哪些节点将用作备份节点，则外部配置存储可以为实例提供此类信息。实现配置更新过程也很有用，这样您的实例可以在运行过程中轻松地重新配置。您可以使用现成的解决方案，如 Firebase Remote Config，利用基于 Java 的 Netflix Archaius，或者利用云存储和更改通知在自己的基础上编写配置存储。

既然我们已经了解了一些有用的部署模式，那么当涉及到高级设计时，让我们转到另一个重要的主题: api。

# 管理您的 api

适当的 api 对于开发团队和产品的成功至关重要。我们可以将这个主题分为两个较小的主题: 系统级 api 和组件级 api。在本节中，我们将讨论处理这些级别中的第一个级别的 api，而下一章将向您介绍第二个级别的提示。

除了管理对象之外，您还需要管理整个 API。如果您想引入有关 API 使用的政策，控制对所述 API 的访问，收集性能指标和其他分析数据，或者仅根据客户对接口的使用向客户收费，**API 管理** (**APIM**) 是您正在寻找的解决方案。

通常，一组 APIM 工具由以下组件组成:

*   **API 网关**: 一个 API 的所有用户的单个入口点。在下一节中详细介绍。
*   **Reporting and analytics**: 监控您的 api、消耗的资源或发送的数据的性能和延迟。可以利用这些工具来检测使用趋势，知道 API 的哪些部分以及它们背后的哪些组件是性能瓶颈，或者提供哪些 sla 是合理的，以及如何改进它们。
*   **开发人员的门户**: 帮助他们快速了解您的 API，并完全订阅您的 API。
*   **管理员门户**: 管理策略、用户和将 api 打包到可销售产品中。
*   **货币化**: 根据客户使用 api 的方式向客户收取费用，并帮助相关业务流程。

APIM 工具由云提供商和独立方提供，例如 NGINX 的控制器或 Tyk。

在为给定的云设计 api 时，要了解云提供商通常会记录的良好做法。例如，您可以在*进一步阅读*部分中找到 Google Cloud Platform 的常见设计模式。在他们的情况下，许多做法都是围绕使用 Protobufs 进行的。

选择正确的使用 api 的方式可以使您走很长一段路。向服务器提交请求的最简单方法是直接连接到服务。虽然易于设置，适用于小型应用程序，但它可能会导致未来的性能问题。API 使用者可能需要调用一些不同的服务，从而导致高延迟。使用这种方法也无法实现适当的可伸缩性。

更好的方法是使用 API 网关。这样的网关通常是 APIM 解决方案的重要组成部分，但也可以单独使用。

## API 网关

API 网关是想要使用您的 API 的客户端的入口点。然后，它可以将传入的请求路由到特定的服务实例或集群中。这可以简化您的客户端代码，因为它不再需要知道所有后端节点，或者它们如何相互合作。客户端需要知道的只是 API 网关的地址-网关将处理其余的地址。由于对客户端隐藏了后端架构，因此可以轻松地对其进行改造，甚至无需触摸客户端的代码。

网关可以将系统 API 的多个部分聚合为一个，然后使用**第 7 层路由** (例如，基于 URL) 到系统的适当部分。第 7 层路由由云提供商本身以及 Envoy 等工具提供。

与本章中描述的许多模式一样，请始终考虑是否值得通过在体系结构中引入另一种模式来增加更多的复杂性。考虑一下添加它将如何影响您的可用性，容错性和性能 (如果它们对您很重要)。毕竟，网关通常只是一个节点，因此请尽量不要使其成为瓶颈或单点故障。

我们前面几章提到的前端模式的后端可以被认为是 API 网关模式的一种变体。在 “前端后端” 的情况下，每个前端连接到自己的网关。

现在您已经了解了系统设计与 API 设计的关系，让我们总结一下我们在最后几节中讨论的内容。

# 摘要

在这一章中，我们学到了很多东西。您现在知道何时应用哪种服务模型以及如何避免设计分布式系统的常见陷阱。您已经了解了 CAP 定理以及它对分布式体系结构的实际结果。现在，您可以在此类系统中成功运行事务，减少它们的停机时间，防止出现问题，并从错误中优雅地恢复。处理异常高的负荷不再是黑魔法。将系统的各个部分，甚至是传统的部分，与新设计的部分集成在一起也是您能够执行的事情。现在，您还可以使用一些技巧来提高系统的性能和可伸缩性。部署和负载平衡您的系统也被神秘化，因此您现在可以高效地执行它们。最后但并非最不重要的一点是，发现服务以及设计和管理其 api 是您现在已经学会执行的所有操作。不错!

在下一章中，我们将学习如何使用特定的 C 特性，以更愉快和高效的方式在通往卓越架构的道路上旅行。

# 问题

1.  什么是事件采购？
2.  CAP 定理的实际后果是什么？
3.  您可以使用 Netflix 的 Chaos Monkey 做什么？
4.  缓存在哪里可以应用？
5.  当整个数据中心出现故障时，如何防止应用程序出现故障？
6.  为什么要使用 API 网关？
7.  Envoy 如何帮助您实现各种建筑目标？

# 进一步阅读

*   微软 Azure 云设计模式: [https://docs.microsoft.com/en-us/azure/架构/模式/](https://docs.microsoft.com/en-us/azure/architecture/patterns/)
*   谷歌云 api 的常见设计模式: [https://cloud.google.com/apis/design/ 设计 _ 模式](https://cloud.google.com/apis/design/design_patterns)
*   微软 REST API 指南: [https://github.com/microsoft/ api-指南/blob/vNext/guidelines.md](https://github.com/microsoft/api-guidelines/blob/vNext/Guidelines.md)
*   Envoy Proxy 的*入门*页面: [https://www.envoyproxy.io/docs/envoy/latest/start/start](https://www.envoyproxy.io/docs/envoy/latest/start/start)
*   具有 MongoDB 的主动主动应用程序体系结构: [https://developer.mongodb.com/article/ 主动主动应用程序体系结构](https://developer.mongodb.com/article/active-active-application-architectures)