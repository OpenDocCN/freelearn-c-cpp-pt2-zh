# 自动光学检查、对象分割和检测

在[第 4 章](04.html)，*深入研究直方图和过滤器*中，我们了解了直方图和过滤器，它们使我们能够理解图像操作并创建照片应用程序。

在本章中，我们将介绍目标分割和检测的基本概念。 这意味着隔离图像中出现的对象以供将来处理和分析。

本章介绍以下主题：

*   去噪
*   灯光/背景移除基础知识
*   阈值设置
*   用于对象分割的连通分量
*   寻找轮廓以进行对象分割

许多行业使用复杂的计算机视觉系统和硬件。 计算机视觉试图发现问题并将错误降至最低。

# 技术要求

本章要求熟悉基本的 C++编程语言。 本章中使用的所有代码都可以从以下 giHub 链接下载：[https://github.com/PacktPublishing/Learn-OpenCV-4-By-Building-Projects-Second-Edition/tree/master/Chapter_05](https://github.com/PacktPublishing/Learn-OpenCV-4-By-Building-Projects-Second-Edition/tree/master/Chapter_05)。 该代码可以在任何操作系统上执行，尽管它只在 Ubuntu 上进行了测试。

请查看以下视频，了解实际操作中的代码：
[http://bit.ly/2DRbMbz](http://bit.ly/2DRbMbz)

# 隔离场景中的对象

在本章中，我们将介绍 AOI 算法的第一步，并尝试分离场景中的不同部分或对象。 我们将以三种对象类型(螺丝、密封环和螺母)的对象检测和分类为例，在本章和[第 6 章](06.html)、*学习对象分类*中对其进行开发。

假设我们在一家生产这三种产品的公司。 它们都在同一条载带上。 我们的目标是检测载带中的每个物体，并对每个物体进行分类，以便机器人将每个物体放到正确的架子上：

![](Images/91eceec6-11d9-4b16-820d-cf0197e6f02c.png)

在这一章中，我们是……

# 为 AOI 创建应用程序

要创建我们的新应用程序，我们需要一些输入参数。 当用户执行应用程序时，除了要处理的输入图像外，所有这些都是可选的。 输入参数如下：

*   要处理的输入图像
*   光像图案
*   轻操作，用户可以在差或除操作之间进行选择
*   如果用户将`0`设置为值，则应用差值运算
*   如果用户将`1`设置为值，则应用除法运算
*   分段，用户可以在具有或不具有统计数据的连接组件之间进行选择，并查找等高线方法
*   如果用户将`1`设置为输入值，则应用分段的连通分量方法
*   如果用户将`2`设置为输入值，则应用带有统计区域的连通分量方法
*   如果用户将`3`设置为输入值，则会应用查找等值线方法进行分段

要启用此用户选择，我们将使用带有以下键的`command line parser`类：

```
// OpenCV command line parser functions 
// Keys accepted by command line parser 
const char* keys = 
{ 
  "{help h usage ? | | print this message}" 
   "{@image || Image to process}" 
   "{@lightPattern || Image light pattern to apply to image input}" 
   "{lightMethod | 1 | Method to remove background light, 0 difference, 1 div }" 
   "{segMethod | 1 | Method to segment: 1 connected Components, 2 connected components with stats, 3 find Contours }" 
}; 
```

我们将通过检查参数在`main`函数中使用`command line parser`类。 在*阅读视频和摄像机*部分的[第 2 章](02.html)，*OpenCV*基础简介中解释了`CommandLineParser`：

```
int main(int argc, const char** argv) 
{ 
  CommandLineParser parser(argc, argv, keys); 
  parser.about("Chapter 5\. PhotoTool v1.0.0"); 
  //If requires help show 
  if (parser.has("help")) 
  { 
      parser.printMessage(); 
      return 0; 
  } 

  String img_file= parser.get<String>(0); 
  String light_pattern_file= parser.get<String>(1); 
  auto method_light= parser.get<int>("lightMethod"); 
  auto method_seg= parser.get<int>("segMethod"); 

  // Check if params are correctly parsed in his variables 
  if (!parser.check()) 
  { 
      parser.printErrors(); 
      return 0; 
  } 
```

解析命令行用户数据后，我们需要检查输入图像是否已正确加载。 然后，我们加载图像并检查其是否包含数据：

```
// Load image to process 
  Mat img= imread(img_file, 0); 
  if(img.data==NULL){ 
    cout << "Error loading image "<< img_file << endl; 
    return 0; 
  } 
```

现在，我们准备创建我们的 AOI 细分流程。 我们将从预处理任务开始。

# 对输入图像进行预处理

本节介绍在对象分割/检测上下文中可以应用于图像预处理的一些最常见的技术。 预处理是我们在开始工作并从中提取所需信息之前对新图像所做的第一个更改。 通常，在预处理步骤中，我们会尽量减少由相机镜头引起的图像噪声、光线条件或图像变形。 这些步骤在检测图像中的对象或片段时将误差降至最低。

# 去噪

如果我们不去除噪声，我们可以检测到比我们预期更多的目标，因为噪声通常表示为图像中的小点，并且可以被分割为一个目标。 传感器和扫描仪电路通常会产生此噪声。 这种亮度或颜色的变化可以用不同的类型来表示，例如高斯噪声、尖峰噪声和散粒噪声。

可以使用不同的技术来消除噪音。 这里，我们将使用平滑操作，但根据噪声类型的不同，有些比另一些要好。 中值滤波器通常用于去除胡椒噪声；例如，请考虑下图：

![](Images/578318f1-5c92-42a9-a75a-fb6c2d6cee45.png)

前一幅图像是带有盐和胡椒噪声的原始输入。 如果我们应用中间模糊，我们会得到一个很棒的结果，其中会丢失一些小细节。 例如，我们丢失了螺钉的边缘，但我们保持了完美的边缘。 请参见下图中的结果：

![](Images/ee868769-9c8d-4a81-b863-80c4c3455735.png)

如果我们应用盒过滤器或高斯过滤器，噪声不会被去除，而是变得平滑，对象的细节也会丢失和平滑。 有关结果，请参见下图：

![](Images/ddc55313-3189-4ceb-b113-ec491c19868e.png)

OpenCV 提供了`medianBlur`函数，它需要三个参数：

*   具有`1`、`3`或`4`通道图像的输入图像。 当内核大小大于`5`时，图像深度只能为`CV_8U`。
*   输出图像，它是应用与输入相同类型和深度的中间模糊的结果图像。

*   内核大小，它是大于`1`的奇数孔径大小，例如 3、5、7 等等。

以下代码用于消除噪音：

```
  Mat img_noise; 
  medianBlur(img, img_noise, 3); 
```

# 使用用于分割的光图案去除背景

在这一部分中，我们将开发一个基本算法，使我们能够使用灯光模式删除背景。 这种预处理可以给我们更好的分割效果。 无噪声的输入图像如下：

![](Images/c86fa656-74fa-4826-abe4-7fc224178280.png)

如果我们应用一个基本阈值，我们将获得如下图像结果：

![](Images/b3f80307-88d1-41d1-a11b-87e56bf39eef.png)

我们可以看到上面的图像伪像有很多白噪声。 如果我们应用光图案和背景去除技术，我们可以获得令人惊叹的结果，其中我们可以看到，在那里…

# 阈值设置

在去除背景之后，我们只需要对图像进行二值化，以便将来进行分割。 我们要用 Threshold 来做这件事。 `Threshold`是一个简单的函数，它将每个像素的值设置为最大值(例如 255)。 如果像素的值大于**阈值**值，或者如果像素的值小于**阈值**值，则它将被设置为最小值(0)：

![](Images/d1576ef1-198b-4e9f-ab66-1f109349699f.png)

现在，我们将使用两个不同的`threshold`值来应用`threshold`函数：当我们移除灯光/背景时，我们将使用 30`threshold`值，因为所有不感兴趣的区域都是黑色的。 这是因为我们应用了背景移除。 当我们不使用灯光移除方法时，我们还将使用中值`threshold`(140)，因为我们使用的是白色背景。 最后一个选项用于允许我们在删除和不删除背景的情况下检查结果：

```
  // Binarize image for segment 
  Mat img_thr; 
  if(method_light!=2){ 
   threshold(img_no_light, img_thr, 30, 255, THRESH_BINARY); 
  }else{ 
   threshold(img_no_light, img_thr, 140, 255, THRESH_BINARY_INV); 
  } 
```

现在，我们将继续我们应用程序中最重要的部分：分割。 这里我们将使用两种不同的方法或算法：连通分量和查找轮廓。

# 分割我们的输入图像

现在，我们将介绍两种分割阈值图像的技术：

*   连接的组件
*   查找等高线

使用这两种技术，我们可以提取图像中出现目标对象的每个**感兴趣区域**(**ROI**)。 在我们的例子中，这些是螺母、螺丝和环。

# 连通分量算法

连通分量算法是一种非常常用的算法，用于分割和识别二值图像中的部分。 连通分量是一种迭代算法，其目的是使用八个或四个连通性像素来标记图像。 如果两个像素具有相同的值并且是相邻像素，则这两个像素是相连的。 在图像中，每个像素都有八个相邻像素：

![](Images/b60dde12-2347-4af3-b0a1-063963874bee.png)

四连通性意味着，如果**2**、**4**、**5**和**7**邻居的值与中心像素相同，则它们只能连接到中心。 通过八个连接，如果**1**、**2**、**3**、**4**、**5**、**6**、**7**和**8**邻居的值与中心像素相同，则可以连接它们。 我们可以从四连通性算法和八连通性算法中看出以下示例的不同之处。 我们将把每种算法应用于下一幅二值化图像。 我们使用了一幅小的**9x9**图像，并放大显示了连接组件的工作原理以及四连接和八连接之间的区别：

![](Images/26a8c0f5-f584-4d8b-b660-12eb8b7261f2.png)

四连通性算法检测到两个对象；我们可以在左图中看到这一点。 八连通性算法只检测一个对象(右侧图像)，因为两个对角线像素是相连的。 八连通性处理对角线连通性，这是与四连通性相比的主要区别，因为在四连通性中只考虑垂直和水平像素。 我们可以在下图中看到结果，其中每个对象都有不同的灰色值：

![](Images/b40375cf-b26e-4e47-bb95-189154b06334.png)

OpenCV 为我们带来了具有两种不同功能的连通分量算法：

*   `connectedComponents`(图像，标签，连接性=`8`，类型=`CV_32S`)
*   `connectedComponentsWithStats`(图像，标签，统计信息，质心，连接性=`8`，类型=`CV_32S`)

这两个函数都返回一个带有检测到的标签数量的整数，其中 Label`0`表示背景。 这两个函数之间的区别基本上在于返回的信息。 让我们检查一下每一台的参数。 `connectedComponents`函数为我们提供以下参数：

*   **Image**：要标记的输入图像。
*   **标签**：与输入图像大小相同的输出垫，其中每个像素都有其标签值，其中所有 OS 表示背景，值为`1`的像素表示第一个连接的组件对象，依此类推。
*   **连接性**：表示我们要使用的连接性的两个可能值`8`或`4`。
*   **类型**：我们要使用的标签图像的类型。 只允许两种类型：`CV32_S`和`CV16_U`。 默认情况下，这是`CV32_S`。
*   `connectedComponentsWithStats`函数还定义了两个参数。 以下是统计数据和质心：
    *   **Stats**：这是一个输出参数，为我们提供每个标签的以下统计值(包括背景)：
        *   `CC_STAT_LEFT`：连接组件对象最左侧的`x`坐标
        *   `CC_STAT_TOP`：连接的组件对象的最上面的`y`坐标
        *   `CC_STAT_WIDTH`：由其边界框定义的连接组件对象的宽度
        *   `CC_STAT_HEIGHT`：由其边界框定义的连接组件对象的高度
        *   `CC_STAT_AREA`：连接组件对象的像素数(面积)
    *   **质心**：质心指向每个标签的浮动类型，包括考虑用于另一个连接组件的背景。

在我们的示例应用程序中，我们将创建两个函数，以便可以应用这两个 OpenCV 算法。 然后，我们将在具有基本连通分量算法的带有彩色对象的新图像中向用户显示所获得的结果。 如果我们使用 stats 方法选择连通组件，我们将在每个对象上绘制返回此函数的相应计算区域。

让我们定义连通组件函数的基本绘图：

```
void ConnectedComponents(Mat img) 
{ 
  // Use connected components to divide our image in multiple connected component objects
     Mat labels; 
     auto num_objects= connectedComponents(img, labels); 
  // Check the number of objects detected 
     if(num_objects < 2 ){ 
        cout << "No objects detected" << endl; 
        return; 
      }else{ 
       cout << "Number of objects detected: " << num_objects - 1 << endl; 
      } 
  // Create output image coloring the objects 
     Mat output= Mat::zeros(img.rows,img.cols, CV_8UC3); 
     RNG rng(0xFFFFFFFF); 
     for(auto i=1; i<num_objects; i++){ 
        Mat mask= labels==i; 
        output.setTo(randomColor(rng), mask); 
      } 
     imshow("Result", output); 
} 
```

首先，我们调用 OpenCV`connectedComponents`函数，该函数返回检测到的对象数量。 如果对象的数量少于两个，这意味着只检测到背景对象，然后我们不需要绘制任何东西，就可以完成。 如果算法检测到多个对象，我们会显示控制台上检测到的对象数量：

```
  Mat labels; 
  auto num_objects= connectedComponents(img, labels); 
  // Check the number of objects detected 
  if(num_objects < 2){ 
    cout << "No objects detected" << endl; 
    return; 
  }else{ 
    cout << "Number of objects detected: " << num_objects - 1 << endl;
```

现在，我们要用不同的颜色在新图像中绘制所有检测到的对象。 在此之后，我们需要创建一个具有相同输入大小和三个通道的新黑色图像：

```
Mat output= Mat::zeros(img.rows,img.cols, CV_8UC3); 
```

我们将循环遍历除`0`值之外的每个标签，因为这是背景：

```
for(int i=1; i<num_objects; i++){ 
```

要从标签图像中提取每个对象，我们可以使用比较为每个`i`标签创建一个蒙版，并将其保存在新图像中：

```
    Mat mask= labels==i; 
```

最后，我们使用`mask`为输出图像设置伪随机颜色：

```
    output.setTo(randomColor(rng), mask); 
  } 
```

在循环所有图像之后，我们的输出中有所有检测到的不同颜色的对象，我们只需在窗口中显示输出图像：

```
imshow("Result", output); 
```

这是使用不同颜色或灰度值绘制每个对象的结果：

![](Images/c1ba4e5a-e7ba-4e3e-b50f-1feb158a6dab.png)

现在，我们将解释如何将连通分量与`stats`OpenCV 算法一起使用，并在生成的图像中显示更多信息。 以下函数实现此功能：

```
void ConnectedComponentsStats(Mat img) 
{ 
  // Use connected components with stats 
  Mat labels, stats, centroids; 
  auto num_objects= connectedComponentsWithStats(img, labels, stats, centroids); 
  // Check the number of objects detected 
  if(num_objects < 2 ){ 
    cout << "No objects detected" << endl; 
    return; 
  }else{ 
    cout << "Number of objects detected: " << num_objects - 1 << endl; 
  } 
  // Create output image coloring the objects and show area 
  Mat output= Mat::zeros(img.rows,img.cols, CV_8UC3); 
  RNG rng( 0xFFFFFFFF ); 
  for(auto i=1; i<num_objects; i++){ 
    cout << "Object "<< i << " with pos: " << centroids.at<Point2d>(i) << " with area " << stats.at<int>(i, CC_STAT_AREA) << endl; 
    Mat mask= labels==i; 
    output.setTo(randomColor(rng), mask); 
    // draw text with area 
    stringstream ss; 
    ss << "area: " << stats.at<int>(i, CC_STAT_AREA); 

    putText(output,  
      ss.str(),  
      centroids.at<Point2d>(i),  
      FONT_HERSHEY_SIMPLEX,  
      0.4,  
      Scalar(255,255,255)); 
  } 
  imshow("Result", output); 
} 
```

让我们来理解一下这段代码。 正如我们在非统计函数中所做的那样，我们调用了 Connected Components 算法，但在这里，我们使用`stats`函数来执行此操作，以检查我们是否检测到多个对象：

```
Mat labels, stats, centroids; 
  auto num_objects= connectedComponentsWithStats(img, labels, stats, centroids); 
  // Check the number of objects detected 
  if(num_objects < 2){ 
    cout << "No objects detected" << endl; 
    return; 
  }else{ 
    cout << "Number of objects detected: " << num_objects - 1 << endl; 
  }
```

现在，我们又有了两个输出结果：统计数据和质心变量。 然后，对于每个检测到的标签，我们将通过命令行显示质心和区域：

```
for(auto i=1; i<num_objects; i++){ 
    cout << "Object "<< i << " with pos: " << centroids.at<Point2d>(i) << " with area " << stats.at<int>(i, CC_STAT_AREA) << endl; 
```

您可以检查对 stats 变量的调用，以使用列常量`stats.at<int>(I, CC_STAT_AREA)`提取区域。 现在，像以前一样，我们在输出图像上绘制标有`i`的对象：

```
Mat mask= labels==i; 
output.setTo(randomColor(rng), mask); 
```

最后，在每个分割对象的质心位置，我们希望在生成的图像上绘制一些信息(如面积)。 为此，我们使用`putText`函数的 STATS 和质心变量。 首先，我们必须创建一个`stringstream`，以便可以添加统计区域信息：

```
// draw text with area 
stringstream ss; 
ss << "area: " << stats.at<int>(i, CC_STAT_AREA); 
```

然后，我们需要使用`putText`，使用质心作为文本位置：

```
putText(output,  
  ss.str(),  
  centroids.at<Point2d>(i),  
  FONT_HERSHEY_SIMPLEX,  
  0.4,  
  Scalar(255,255,255)); 
```

此函数的结果如下所示：

![](Images/10e79360-47ac-4ae7-83c2-67547df40016.png)

# FindContours 算法

在分割对象时，`findContours`算法是最常用的 OpenCV 算法之一。 这是因为此算法是从 1.0 版开始包含在 OpenCV 中的，它为开发人员提供了更多信息和描述符，包括形状、拓扑组织等：

```
void findContours(InputOutputArray image, OutputArrayOfArrays contours, OutputArray hierarchy, int mode, int method, Point offset=Point()) 
```

下面我们来解释一下每个参数：

*   **图像**：输入二进制图像。
*   **轮廓**：轮廓的输出，其中每个检测到的轮廓都是点的矢量。
*   **层次**：这是保存等高线层次的可选输出向量。 这是图像的拓扑结构，在这里我们可以得到……之间的关系。

# 简略的 / 概括的 / 简易判罪的 / 简易的

在本章中，我们探讨了在摄像机拍摄不同对象的受控情况下对象分割的基础知识。 在这里，我们学习了如何去除背景和光线，以便更好地对图像进行二值化，从而将噪声降至最低。 在对图像进行二值化之后，我们了解了三种不同的算法，这些算法可用于分割和分离图像中的每个对象，从而使我们能够隔离每个对象以操作或提取特征。

我们可以在下图中看到整个过程：

![](Images/617ededa-c684-4f4c-b460-2d1fe8d99849.png)

最后，我们提取了一幅图像上的所有对象。 您需要这样做才能继续下一章，在下一章中，我们将提取每个对象的特征来训练机器学习系统。

在下一章中，我们将预测图像中任何物体的类别，然后呼叫机器人或任何其他系统来挑选它们中的任何一个，或者检测不在正确载体带上的物体。 然后，我们将研究如何通知一个人来取它。