# 使用 Tesseract 进行文本识别

在[第 10 章](10.html)，*开发用于文本识别的分割算法*中，我们介绍了非常基本的 OCR 处理函数。 虽然它们对于扫描或拍照的文档非常有用，但在处理随意出现在图片中的文本时几乎毫无用处。

在本章中，我们将探索 OpenCV 4.0 文本模块，该模块专门处理场景文本检测。 使用此接口，可以检测网络摄像头视频中出现的文本，或者分析拍摄的图像(如街景或监控摄像头拍摄的图像)，以实时提取文本信息。 这允许创建范围广泛的应用，从可访问性到营销，甚至是机器人领域。

在本章结束时，您将能够执行以下操作：

*   了解什么是场景文本识别
*   了解 Text API 的工作原理
*   使用 OpenCV 4.0 Text API 检测文本
*   将检测到的文本提取到图像中
*   使用 Text API 和 Tesseract 集成来识别字母

# 技术要求

本章要求熟悉基本的 C++ 编程语言。 本章使用的所有代码都可以从以下 giHub 链接下载：[https://github.com/PacktPublishing/Learn-OpenCV-4-By-Building-Projects-Second-Edition/tree/master/Chapter_11](https://github.com/PacktPublishing/Learn-OpenCV-4-By-Building-Projects-Second-Edition/tree/master/Chapter_11)。 该代码可以在任何操作系统上执行，尽管它只在 Ubuntu 上进行了测试。

请查看以下视频以了解实际操作的代码：[http://bit.ly/2Slht5A](http://bit.ly/2Slht5A)

# Text API 的工作原理

Text API 实现了*Lukás Neumann*和*Jiri Matas*在 2012 年**计算机视觉和模式识别**(**CVPR**)会议期间在文章*Real*-*Time Scene Text Location and Recognition*中提出的算法。 该算法代表了场景文本检测的显著提高，在 CVPR 数据库和 Google Street View 数据库中都执行了最先进的检测。 在使用 API 之前，让我们先来看看这个算法是如何在幕后工作的，以及它是如何解决场景文本检测问题的。

**Remember**: The OpenCV 4.0 text API does not come with the standard OpenCV modules. It's an additional module that's present in the OpenCV `contrib` package. If you installed OpenCV using the Windows Installer, you should take a look back at [Chapter 1](01.html), *Getting Started with OpenCV;* this will guide you on how to install these modules.

# 场景检测问题

检测场景中随机出现的文本是一个比看起来更难的问题。 在与识别的扫描文本进行比较时，需要考虑以下几个新变量：

*   **三维性**：文本可以是任何比例、方向或视角。 此外，文本可能被部分遮挡或中断。 从字面上看，它可能出现在图像中的区域有数千个。
*   **Varity**：文本可以有几种不同的字体和颜色。 字体可能有轮廓边框。 背景可以是深色、浅色或复杂的图像。
*   **照明和阴影**：太阳光的位置和外观颜色随时间变化。 不同的天气条件比如..。

# 极值区域

极值区域是以几乎均匀的强度为特征的连通区域，周围环绕着对比鲜明的背景。 一个区域的稳定性可以通过计算该区域对阈值变化的抵抗力来衡量。 这种差异可以用一种简单的算法来测量：

1.  应用阈值，生成图像*A*。 检测其连接的像素区域(极值区域)。
2.  将阈值增加一个增量，生成图像*B*。 检测其连接的像素区域(极值区域)。
3.  将图像*B*与*A*进行比较。 如果图像 A 中的某个区域与图像*B*中的相同区域相似，则将其添加到树中的同一分支。 相似性的标准可能因实现而异，但通常与图像区域或一般形状有关。 如果图像*A*中的区域似乎在图像*B*中被拆分，则在树中为新区域创建两个新分支，并将其与前一个分支相关联。
4.  设置*A*=*B*并返回步骤 2，直到应用最大阈值。

这将组装一个区域树，如下所示：

![](img/c9442351-9576-48c7-b6c7-46bf4361eb11.png)

对方差的抵抗力是通过计算同一级别中有多少个节点来确定的。 通过分析这棵树，还可以确定**个最稳定的极值区域**(**MSER**s)，即该区域在各种阈值下保持稳定的区域。 在上图中，很明显这些区域将包含字母***O***、***N***和***Y***。 最大极值区域的主要缺点是它们在存在模糊的情况下很弱。 OpenCV 在**Feature 2d**模块中提供了一个 MSER 特性检测器。 极值区域很有趣，因为它们对光照、比例和方向都有很强的不变性。 它们也是很好的文本候选者，因为它们在使用的字体类型方面也是不变的，即使在设置了字体样式的情况下也是如此。 还可以分析每个区域以确定其边界省略，并且可以具有仿射变换和数值确定的面积等属性。 最后，值得一提的是，整个过程速度很快，这使得它成为实时应用的一个非常好的候选者。

# 极值区域滤波

虽然 MSER 是定义哪些极端区域值得使用的常用方法，但*Neumann*和*Matas*算法使用不同的方法，将所有极端区域提交给经过字符检测训练的顺序分类器。 此分类器在两个不同的阶段工作：

1.  第一阶段递增地计算每个区域的描述符(边界框、周长、面积和欧拉数)。 这些描述符被提交给分类器，该分类器估计该区域成为字母表中的字符的可能性有多大。 然后，仅为阶段 2 选择高概率区域。
2.  在这一阶段，综合考虑了整体面积比、凸壳比、外边界数等特征。

# 使用 Text API

理论说得够多了。 现在我们来看看文本模块在实践中是如何工作的。 让我们研究一下如何使用它来执行文本检测、提取和识别。

# 文本检测

让我们从创建一个简单的程序开始，这样我们就可以使用**ERFilters**执行文本分割。 在本程序中，我们将使用文本 API 样本中训练好的分类器。 您可以从 OpenCV 资源库下载，但也可以在本书的配套代码中找到。

首先，我们首先包括所有必要的`libs`和`usings`：

```cpp
#include  "opencv2/highgui.hpp" 
#include  "opencv2/imgproc.hpp" 
#include  "opencv2/text.hpp" 

#include  <vector> 
#include  <iostream> 

using namespace std; 
using namespace cv; 
using namespace cv::text; 
```

回想一下*极值区域滤波*部分，`ERFilter`在每个图像通道中单独工作。 因此，我们必须提供一种方法，将每个想要的频道分开到不同的…

# 文本提取

既然我们已经检测到区域，我们必须在将文本提交给 OCR 之前对其进行裁剪。 我们可以简单地使用像`getRectSubpix`或`Mat::copy`这样的函数，将每个区域矩形用作感兴趣的**区域**(**ROI**)，但是，由于字母倾斜，一些不需要的文本也可能被裁剪。 例如，如果我们仅根据给定的矩形提取 ROI，则其中一个区域的外观如下所示：

![](img/f227149d-3d30-4a84-9a38-4af84e3ead02.png)

幸运的是，`ERFilter`为我们提供了一个名为`ERStat`的对象，它包含每个极端区域内的像素。 有了这些像素，我们就可以使用 OpenCV 的`floodFill`函数来重建每个字母。 此函数能够基于种子点绘制相似颜色的像素，就像大多数绘图应用的**bucket**工具一样。 函数签名如下所示：

```cpp
int floodFill(InputOutputArray image, InputOutputArray mask,  Point seedPoint, Scalar newVal, 
 CV_OUT Rect* rect=0, Scalar loDiff = Scalar(), Scalar upDiff = Scalar(), int flags = 4 ); 
```

让我们了解一下这些参数以及它们的使用方法：

*   `image`：输入图像。 我们将使用拍摄极端区域的通道图像。 除非提供了`FLOODFILL_MASK_ONLY`，否则这是该函数通常执行泛洪填充的位置。 在这种情况下，图像保持不变，绘制发生在蒙版中。 这正是我们要做的。
*   `mask`：蒙版必须是比输入图像大两行两列的图像。 当整体填充绘制像素时，它会验证蒙版中相应的像素是否为零。 在这种情况下，它将绘制该像素并将其标记为 1(或传递到标志中的另一个值)。 如果像素不为零，则整体应用填充不会绘制像素。 在我们的例子中，我们将提供一个空白蒙版，这样每个字母都会被绘制到蒙版中。
*   `seedPoint`：起点。 它类似于您想要使用图形应用的**Bucket**工具时单击的位置。
*   `newVal`：重新绘制的像素的新值。
*   `loDiff`和`upDiff`：这些参数表示正在处理的像素与其相邻像素之间的上下差异。 如果邻居落在这个范围内，它就会被画出来。 如果使用`FLOODFILL_FIXED_RANGE`标志，则将使用种子点和正在处理的像素之间的差值。
*   `rect`：这是一个可选参数，用于限制将应用泛洪填充的区域。
*   `flags`：该值由位掩码表示：
    *   标志的最低有效 8 位包含连接值。 值`4`表示将使用所有四个边缘像素，值`8`表示还必须考虑对角线像素。 我们将使用`4`作为此参数。
    *   接下来的 8 到 16 位包含一个从`1`到`255`的值，用于填充掩码。 因为我们想用白色填充蒙版，所以我们将使用`255 << 8`作为此值。
    *   正如我们已经描述的，可以通过添加`FLOODFILL_FIXED_RANGE`和`FLOODFILL_MASK_ONLY`标志来设置另外两位。

我们将创建一个名为`drawER`的函数。 此函数将接收四个参数：

*   具有所有已处理通道的矢量
*   `ERStat`区域
*   必须抽签的组
*   组矩形

此函数将返回包含由该组表示的单词的图像。 让我们通过创建遮罩图像并定义标志来开始此函数：

```cpp
Mat out = Mat::zeros(channels[0].rows+2, channels[0].cols+2, CV_8UC1); 

int flags = 4                    //4 neighbors 
   + (255 << 8)                        //paint mask in white (255) 
   + FLOODFILL_FIXED_RANGE       //fixed range 
   + FLOODFILL_MASK_ONLY;        //Paint just the mask 
```

然后，我们将遍历每组。 有必要找出地区指数及其地位。 这个极端的区域有可能是根，它不包含任何点。 在本例中，我们将忽略它：

```cpp
for (int g=0; g < group.size(); g++) 
{ 
   int idx = group[g][0];         
   auto er = regions[idx][group[g][1]]; 

//Ignore root region 
   if (er.parent == NULL)  
         continue; 
```

现在，我们可以从`ERStat`对象读取像素坐标。 它由像素数表示，从上到下，从左到右计数。 此线性索引必须转换为行(*y*)和列(*z*)表示法，使用与我们在[第 2 章](02.html)，*OpenCV*基础简介中看到的公式类似的公式：

```cpp
int px = er.pixel % channels[idx].cols; 
int py = er.pixel / channels[idx].cols; 
Point p(px, py); 
```

然后，我们可以调用`floodFill`函数。 `ERStat`对象为我们提供了要在`loDiff`参数中使用的值：

```cpp
floodFill( 
    channels[idx], out,          //Image and mask 
    p, Scalar(255),              //Seed and color 
    nullptr,                     //No rect 
    Scalar(er.level),Scalar(0),  //LoDiff and upDiff 
    flags                        //Flags 
```

在对组中的所有区域执行此操作后，我们将以一个比原始图像稍大的图像结束，该图像的背景为黑色，单词为白色字母。 现在，让我们只裁剪字母的区域。 由于给出了区域矩形，我们首先将其定义为感兴趣的区域：

```cpp
out = out(rect);
```

然后，我们将找到所有非零像素。 这是我们将在`minAreaRect`函数中使用的值，以获得围绕字母旋转的矩形。 最后，我们将借用上一章的`deskewAndCrop`函数为我们裁剪和旋转图像：

```cpp
   vector<Point> points;    
   findNonZero(out, points); 
   //Use deskew and crop to crop it perfectly 
   return deskewAndCrop(out, minAreaRect(points)); 
} 
```

这是画架图像处理的结果：

![](img/ae3ff958-8639-4052-aa97-c6474f119b77.png)

# 文本识别

在[第 10 章](10.html)，*开发用于文本识别的分割算法中，*我们直接使用了 Tesseract API 来识别文本区域。 这一次，我们将使用 OpenCV 类来实现相同的目标。

在 OpenCV 中，所有特定于 OCR 的类都派生自**BaseOCR**虚拟类。 此类为 OCR 执行方法本身提供公共接口。 特定的实现必须从该类继承。 默认情况下，文本模块提供三种不同的实现：**OCRTesseract**、**OCRHMMDecoder**和**OCRBeamSearchDecoder**。

下面的类图描述了此层次结构：

![](img/463bba5c-a8d2-4b38-b981-7c4d7e23b74f.png)

用这种方法，我们可以把……

# 简略的 / 概括的 / 简易判罪的 / 简易的

在本章中，我们看到场景文本识别比处理扫描文本要困难得多。 我们研究了文本模块如何使用*Newmann*和*Matas*算法进行极值区域识别。 我们还了解了如何使用此 API 和`floodFill`函数将文本提取到图像中，并将其提交给 Tesseract OCR。 最后，我们学习了 OpenCV 文本模块如何与 Tesseract 和其他 OCR 引擎集成，以及如何使用它的类来识别图像中所写的内容。

在下一章中，我们将向您介绍 OpenCV 中的深度学习。 您将通过使用**只看一次**(**YOLO**)算法了解对象检测和分类。