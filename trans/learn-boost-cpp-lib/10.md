# 第 10 章.使用 Boost 实现并发

**线程**表示进程内的个并发执行流。 它们是**并发**的低级抽象，由操作系统的系统编程库或系统调用接口(例如 POSIX 线程、Win32Thread)公开。 在多处理器或多核系统上，操作系统可以调度同一进程中的两个线程在两个不同的核心上并行运行，从而实现真正的**并行性**。

线程是一种流行的机制，用于抽象可能与其他此类任务并行运行的并发任务。 如果处理得当，线程可以简化程序结构并提高性能。 然而，并发性和并行性引入了单线程程序中看不到的复杂性和不确定性行为，当涉及到线程时，正确处理往往是最大的挑战。 操作系统之间的本机多线程库或接口存在很大差异，这使得使用线程编写可移植并发软件的任务变得更加困难。 Boost Thread 库通过提供可移植接口来为并发任务创建线程和更高级别的抽象，从而解决了这个问题。 **Boost 协程**库提供了一种机制来创建协作*协程*或可以退出和恢复的函数，从而在这样的调用之间保留自动对象的状态。 协程可以用一种更简单的方式表达事件驱动的逻辑，并且在某些情况下避免了线程的开销。

本章是对 Boost Thread 库使用的实践介绍，同时还简要介绍了 Boost Cooutine 库。 它分为以下几个部分：

*   使用 Boost 线程创建并发任务
*   并发、信令和同步
*   增强协程程序

即使您从未编写过多线程程序或并发软件，这也是一个很好的起点。 我们还将讨论 C++ 11 标准库中的线程库，它基于 Boost Thread 库并引入了额外的改进。

# 使用 Boost 线程创建并发任务

考虑一个用不同语言打印问候语的程序。 英语、德语、荷兰语、丹麦语等盎格鲁-撒克逊语有一个问候语列表。 还有第二种罗曼语问候语，如意大利语、西班牙语、法语、葡萄牙语等等。 两个语言组的问候语都需要打印，我们不想因为一个组的问候语打印延迟，也就是说，我们希望同时打印两个组*的问候语*。 以下是打印这两组问候语的一种方式：

**清单 10.1：交错任务**

```cpp
 1 #include <iostream>
 2 #include <string>
 3 #include <vector>
 4
 5 int main()
 6 {
 7   typedef std::vector<std::string> strvec;
 8
 9   strvec angloSaxon{"Guten Morgen!", "Godmorgen!", 
10                    "Good morning!", "goedemorgen"};
11
12   strvec romance{"Buenos dias!", "Bonjour!", 
13                  "Bom dia!", "Buongiorno!"};
14
15   size_t max1 = angloSaxon.size(), max2 = romance.size();
16   size_t i = 0, j = 0;
17
18   while (i < max1 || j < max2) {
19     if (i < max1)
20       std::cout << angloSaxon[i++ ] << '\n';
21
22     if (j < max2)
23       std::cout << romance[j++ ] << '\n';
24   }
25 }
```

在前面的示例中，我们有两个问候语矢量，打印每个矢量中的问候语是一项独立的任务。 我们通过从每个数组打印一个问候语来交替执行这两个任务，因此这两个任务同时进行。 从代码中我们可以看出，拉丁语和盎格鲁-撒克逊问候语将按如下所示的顺序交替打印：

```cpp
Buenos dias!
Guten Morgen!
Bonjour!
Godmorgen!
Bom dia!
Good morning!
Buongiorno!
goedemorgen
```

虽然这两个任务是交错运行的，从这个意义上说，它们在代码中的区别完全混淆到了在单个函数中编码的程度。 通过将它们分离为单独的函数并在单独的线程中运行，任务可以完全彼此解耦，但仍可并发运行。 此外，线程将允许其并行执行。

## 使用 Boost 线程

每个正在运行的进程至少有一个执行线程。 带有`main`函数的传统“hello world”程序也有一个线程，通常称为**主线程**。 这样的程序称为**单线程**。 使用 Boost Thread，我们可以创建具有多个运行并发任务的执行线程的程序。 我们可以使用 Boost Thread 重写清单 10.1，这样就可以清楚地分解出单个任务的代码，并且当并行硬件可用时，这些任务可能会并行运行。 以下是我们可以如何做到这一点：

**清单 10.2：作为线程的并发任务**

```cpp
 1 #include <boost/thread.hpp>
 2 #include <string>
 3 #include <vector>
 4 #include <iostream>
 5
 6 typedef std::vector<std::string> strvec;
 7 
 8 void printGreets(const strvec& greets)
 9 {
10   for (const auto& greet : greets) {
11     std::cout << greet << '\n';
12   }
13 }
14
15 int main()
16 {
17   strvec angloSaxon{"Guten Morgen!", "Godmorgen!", 
18                    "Good morning!", "goedemorgen"};
19
20   strvec romance{"Buenos dias!", "Bonjour!", 
21                  "Bom dia!", "Buongiorno!"};
15
16   boost::thread t1(printGreets, romance);
17   printGreets(angloSaxon);
18   t1.join();
19 }
```

我们定义了一个函数`printGreets`，该函数接受一个问候语向量并打印该向量中的所有问候语(第 8-13 行)。 这是任务的代码，经过简化和分解后的代码。 该函数在两个问候语向量上各调用一次。 它从在主线程中执行的`main`函数调用一次(第 17 行)，从我们通过实例化类型`boost::thread`的对象产生的第二个执行线程调用一次，向它传递要调用的函数及其参数(第 16 行)。 头文件`boost/thread.hpp`提供了使用 Boost Thread(第 1 行)所需的类型和函数。

类型为`boost::thread`的对象`t1`包装本机线程，例如`pthread_t`、Win32 线程`HANDLE`等。 为简明起见，我们只引用“线程`t1`”来表示底层线程以及包装它的`boost::thread`对象，除非有必要区分这两者。 对象`t1`是通过传递函数对象(线程的初始函数)和要传递给函数对象的所有参数来构造的(第 16 行)。 在构造时，底层本机线程通过使用提供的参数调用传递的函数立即开始运行。 当此函数返回时，线程终止。 这与从`main`函数调用的`printGreets`函数同时发生(第 17 行)。

此程序的一种可能输出是：

```cpp
Guten Morgen!
Buenos dias!
Godmorgen!
Bonjour!
Bom dia!
Good morning!
Buongiorno!
goedemorgen
```

拉丁语问候语按照它们在`romance`矢量中出现的顺序打印，盎格鲁-撒克逊问候语按照它们在`angloSaxon`矢量中出现的顺序打印。 但它们交错的顺序是不可预测的。 这种确定性的缺乏是并发编程的一个关键特征，也是造成一些困难的原因之一。 可能更令人不安的是，甚至可能出现以下输出：

```cpp
Guten Morgen!
Buenos dGodmorgeias!
n!
Bonjour!
Bom dia! Good morning!
Buongiorno!
goedemorgen
```

请注意，两个问候语`Buenos dias!`(西班牙语)和`Godmorgen!`(荷兰语)是交错的，并且在打印`Bom dia!`之后的新行之前打印了`Good morning!`。

我们在`t1`上调用`join`成员函数以等待底层线程终止(第 18 行)。 由于主线程和线程`t1`同时运行，因此它们中的任何一个都可以在另一个线程之前终止。 如果`main`函数首先终止，则它将终止程序，并且在线程`t1`中运行的`printGreets`函数将在其完成执行之前被终止。 通过调用`join`，Main 函数确保它不会在`t1`仍在运行时退出。

### 备注

**链接 Boost 线程库**

Boost Thread 不是仅包含头文件的库，而是必须从源代码构建的库。 [第 1 章](01.html "Chapter 1. Introducing Boost")，*Boost*简介，描述了从 Boost 库的源代码、它们的**名称布局变体**和命名约定构建 Boost 库的细节。

要从清单 10.2 构建一个正在运行的程序，您需要将编译后的对象与这些库链接起来。 要构建前面的示例，必须链接 Boost Thread 和 Boost 系统库。 在 Linux 上，您还必须链接到`libpthread`，它包含 Pthread 库实现。

假设源文件为`Listing9_2.cpp`，下面是 Linux 上的 g++ 命令行，用于编译和链接源代码以构建二进制文件：

```cpp
$ g++ Listing9_2.cpp -o Listing9_2 -lboost_thread -lboost_system –lboost_chrono –pthread 
```

只有当我们使用 Boost 计时库时，才需要链接到`libboost_chrono`。 选项`-pthread`设置必要的预处理器和链接器标志，以启用编译多线程应用并将其链接到`libpthread`。 如果您没有使用本机包管理器在 Linux 上安装 Boost，或者如果您试图在其他平台(如 Windows)上构建，请参阅[第 1 章](01.html "Chapter 1. Introducing Boost")，*Boost*简介中的详细构建说明。

如果您使用的是 C++ 11，则可以使用标准库线程而不是 Boost 线程。 为此，您必须包含标准库头`thread`，并使用`std::thread`而不是`boost::thread`。 Boost Thread 和`std::thread`不是相互替代的替代产品，因此需要进行一些更改。

### 移动线程和等待线程

`std::thread`的对象与进程中的恰好一个线程相关联并对其进行管理。 请考虑以下代码片段：

```cpp
 1 void threadFunc() { ... }
 2
 3 boost::thread makeThread(void (*thrFunc)()) {
 4   assert(thrFunc);
 5   boost::thread thr(thrFunc);
 6   // do some work
 7   return thr;
 8 }
 9
10 int main() {
11   auto thr1 = makeThread(threadFunc);
12   // ...
13   thr1.join();
14 }
```

当创建`boost::thread`对象`thr`时(第 4 行)，它与一个新的本机线程(`pthread_t`、Windows 线程的句柄等)相关联，该线程执行`thrFunc`所指向的函数。 现在`boost::thread`是可移动的类型，但不是可复制的类型。 当`makeThread`函数按值返回`thr`时(第 7 行)，底层本机线程句柄的所有权从`makeThread`中的对象`thr`移动到`main`函数中的`thr1`(第 11 行)。 因此，您可以在一个函数中创建线程并将其返回给调用函数，*在进程中转移所有权*。

最终，我们通过调用`join`等待线程在`main`函数内完成执行(第 13 行)。 这确保了在线程`thr1`终止之前，`main`函数不会退出。 现在完全有可能在`makeThread`返回`thr`时，底层线程已经完成执行。 在本例中，`thr1.join()`(第 13 行)立即返回。 另一方面，底层线程可以在主线程上的控制权转移到`main`函数时继续执行，甚至在`thr1`上调用`join`时也可以继续执行(第 13 行)。 在这种情况下，`thr1.join()`将阻塞，等待线程退出。

有时，我们可能希望线程运行并退出，我们再也不会费心去检查它了。 此外，线程是否终止可能并不重要。 想象一下一个个人金融桌面应用，它有一个漂亮的股票报价器线程，可以在窗口的一角显示一组可配置的公司的股票价格。 它由主应用启动，并继续执行获取股票最新价格并显示它们的工作，直到应用退出。 对于主线程来说，在退出之前等待这个线程几乎没有什么意义。 当应用终止时，股票报价器线程也会终止并在其唤醒过程中被清理。 我们可以通过在`boost::thread`对象上调用`detach`来显式请求线程的此行为，如以下代码片断所示：

```cpp
 1 int main() {
 2   boost::thread thr(thrFunc, arg1, ...);
 3   thr.detach();
 4   // ...
 5 }
```

当我们在`boost::thread`对象上调用时，底层本机线程的所有权被传递给 C++ 运行时，C++ 运行时继续执行该线程，直到线程终止或程序终止，终止该线程。 在调用`detach`之后，`boost::thread`对象不再引用有效的线程，并且程序不再能够检查线程的状态或以任何方式与其交互。

当且仅当在`boost::thread`对象上既没有调用`detach`也没有调用`join`时，线程才被称为可接合的。 当且仅当线程可接合时，`boost::thread`上的`joinable`方法返回`true`。 如果对不可接合的`boost::thread`对象调用`detach`或`join`，调用将立即返回，而不会产生其他效果。 如果我们没有对`boost::thread`对象调用`join`，那么当线程超出作用域时，就会在其析构函数中调用`detach`。

### 备注

`boost::thread`和`std::thread`之间的差异

必须对`std::thread`对象调用`join`或`detach`；否则，`std::thread`的析构函数将调用`std::terminate`并中止程序。 此外，在不可接合的`std::thread`上调用`join`或`detach`将导致抛出`std::system_error`异常。 因此，您在`std::thread`上调用`join`和`detach`中的任何一个，并且只调用一次。 这与我们刚才描述的`boost::thread`的行为形成对比。

通过定义以下预处理器宏，我们可以让`boost::thread`模拟`std::thread`的这种行为，最好在您编写的任何新代码中模拟`std::thread`的行为：

```cpp
BOOST_THREAD_TRHOW_IF_PRECONDITION_NOT_SATISFIED BOOST_THREAD_PROVIDES_THREAD_DESTRUCTOR_CALLS_TERMINATE_IF_JOINABLE
```

### 线程 ID

在任何时候，进程中的每个运行线程都有一个唯一的标识符。 该标识符由类型`boost::thread::id`表示，可以通过调用`get_id`方法从`boost::thread`对象获取。 要获得当前线程的 ID，我们必须使用`boost::this_thread::get_id()`。 可以使用重载插入运算符(`operator<<`)将 ID 的字符串表示打印到`ostream`对象。

线程 ID可以使用`operator<`进行排序，因此可以轻松地将它们存储在有序的关联容器(`std::set`/`std::map`)中。 线程 ID 可以使用`operator==`进行比较，也可以存储在无序关联容器中(`std::unordered_set`/`std::unordered_map`)。 将线程存储在按其 ID 索引的关联容器中是支持线程查找的有效方法：

**清单 10.3：使用线程 ID**

```cpp
 1 #include <boost/thread.hpp>
 2 #include <boost/chrono/duration.hpp>
 3 #include <vector>
 4 #include <map>
 5 #include <iostream>
 6 #include <sstream>
 7 #include <boost/move/move.hpp>
 8
 9 void doStuff(const std::string& name) {
10   std::stringstream sout;
11   sout << "[name=" << name << "]"
12     << "[id=" << boost::this_thread::get_id() << "]"
13     << " doing work\n";
14   std::cout << sout.str();
15   boost::this_thread::sleep_for(boost::chrono::seconds(2));
16 }
17
18 int main() {
19   typedef std::map<boost::thread::id, boost::thread> threadmap;
20   threadmap tmap;
21
22   std::vector<std::string> tnames{ "thread1", "thread2",
23                             "thread3", "thread4", "thread5" };
24   for (auto name : tnames) {
25     boost::thread thr(doStuff, name);
26     tmap[thr.get_id()] = boost::move(thr);
27   }
28
29   for (auto& thrdEntry : tmap) {
30     thrdEntry.second.join();
31     std::cout << thrdEntry.first << " returned\n";
32   }
33 }
```

在前面的示例中，我们创建了五个线程，每个线程都运行函数`doStuff`。 向函数`doStuff`传递其运行的线程的指定名称；我们将线程命名为`thread1`到`thread5`，并将它们放入按其 ID 索引的`std::map`中(第 26 行)。 因为`boost::thread`是可移动的，但不是可复制的，所以我们将线程对象移动到地图中。 `doStuff`函数只是使用方法`boost::this_thread::get_id`(第 12 行)打印当前线程的 ID，作为某些诊断消息的一部分，然后使用`boost::this_thread::sleep_for`休眠 2 秒，这将传递类型为`boost::chrono::duration`的持续时间(参见[第 8 章](08.html "Chapter 8. Date and Time Libraries")，*日期和时间库*)。 我们也可以使用由 Boost Date Time 提供的持续时间类型，也就是`boost::posix_time::time_duration`及其子类型，而不是`boost::chrono`，但是我们需要使用`boost::this_thread::sleep`函数而不是`sleep_for`。

### 芯子和螺纹

许多现代计算机在单个芯片上有多个 CPU 核心，并且在处理器封装中可能有多个芯片。 要获取计算机上的物理核心数量，可以使用静态函数`boost::thread::physical_concurrency`。

现代英特尔 CPU 支持英特尔的超线程技术，该技术通过使用两组寄存器最大限度地提高了单个内核的利用率，允许在任何给定点在内核上多路复用两个线程，并降低了上下文切换的成本。 在具有八核且支持超线程的英特尔系统上，可调度为在任何给定时间并行运行的最大线程数为 8x2=16。静态函数`boost::thread::hardware_concurrency`为本地计算机返回此数字。

这些数字在决定程序中的最佳线程数时非常有用。 但是，如果底层系统中没有数字，则这些函数可能返回 0。 您应该在计划使用这些功能的每个平台上彻底测试它们。

# 管理共享数据

进程中的所有线程都可以访问相同的全局内存，因此在一个线程中执行的计算结果相对容易与其他线程共享。 共享内存上的并发只读操作不需要任何协调，但对共享内存的任何写入都需要与任何读取或写入同步。 共享*可变数据*和其他资源的线程需要机制来*仲裁访问*，以共享数据并相互发送关于事件和状态变化的信号。 在本节中，我们将探讨多个线程之间的协调机制。

## 创建和协调并发任务

考虑一下一个程序，它通过 unix`diff`实用程序生成两个文本文件之间的差异。 您需要读取两个文件，然后应用算法来识别相同的部分和更改的部分。 对于大多数文本文件，读取这两个文件，然后应用合适的算法(基于最长公共子序列问题)效果很好。 算法本身超出了本书的范围，与当前的讨论无关。

考虑我们需要执行的任务：

*   R1：读取第一个文件的完整内容
*   R2：读取第二个文件的完整内容
*   D：对两个文件的内容应用 DIFF 算法

可以想象，任务 R1 和 R2 产生包含文件内容的两个字符数组。 任务 D 使用 R1 和 R2 生成的内容，并将 diff 生成为另一个字符数组。 R1 和 R2 之间不需要排序，我们可以在单独的线程中并发读取这两个文件。 为简单起见，D 仅在 R1 和 R2 都完成后才开始，也就是说，R1 和 R2 都必须在 D 之前开始。让我们从编写读取文件的代码开始：

**清单 10.4a：读取文件**的内容

```cpp
 1 #include <vector>
 2 #include <string>
 3 #include <fstream>
 4 #include <boost/filesystem.hpp>
 5
 6 std::vector<char> readFromFile(const std::string& filepath)
 7 {
 8   std::ifstream ifs(filepath);
 9   size_t length = boost::filesystem::file_size(filepath);
10   std::vector<char> content(length);
11   ifs.read(content.data(), length);
12
13   return content;
14 }
15
16 std::vector<char> diffContent(const std::vector<char>& c1,
17                               const std::vector<char>& c2) {
18   // stub - returns an empty vector
19   return std::vector<char>();
20 }
```

给定文件名，函数`readFromFile`读取整个文件的内容，并在`vector<char>`中返回它。 我们将文件内容读入`vector`的底层数组，以获得在哪个位置调用 C++ 11 中引入的`data`成员函数(第 11 行)。 我们打开文件进行读取(第 8 行)，并使用`boost::filesystem::size`函数获得文件的大小(第 9 行)。 我们还定义了方法`diffContent`的存根来计算两个文件的内容之间的差异。

如何使用`readFromFile`函数读取单独线程中的文件，并将包含文件内容的向量返回给调用线程？ 调用线程需要一种方法来等待读取器线程中的读取完成，然后获取内容读取。 换句话说，调用线程需要等待异步操作的未来结果。 `boost::future`模板提供了一种在任务之间强制执行此类排序的简单方法。

### Boost：：Future 和 Boost：：Promise

`boost::future<>`模板用于表示将来可能发生的计算结果。 类型为`boost::future<T>`的对象表示将来可能生成的类型为`T`的对象的代理。 不严格地说，`boost::future`使调用代码能够等待或阻止事件的发生-产生特定类型的值的事件。 此机制可用于发信号通知事件并将值从一个线程传递到另一个线程。

值的生产者或事件源需要一种方式来与调用线程中的未来对象通信。 为此，与调用线程中的未来对象相关联的类型`boost::promise<T>`对象用于通知事件和发送值。 因此，`boost::future`和`boost::promise`对象成对工作，用信号通知事件并跨线程传递值。 现在，我们将了解如何使用 Boost Futures 和 Promises 来保证在 diff 操作之前的两个线程中的两个文件读取操作：

**清单 10.4B：使用期货和承诺**从线程返回值

```cpp
 1 #define BOOST_THREAD_PROVIDES_FUTURE
 2 #include <boost/thread.hpp>
 3 #include <boost/thread/future.hpp>
 4 // other includes
 5
 6 std::vector<char> diffFiles(const std::string& file1, 
 7                             const std::string& file2) {
 8   // set up the promise-future pair
 9   boost::promise<std::vector<char>> promised_value;
10   boost::future<std::vector<char>> future_result
11                                = promised_value.get_future();
12   // spawn a reader thread for file2
13   boost::thread reader(
14                     [&promised_value, &file2]() {
15                       std::cout << "Reading " << file2 << '\n';
16                       auto content = readFromFile(file2);
17                       promised_value.set_value(content);
18                       std::cout << "Read of " << file2
19                                 << " completed.\n";
20                     });
21
22   std::cout << "Reading " << file1 << '\n';
23   auto content1 = readFromFile(file1);
24   std::cout << "Read of " << file1 << " completed.\n";
25
26   auto content2 = future_result.get(); // this blocks
27   auto diff = diffContent(content1, content2);
28   reader.join();
29   return diff; 
30 }
```

要使能够使用`boost::future`和`boost::promise`，我们需要包括`boost/thread/future.hpp`(第 3 行)。 如果我们没有定义预处理器符号`BOOST_THREAD_PROVIDES_FUTURE`(第 1 行)，则需要使用`boost::unique_future`而不是`boost::future`。 如果我们将`boost::future`替换为`boost::unique_future`，这个示例将不会改变，但总的来说，这两个工具的功能存在差异，我们在本书中始终使用`boost::future`。

函数`diffFiles`(第 6 行和第 7 行)接受两个文件名并返回它们的 diff。 它使用清单 10.4a 中的`readFromFile`函数同步读取第一个文件(第 23 行)，并创建名为`reader`的线程并发读取第二个文件(第 13 行)。 为了得到通知，当`reader`线程完成读取并读取内容时，我们需要设置一个 Future-Promise 对。 由于我们希望从`reader`线程返回类型为`std::vector<char>`的值，因此我们定义了类型为`boost::promise<std::vector<char>>`的名为`promised_value`的承诺(第 9 行)。 Promise 对象的`get_future`成员返回关联的将来对象，并用于移动构造`future_result`(第 10-11 行)。 这将`promised_value`和`future_result`设置为我们合作的 Promise-Future 对。

为了读取`file2`的内容，我们创建了传递 lambda 的`reader`线程(第 14-20 行)。 Lambda 捕获`promised_value`和要读取的文件的名称(第 14 行)。 它读取文件的内容并在 Promise 对象上调用`set_value`，传入读取的内容(第 17 行)。 然后，它打印一条诊断消息并返回。 同时，调用线程还将另一个文件`file1`读入缓冲区`content1`，然后在`future_result`上调用`get`(第 26 行)。 此调用会一直阻塞，直到通过调用`set_value`设置了关联的承诺(第 17 行)。 它返回 Promise 中设置的`vector<char>`，这用于移动构造`content2`。 如果已经设置了 Promise，则在将来调用`get`时，它将返回该值，而不会阻塞调用线程。

现在我们有了计算 diff 所需的数据，我们通过将缓冲区`content1`和`content2`传递给`diffContent`函数来实现(第 27 行)。 请注意，在返回`diff`(第 28 行)之前，我们在`reader`线程上调用了`join`。 只有当我们希望确保`reader`线程在从函数返回之前退出时，才需要这样做。 我们也可以调用`detach`而不是`join`来不等待读取器线程退出。

### 等待未来

`boost::future<>`的`get`成员函数阻塞调用线程，直到设置了关联的 Promise。 它返回承诺中设置的值。 有时，您可能想要在短时间内阻止，并在没有设定承诺的情况下继续进行。 为此，您必须使用`wait_for`成员函数，并使用`boost::chrono::duration`指定等待的持续时间(参见[第 8 章](08.html "Chapter 8. Date and Time Libraries")、*日期和时间库*)：

**清单 10.5：未来的等待和超时**

```cpp
 1 #define BOOST_THREAD_PROVIDES_FUTURE
 2 #include <boost/thread.hpp>
 3 #include <boost/thread/future.hpp>
 4 #include <boost/chrono.hpp>
 5 #include <ctime>
 6 #include <cassert>
 7 #include <cstdlib>
 8 #include <iostream>
 9 
10 int main() {
11   boost::promise<void> promise;
12   boost::future<void> future = promise.get_future();
13
14   std::cout << "Main thread id=" 
15                       << boost::this_thread::get_id() << '\n';
16   boost::thread thr([&promise]() {
17          srand(time(0));
18          int secs = 10 + rand() % 10;
19          std::cout << "Thread " << boost::this_thread::get_id()
20                   << " sleeping for "
21                   << secs << " seconds\n";
22          boost::this_thread::sleep_for(
23               boost::chrono::seconds(secs));
24          promise.set_value();
25        });
26
27   size_t timeout_count = 0;
28   size_t secs = 2;
29
30   while (future.wait_for(boost::chrono::seconds(secs)) 
31           == boost::future_status::timeout) {
32     std::cout << "Main thread timed out\n";
33     ++ timeout_count;
34   }
35   assert(future.is_ready());
36   assert(future.get_state() == boost::future_state::ready);
37
38   std::cout << "Timed out for " << timeout_count * secs 
39             << " seconds \n";
40   thr.join();
41 }
```

这个例子演示了我们如何在将来的对象上等待固定的持续时间。 我们创建了一个 Promise-Future 对(第 11-12 行)，但是`boost::future<>`和`boost::promise<>`的模板参数是无效的。 这意味着我们可以将此对纯粹用于发送信号/等待，但不能用于跨线程传输任何数据。

我们创建一个线程`thr`(第 16 行)，向它传递一个 lambda，它捕获 Promise 对象。 通过将随机持续时间传递给`boost::this_thread::sleep_for`(第 22 行)，该线程简单地休眠 10 到 19 秒之间的随机持续时间，然后退出。 使用`boost::chrono::seconds`函数构造持续时间(第 23 行)，并传递使用`rand`函数计算的随机间隔`secs`(第 18 行)。 为了简单起见，我们使用`rand`，尽管 Boost 和 C++ 11 中提供了更可靠、更健壮的功能。要使用`rand`，我们需要调用`srand`来为随机数生成器设定种子。 在 Windows 上，我们必须在调用`rand`的每个线程中调用`srand`，如我们这里所示(第 17 行)，而在 POSIX 上，我们应该为每个进程调用一次`srand`，这可能是在`main`的开头。

在休眠一段特定时间后，线程`thr`对承诺调用`set_value`并返回(第 24 行)。 由于 Promise 的类型为`boost::promise<void>`，因此`set_value`不带任何参数。

在主线程中，我们在与`promise`相关联的将来运行一个调用`wait_for`的循环，每次传递 2 秒的持续时间(第 30 行)。 函数`wait_for`返回枚举类型`boost::future_state`的值。 每次`wait_for`超时时，它返回`boost::future_state::timeout`。 一旦设置了承诺(第 24 行)，`wait_for`调用返回`boost::future_state::ready`，循环中断。 `boost::future`的`is_ready`成员函数返回`true`(第 35 行)，而`get_state`成员函数返回的未来状态是`boost::future_state::ready`(第 36 行)。

### 跨线程抛出异常

如果传递给`boost::thread`构造函数的初始函数允许传播任何异常，则调用`std::terminate`会立即中止程序。 如果我们需要从一个线程抛出异常以将问题指示给另一个线程，或者需要将在一个线程中捕获的异常传播到另一个线程，这就会产生问题。 对于这一目的，承诺/未来机制也派上了用场。 考虑一下，在清单 10.4a 和 10.4b 中，如何处理文件不存在或不可读的情况：

**清单 10.6：跨线程传输异常**

```cpp
 1 #define BOOST_THREAD_PROVIDES_FUTURE
 2 #include <boost/thread.hpp>
 3 #include <boost/thread/future.hpp>
 4 // other includes
 5
 6 std::vector<char> readFromFile(const std::string& filepath)
 7 {
 8   std::ifstream ifs(filepath, std::ios::ate);
 9   if (!ifs) {
10     throw std::runtime_error(filepath + " unreadable");
11   }
12   ... // rest of the code – check Listing 10.4a
13 }
14
15 std::vector<char> diffFiles(const std::string& file1,
16                             const std::string& file2) {
17   // set up the promise-future pair
18   boost::promise<std::vector<char> > promised_value;
19   boost::future<std::vector<char> > future_result
20                                = promised_value.get_future();
21   // spawn a reader thread for file2
22   boost::thread reader(
23                        [&promised_value, &file2]() {
24                          try {
25                            auto content = readFromFile(file2);
26                            promised_value.set_value(content);
27                          } catch (std::exception& e) {
28                            promised_value.set_exception(
29                               boost::copy_exception(e));
30                          }
31                        });
32   ...
33   std::vector<char> diff;
34   try {
35     auto content2 = future_result.get(); // this blocks
36     diff = diffContent(content1, content2);
37   } catch (std::exception& e) {
38     std::cerr << "Exception caught: " << e.what() << '\n';
39   }
40   reader.join();
41   return diff; 
42 }
```

如果`file2`是不存在或不可读的文件名(第 25 行)，则函数`readFromFile`抛出一个异常(第 10 行)，该异常被`reader`线程捕获(第 27 行)。 `reader`线程使用`set_exception`成员函数在 Promise 对象中设置异常(第 28-29 行)。 注意，我们使用`boost::copy_exception`创建了 Exception 对象的副本，并将其设置在 Promise 对象中(第 29 行)。 一旦在 Promise 中设置了异常，对未来对象的`get`调用(第 35 行)抛出该异常，需要捕获和处理该异常(第 38 行)。

### 共享未来

`boost::future`对象只能由一个线程等待。 它不可复制，但可以移动；因此，它的所有权可以从一个线程转移到另一个线程，也可以从一个功能转移到另一个线程，但永远不能共享。 如果我们希望多个线程使用未来机制等待相同的条件，则需要使用`boost::shared_future`。 在下面的示例中，我们创建了一个发布者线程，该线程在使用其线程 ID 设置 Promise 之前等待固定的持续时间。我们还创建了三个订阅者线程，这三个订阅者线程轮询与 Promise 对象相关联的`boost::shared_future`对象，直到它准备就绪，然后从`shared_future`检索 Publisher 对象的线程 ID：

**清单 10.7：使用 SHARED_FIRRED**

```cpp
 1 #include <string>
 2 #include <vector>
 3 #include <iostream>
 4 #define BOOST_THREAD_PROVIDES_FUTURE
 5 #include <boost/lexical_cast.hpp>
 6 #include <boost/thread.hpp>
 7 #include <boost/thread/future.hpp>
 8 #include <boost/chrono.hpp>
 9
10 int main() {
11   boost::promise<std::string> prom;
12   boost::future<std::string> fut(prom.get_future());
13   boost::shared_future<std::string> shfut(std::move(fut));
14   boost::thread publisher([&prom]() {
15               std::string id =
16                 boost::lexical_cast<std::string>(
17                                boost::this_thread::get_id());
18               std::cout << "Publisher thread " << id 
19                         << " starting.\n";
20               boost::this_thread::sleep_for(
21                                   boost::chrono::seconds(15));
22               prom.set_value(id);
23            });
24   auto thrFunc = [](boost::shared_future<std::string> sf, 
25                     int waitFor) {
26     while (sf.wait_for(boost::chrono::seconds(waitFor))
27         == boost::future_status::timeout) {
28       std::cout << "Subscriber thread " 
29                 << boost::this_thread::get_id()
30                 << " waiting ...\n";
31     }
32
33     std::cout << "\nSubscriber thread " 
34               << boost::this_thread::get_id()
35               << " got " << sf.get() << ".\n";
36   };
37
38   boost::thread subscriber1(thrFunc, shfut, 2);
39   boost::thread subscriber2(thrFunc, shfut, 4);
40   boost::thread subscriber3(thrFunc, shfut, 6);
41
42   publisher.join();
43   subscriber1.join();
44   subscriber2.join();
45   subscriber3.join();
46 }
```

按照熟悉的模式，我们创建一个 Promise(第 11 行)和一个`boost::future`(第 12 行)。 使用未来对象，我们移动-初始化一个`shared_future`对象`shfut`(第 13 行)。 `publisher`线程捕获 Promise(第 14 行)并休眠 15 秒(第 21 行)，然后将其 ID 字符串设置到 Promise 中(第 22 行)。

对于订户线程，我们将 lambda 表达式生成的函数对象存储在一个名为`thrFunc`的变量中(第 24 行)，以便可以多次重用它。 订户线程的初始函数按值接受`shared_future`参数，还接受`waitFor`参数，该参数指定轮询`shared_future`的频率(以秒为单位)。 订户在共享未来调用`wait_for`的循环中旋转，在`waitFor`秒后超时。 一旦设置了 Promise(第 22 行)，它就会退出循环，并通过在`shared_future`上调用`get`来检索 Promise 中设置的值(发布者的线程 ID)(第 35 行)。

派生了三个订户线程(第 38-40 行)。 注意它们的初始函数、`shared_future`对象的参数和等待时间(以秒为单位)是如何作为附加参数传递给`boost::thread`对象的可变构造函数模板的。 请注意，`shared_future`是可复制的，并且相同的`shared_future`对象`shfut`被复制到三个订户线程中。

### std：：Future 和 std：：Promise

C++ 11 标准库提供了与 Boost 库对应的模板`std::future<>`、`std::shared_future<>`和`std::promise<>`，这些模板在行为上几乎相同。 Boost 版本的附加成员函数是试验性的，但撇开这些不谈，它们反映了标准库的对应物。 例如，我们可以通过替换程序文本中的以下符号来重写清单 10.5 和 10.7：

*   将`boost::thread`替换为`std::thread`
*   将`boost::future`替换为`std::future`
*   将`boost::promise`替换为`std::promise`
*   将`boost::shared_promise`替换为`std::shared_promise`
*   将`boost::chrono`替换为`std::chrono`

此外，我们还需要将包含的标头`boost/thread.hpp`、`boost/thread/future.hpp`和`boost/chrono.hpp`分别替换为标准库标头`thread`、`future`和`chrono`。

在清单 10.6 中，我们使用了`boost::promise`的`set_exception`成员函数来允许跨线程边界传递异常。 这需要进行一些更改才能与`std::promise`配合使用。 C++ 11 引入了`std::exception_ptr`，这是一种具有共享所有权语义的特殊智能指针类型，它必须包装异常对象，以便它们可以跨函数和线程传递(参见[附录](12.html "Appendix A. C++ 11 Language Features Emulation")、*C++ 11 语言功能仿真*)。 `std::promise`的`set_exception`成员函数接受`std::exception_ptr`类型的参数，而不是`std::exception`类型的参数。 以下代码片段显示了如何更改清单 10.6 以使用标准库：

```cpp
 1 // include other headers
 2 #include <exception>
... // other code
22   boost::thread reader(
23                        [&promised_value, &file2]() {
24                          try {
25                            auto content = readFromFile(file2);
26                            promised_value.set_value(content);
27                          } catch (std::exception& e) {
28                            promised_value.set_exception(
29                                     std::current_exception());
30                          }
31                        });
```

在这里，我们调用`std::current_exception`(第 29 行)，它返回包装 Catch 块中当前活动异常的`std::exception_ptr`对象。 此`exception_ptr`被传递给`std::promise`的`set_exception`成员函数(第 28 行)。 这些类型和函数声明可从标准库标题`exception`(第 2 行)获得。

我们还可以使用`std::make_exception_ptr`从异常对象创建对象，如以下代码片段(第 29 行)所示：

```cpp
22   boost::thread reader(
23                        [&promised_value, &file2]() {
24                          try {
25                            auto content = readFromFile(file2);
26                            promised_value.set_value(content);
27                          } catch (std::exception& e) {
28                            promised_value.set_exception(
29                                  std::make_exception_ptr(e));
30                          }
31                        });
The exception stored in a std::exception_ptr can be thrown using std::rethrow_exception, as shown here:
01 void throwAgain(std::exception_ptr eptr) {
02   // do stuff
03   std::rethrow_exception(eptr);
04 }
```

### std：：Package_TASK 和 std：：Async

虽然线程是强大的构造，但它们提供的全部通用性和控制力是以简单性为代价的。 在很多情况下，最好在更高的抽象级别上操作，而不是创建显式线程来运行任务。 标准库提供了`std::async`函数模板和`std::packaged_task`类模板，它们为创建并发任务提供了不同级别的抽象，使程序员不必在过程中编写大量样板代码。 它们在 Boost 库(`boost::async`和`boost::packaged_task`)中有对应的版本，但在撰写本文时(Boost 版本 1.57)还没有完全实现，可移植性较差，尤其是在 C++ 11 之前的环境中。

#### std：：Package_TASK

`std::packaged_task<>`类模板用于创建异步任务。 您需要显式创建一个线程来运行任务或使用`packaged_task`中的重载`operator()`手动调用任务。 但您不需要手动设置承诺-未来对或以任何方式处理承诺。 下面是使用`std::packaged_task`重写的清单 10.6：

**清单 10.8：使用 std：：Package_TASK**

```cpp
 1 #include <future>
 2 #include <thread>
 3 #include <vector>
 4 // other includes
 5
 6 std::vector<char> readFromFile(const std::string& filepath)
 7 {
 8   std::ifstream ifs(filepath, std::ios::ate);
 9   if (!ifs) {
10     throw std::runtime_error(filepath + " unreadable");
11   }
12   ... // rest of the code – check Listing 10.4a
13 }
14
15 std::vector<char> diffFiles(const std::string& file1,
16                             const std::string file2)
17 {
18   typedef std::vector<char> buffer_t;
19   std::packaged_task<buffer_t(const std::string&)>
20             readerTask(readFromFile);
21   auto future = readerTask.get_future();
22
23   try {
24     std::thread thread2(std::move(readerTask), file2);
25     auto content1 = readFromFile(file1);
26     std::cout << "Read from file " << file1 << " completed.\n";
27
28     auto content2 = future.get();
29     thread2.detach();
30     return diffContent(content1, content2);
31   } catch (std::exception& e) {
32     std::cout << "Exception caught: " << e.what() << '\n';
33   }
34
35   return std::vector<char>(); 
36 }
```

在本例中，我们读取两个文件并计算它们的差异。 要读取文件，我们使用函数`readFromFile`，该函数返回`vector<char>`中的文件内容，或者在文件不可读时抛出异常。 我们通过对`readFromFile`(第 25 行)的阻塞调用读取两个文件中的一个，并在单独的线程上读取另一个文件。

要同时读取第二个文件和第一个文件，我们将`readFromFile`函数包装在名为`readerTask`的`std::packaged_task`中(第 19-20 行)，并在单独的线程中运行它。 `readerTask`的具体类型为`std::packaged_task<buffer_t(const std::string&)>`。 `packaged_task`的模板参数是包装函数类型。 在单独的线程上启动此任务之前，我们必须首先获取对关联的未来对象的引用。 我们通过调用`packaged_task`的`get_future`成员函数(第 21 行)获得对未来对象的引用。 接下来，我们创建一个线程并将打包的任务移到该线程(第 24 行)。 这是必要的，因为`packaged_task`是可移动的，但不可复制，这就是在移动`packaged_task`对象之前必须对其调用`get_future`方法的原因。

线程`thread2`通过调用在`packaged_task`中传递给它的`readFromFile`函数来读取`file2`。 通过调用未来的`get`成员函数，可以从与`readerTask`相关联的未来对象获得由`readFromFile`返回的`vector<char>`(第 28 行)。 `get`调用将抛出最初由`readFromFile`抛出的任何异常，例如当指定的文件不存在时。

#### std：：Async

`std::async`函数模板从可能在单独线程中并发运行的函数对象创建任务。 它返回一个`std::future`对象，该对象可用于阻塞或等待任务。 它可以通过标准库头文件`future`获得。 使用`std::async`，我们不再需要显式创建线程。 相反，我们将把要执行的函数、要传递的参数和一个可选的启动策略传递给`std::async`。 `std::async`根据指定的启动策略在不同的线程中异步运行函数，或者在调用线程上同步运行函数。 下面是使用`std::async`重写清单 10.5 的简单代码：

**清单 10.9：使用 std：：Async 创建并发任务**

```cpp
 1 #include <iostream>
 2 #include <thread>
 3 #include <future>
 4 #include <chrono>
 5 #include <ctime>
 6 #include <cstdlib>
 7
 8 int main()
 9 {
10   int duration = 10 + rand() % 10;
11   srand(time(0));
12   std::cout << "Main thread id="
13             << std::this_thread::get_id() << '\n';
14 
15   std::future<int> future =
16     std::async(std::launch::async,
17        [](int secs) -> int {               
18            std::cout << "Thread " << std::this_thread::get_id()
19                     << " sleeping for "
20                     << secs << " seconds\n";
21            std::this_thread::sleep_for(
22                     std::chrono::seconds(secs));
23            return secs;
24        }, duration);
25   
26   size_t timeout_count = 0, secs = 2;
27 
28   while (future.wait_for(std::chrono::seconds(secs))
29           == std::future_status::timeout) {
30     std::cout << "Main thread timed out\n";
31     ++ timeout_count;
32   }
33   std::cout << "Launched task slept for " 
34             << future.get() << '\n';
35   std::cout << "Timed out for " << timeout_count * secs 
36             << " seconds \n";
37 }
```

`packaged_task`抽象承诺，`std::async`抽象线程本身，我们不再处理`std::thread`的对象。 相反，我们调用`std::async`，向其传递一个启动策略`std::launch::async`(第 16 行)、一个函数对象(第 17 行)和函数对象接受的任意数量的参数。 它返回一个未来的对象，并异步运行传递给它的函数。

与`thread`的构造函数一样，`std::async`是一个变量函数，它会传递需要转发给函数对象的所有参数。 函数对象是使用 lambda 表达式创建的，除了作为参数传递给它的休眠持续时间外，它几乎不做任何事情。 `duration`是一个介于 10 到 19 秒之间的随机值，并作为函数对象的唯一参数传递给`async`调用(第 24 行)。 函数对象返回睡眠持续时间(第 23 行)。 我们在未来对象上调用`wait_for`成员函数，以短时间等待，直到设置了未来(第 28 行)。 我们通过调用未来对象的`get`成员函数来检索任务的返回值(第 34 行)。

##### 启动策略

我们使用启动策略`std::launch::async`来指示我们希望任务在单独的线程上运行。 这将在单独的线程中立即启动任务。 使用另一个标准启动策略`std::launch::deferred`，当我们第一次对关联的未来对象调用`get`或`wait`(非计时等待函数)时，我们可以延迟启动任务。 该任务将在调用`get`或`wait`的线程中运行 Synchron。 这也意味着，如果使用`deferred`策略而不调用`get`或`wait`，任务将永远不会启动。

我们不可能在清单 10.10 中使用`std::launch::deferred`。 这是因为我们等待将来准备就绪(第 28 行)，然后才在同一线程中调用`get`(第 34 行)。 在我们调用`get`之前，任务永远不会启动，但除非任务启动并返回一个值，否则未来永远不会准备好；因此，我们将在`while`循环中永远旋转。

在使用`std::async`创建任务时，我们还可以省略启动策略：

```cpp
auto future = std::async([]() {...}, arg1, arg2);
```

在这种情况下，行为相当于以下调用：

```cpp
auto future = std::async(std::launch::async|std::launch::deferred,
                          []() {...}, arg1, arg2);
```

选择符合`std::launch::async`或`std::launch::deferred`的行为取决于实现。 此外，只有在支持多线程所需的运行时库链接到程序时，实现才会创建新线程。 使用默认策略时，当启用多线程时，`std::async`要么在新线程中启动新任务，要么将它们发布到内部线程池。 如果池中没有空闲线程或空闲内核，则任务将同步启动。

## 基于锁的线程同步方法

到目前为止，我们了解了如何使用`boost::thread`和`std::thread`委托在不同线程上运行的函数。 我们看到了如何使用`boost::future`和`boost::promise`在线程之间传递结果和异常，并通过阻塞调用在任务之间施加顺序。 有时，您可以将程序分解为可以并发运行的独立任务，从而产生值、副作用或两者兼而有之，然后由程序的另一部分使用。 启动这类任务，并利用期货等待它们，是一种有效的策略。 一旦任务返回，您就可以开始使用第一阶段结果的下一阶段计算。

不过，通常情况下，多个线程需要并发且重复地访问和修改相同的数据结构。 这些访问需要可靠地排序，并且彼此隔离，以防止由于不协调的并发访问而导致的不一致潜入底层数据结构。 在本节中，我们将介绍帮助我们解决这些问题的 Boost 库。

### 数据竞争和原子操作

考虑下面的代码片段。 我们创建两个线程，每个线程在循环中将共享整数变量递增固定次数：

```cpp
int main() {
  int x = 0;
  const int max = 1000000;

  auto thrFunc = [&x]() {
                          for (int i = 0; i < max; ++ i) {
                            ++ x;
                          }
                        };

  boost::thread t1(thrFunc);
  boost::thread t2(thrFunc);
  t1.join();
  t2.join();

  std::cout << "Value of x: " << x << '\n';
}
```

程序末尾会打印出什么值`x`？ 因为每个线程递增`x`一百万次，并且有两个线程，所以可以预期它是`2000000`。 您可以自己验证增量运算符在`x`上被调用的次数不少于也不超过`N*max`次，其中`N=2`是线程数，`max`是一百万次。 然而，我不止一次看到`2000000`被打印出来；每一次都是一个较小的数字。 根据操作系统和硬件的不同，此行为可能会有所不同，但很常见。 显然，一些增量措施并未见效。

当您意识到操作`++ x`涉及读取`x`的值，将该值加 1，然后将此结果写回`x`时，原因就会变得清晰起来。 假设`x`的值是`V`，两个线程在`V`上执行操作`++ x`。 两个线程中的每个线程都可以读取 V 作为`x`的值，执行递增，然后写回 V+1。因此，在两个线程之后，每个线程递增`x`一次，`x`的值仍然可以像它只递增一次一样。 根据机器架构的不同，对于某些“原始”数据类型，可能需要两条 CPU 指令来更新变量的值。 由于*部分写入*，并发执行的两个这样的操作可能最终将值设置为两个都不想要的值。

这样的交错操作表示**个数据竞争**-执行这些操作的线程在执行操作步骤及其确切顺序时会相互竞争，因此，结果是不可预测的。

让我们使用符号[r=v1，w=v2]来表示线程*从变量`x`读取*值 v1，*写回*v2。 请注意，在线程读取`x`的值和写回值的时间之间可以有任意的持续时间。 所以符号[r=v1，…。 用于指示已读取值 v1，但尚未进行写回，符号…。 W=v2]表示发生了挂起写入。 现在考虑两个线程，每个线程都递增`x`一百万次，如下面的序列所示：

![Data races and atomic operations](img/1217OT_10_01.jpg)

为简单起见，假设不会发生部分写入。 在时间**T1**，线程 1 和线程 2 都将`x`的值读取为 0。 线程 2 递增该值并写回值 1。线程 2 继续读取并递增`x`的值 999998 次，直到它在时间**t9999**写回值 999999。 接着，线程 1 递增它在**t1**读取的值 0，并写回值 1。接下来，线程 1 和线程 2 都读取值 1，线程 1 写回 2，但线程 2 挂起。 线程 1 继续进行 999998 次以上的迭代，读取并递增`x`的值。 它在时间**t1999999**将值 1000000 写入`x`并退出。 线程 2 现在递增它在**t1000001**读取的值 1 并写回。 对于 200 万个增量，`x`的最终值很可能是 2。您可以将迭代次数更改为大于或等于 2 的任何数字，将线程数更改为大于或等于 2 的任何数字，此结果仍然有效-这是对并发的不确定性和非直观性的度量。 当我们看到操作`++ x`时，我们会直观地认为它是一个不可分割的或*原子操作，而实际上不是*。

**原子操作**在没有任何可观察到的中间状态的情况下运行。 这样的操作不能交错。 原子操作创建的中间状态对其他线程不可见。 机器体系结构为执行原子读-修改-写操作提供特殊指令，操作系统通常为使用这些原语的原子类型和操作提供库接口。

增量运算`++ x`显然是非原子的。 变量`x`是共享资源，在一个线程对`x`的读取、递增和后续写入之间，可以从其他线程对`x`进行任意数量的读-修改-写操作-这些操作可以交错。 对于这样的非原子操作，我们必须找到使它们**线程安全的方法**，也就是说，通过防止操作(如`++ x`)跨多个线程交叉。

### 互斥和临界截面

使`++ x`操作线程安全的一种方法是在**临界区**中执行它。 临界区是不能由两个不同的线程同时执行的代码段。 因此，来自不同线程的两个增量`x`可以交错。 线程必须遵守此协议，并且可以使用**互斥锁**来执行此操作。 互斥是用于同步对共享资源的并发访问的原语，例如变量`x`。 为此，我们使用`boost::mutex`类，如下例所示：

**清单 10.10：使用互斥锁**

```cpp
 1 #include <boost/thread/thread.hpp>
 2 #include <boost/thread/mutex.hpp>
 3 #include <iostream>
 4
 5 int main()
 6 {
 7   int x = 0;
 8   static const int max = 1000000;
 9   boost::mutex mtx;
10
11   auto thrFunc = [&x, &mtx]() {
12     for (int i = 0; i < max; ++ i) {
13       mtx.lock();
14       ++ x;
15       mtx.unlock();
16     }
17   };
18
19   boost::thread t1(thrFunc);
20   boost::thread t2(thrFunc);
21
22   t1.join();
23   t2.join();
24
25   std::cout << "Value of x: " << x << '\n';
26 }
```

我们声明类型为`boost::mutex`的互斥体对象(第 9 行)，在为线程生成初始函数的 lambda 中捕获它(第 11 行)，然后保护变量`x`上的增量操作，方法是在执行互斥体之前锁定它(第 13 行)，之后再解锁它(第 15 行)。 `x`(第 14 行)上的增量操作是关键部分。 此代码每次都打印以下内容：

```cpp
2000000
```

这是怎么回事？ 互斥对象有两种状态：**锁定**和**未锁定**。 在解锁的互斥体上调用`lock`成员函数的第一个线程锁定它，然后返回对`lock`的调用。 在已锁定的互斥体上调用`lock`的其他线程只需**阻塞**，这意味着操作系统调度程序不会调度这些线程运行，除非发生某些事件(如正在讨论的互斥体的解锁)。 然后，拥有锁的线程递增`x`，并调用互斥锁上的`unlock`成员函数以释放它持有的锁。 此时，在`lock`调用中阻塞的一个线程被唤醒，该线程中对`lock`的调用返回，并安排该线程运行。 哪个等待线程被唤醒取决于底层本机实现。 这将一直持续到所有线程(在我们的示例中，只有两个)都运行到完成为止。 锁确保在任何时间点只有一个线程独占地持有锁，因此可以自由递增`x`。

我们选择使用互斥锁保护的部分非常关键。 我们也可以保护整个 for 循环，如以下代码片段所示：

```cpp
12     mtx.lock();
13     for (int i = 0; i < max; ++ i) {
14       ++ x;
15     }
16     mtx.unlock();
```

`x`的最终值仍然与清单 10.10 相同(`2000000`)，但是临界区会更大(第 13-15 行)。 一个线程甚至在另一个线程可以递增`x`一次之前运行它的整个循环。 通过限制临界区的范围和线程持有锁的时间，多个线程可以取得更公平的进展。

线程可以选择探测并查看它是否可以获得互斥体上的锁，但如果不能，则不会阻塞。 为此，线程必须调用`try_lock`成员函数，而不是`lock`成员函数。 如果互斥锁已锁定，则调用`try_lock`将返回`true`，否则将返回`false`，如果互斥锁未锁定，则不会阻塞：

```cpp
boost::mutex mtx;
if (mtx.try_lock()) {
  std::cout << "Acquired lock\n";
} else {
  std::cout << "Failed to acquire lock\n";
}
```

线程还可以使用`try_lock_for`成员函数在等待获取锁的同时选择阻塞指定的持续时间。 如果成功获取锁，则调用`try_lock_for`会立即返回`true`。 否则，它将在指定持续时间的整个长度内阻塞，并在未获取锁的情况下超时后返回 FALSE：

```cpp
boost::mutex mtx;
if (mtx.try_lock_for(boost::chrono::seconds(5))) { 
  std::cout << "Acquired lock\n";
} else {
  std::cout << "Failed to acquire lock\n";
}
```

### 备注

Mutex 应该在必要的一小段代码中保持尽可能短的持续时间。 因为互斥体会序列化临界区的执行，所以在较长时间内保持互斥锁会延迟等待锁定互斥锁的其他线程的进度。

#### Boost：：Lock_Guard

在互斥锁上获取锁并不释放它将是灾难性的，因为等待互斥锁的任何其他线程都不会取得任何进展。 互斥锁上的裸`lock`/`try_lock`和`unlock`调用不是一个好主意，我们需要一些以异常安全的方式锁定和解锁互斥锁的方法。 `boost::lock_guard<>`模板使用**资源获取是初始化**(**RAII**)习惯用法来锁定和解锁其构造函数和析构函数中的互斥对象：

**清单 10.11：使用 Boost：：Lock_Guard**

```cpp
 1 #include <boost/thread/thread.hpp>
 2 #include <boost/thread/mutex.hpp>
 3 #include <iostream>
 4
 5 int main()
 6 {
 7   int x = 0;
 8   static const int max = 1000000;
 9   boost::mutex mtx;
10
11   auto thrFunc = [&x, &mtx]() {
12     for (int i = 0; i < max; ++ i) {
13       boost::lock_guard<boost::mutex> lg(mtx);
14       ++ x;
16     }
17   };
18
19   boost::thread t1(thrFunc);
20   boost::thread t2(thrFunc);
21
22   t1.join();
23   t2.join();
24
25   std::cout << "Value of x: " << x << '\n';
26 }
```

使用`boost::lock_guard`对象(第 13 行)，我们锁定锁保护实例化之后的代码段，直到作用域结束。 `lock_guard`获取构造函数中的锁，并在析构函数中释放它。 这确保了即使在临界区出现异常时，一旦退出作用域，互斥锁也始终处于解锁状态。 将锁的类型作为模板参数传递给`lock_guard`。 `boost::lock_guard`不仅可以与`boost::mutex`一起使用，还可以与符合**BasicLockable**概念的任何类型一起使用，即具有可访问的`lock`和`unlock`成员函数。

我们还可以使用`boost::lock_guard`来封装已经锁定的互斥。 为此，我们需要将第二个参数传递给`lock_guard`构造函数，指示它应该取得互斥锁的所有权，而不是试图锁定它：

```cpp
 1 boost::mutex mtx;
 2 ...
 3 mtx.lock();  // mutex locked
 4 ...
 5 {
 6   boost::lock_guard<boost::mutex> lk(mtx, boost::adopt_lock);
 7   ...
 8 } // end of scope
```

`boost::lock_guard`要么将底层互斥体锁定在其构造函数中，要么采用已锁定的互斥体。 释放互斥锁的唯一方法是让`lock_guard`超出作用域。 `lock_guard`既不是可复制的，也不是可移动的，因此您不能将它们从一个函数传递到另一个函数，也不能将它们存储在容器中。 您不能使用`lock_guard`在互斥体上等待特定的持续时间。

#### Boost：：Unique_lock

`boost::unique_lock<>`模板是一个更灵活的替代方案，它仍然使用 RAII 来管理类似互斥锁的锁，但提供了一个根据需要手动锁定和解锁的接口。 为了实现这种额外的灵活性，`unique_lock`必须维护一个额外的数据成员，以跟踪互斥锁是否属于该线程。 我们可以使用`unique_lock`来管理任何符合**可锁定**概念的类。 如果一个类符合 BasicLockable，那么它就符合可锁定的概念，此外，它还定义了一个可访问的`try_lock`成员函数-就像`boost::mutex`所做的那样。

我们可以使用`boost::unique_lock`替代`boost::lock_guard`，但如果`lock_guard`满足某个目的，则不应使用`unique_lock`。 当我们想要混合手动锁定和异常安全锁管理时，`unique_lock`通常非常有用。 例如，我们可以重写清单 10.11 以使用`unique_lock`，如以下代码片段所示：

```cpp
 7   int x = 0;
 8   static const int max = 1000000;
 9   boost::mutex mtx;
10
11   auto thrFunc = [&x, &mtx]() {
12     boost::unique_lock<boost::mutex> ul(mtx, boost::defer_lock);
13     assert(!ul.owns_lock());
14
15     for (int i = 0; i < max; ++ i) {
16       ul.lock();
17       ++ x;
18       assert(ul.owns_lock());
19       assert(ul.mutex() == &mtx);
20
21       ul.unlock();
22     }
23   };
```

与清单 10.11 不同，我们不会在循环的每次迭代中创建新的`lock_guard`对象。 相反，我们在循环开始之前创建一个封装互斥锁的`unique_lock`对象(第 12 行)。 传递给`unique_lock`构造函数的`boost::defer_lock`参数告诉构造函数不要立即锁定互斥锁。 互斥锁在通过调用`unique_lock`的`lock`成员函数(第 16 行)递增共享变量之前锁定，并在操作之后通过调用`unique_lock`的`unlock`成员函数解锁(第 21 行)。 在发生异常的情况下，`unique_lock`析构函数仅在互斥锁被锁定时才解锁该互斥锁。

如果`unique_lock`拥有互斥锁，则`unique_lock`的`owns_lock`成员函数返回`true`，否则返回`false`(第 13 和 18 行)。 `unique_lock`的`mutex`成员函数返回指向存储的互斥体的指针(第 19 行)，如果`unique_lock`没有包装有效的互斥体，则返回`nullptr`。

#### 死锁

Mutexes提供对共享资源的独占所有权，并且许多现实世界中的问题都涉及多个共享资源。 以多人第一人称射击游戏为例。 它实时维护和更新两个列表。 有一组射手 A 是有某种弹药的玩家，第二组 U 是手无寸铁的玩家。 当玩家耗尽弹药时，她被从 A 移到 U。当她的弹药补充时，她被从 U 移回 A。线程 1 处理从 A 到 U 的移动元素，线程 2 处理从 U 到 A 的移动元素。

当一名新玩家加入游戏时，她会被加到 U 或 A，这取决于她是否有弹药。 当一名玩家在游戏中被杀时，她将被从她所在的任何一组(U 或 A)中移除。 但当弹药耗尽或补充时，玩家会在 U 和 A 之间移动；因此 U 和 A 都需要编辑。 考虑以下代码，其中一个线程负责在弹药耗尽时将玩家从 A 移动到 U，另一个线程负责在弹药补充时将玩家移回(U 到 A)：

**清单 10.12：死锁示例**

```cpp
 1 #include <iostream>
 2 #include <cstdlib>
 3 #include <ctime>
 4 #include <set>
 5 #include <boost/thread.hpp>
 6
 7 struct player {
 8   int id;
 9   // other fields
10   bool operator < (const player& that) const {
11     return id < that.id;
12   }
13 };
14
15 std::set<player> armed, unarmed; // A, U
16 boost::mutex amtx, umtx;
17
18 auto a2u = [&](int playerId) {
19         boost::lock_guard<boost::mutex> lka(amtx);
20         auto it = armed.find(player{playerId}); 
21         if (it != armed.end()) {
22           auto plyr = *it;
23           boost::unique_lock<boost::mutex> lku(umtx);
24           unarmed.insert(plyr);
25           lku.unlock();
26           armed.erase(it);
27         }
28       };
29
30 auto u2a = [&](int playerId) {
31         boost::lock_guard<boost::mutex> lku(umtx);
32         auto it = unarmed.find(player{playerId});
33         if (it != unarmed.end()) {
34           auto plyr = *it;
35           boost::unique_lock<boost::mutex> lka(amtx);
36           armed.insert(plyr);
37           lka.unlock();
38           unarmed.erase(it);
39         }
40       };
41
42 void onAmmoExhausted(int playerId) { // event callback
43   boost::thread exhausted(a2u, playerId);
44   exhausted.detach();
45 }
46
47 void onAmmoReplenished(int playerId) { // event callback
48   boost::thread replenished(a2u, playerId);
49   replenished.detach();
50 }
```

每当玩家的弹药耗尽时，使用该玩家的 ID 调用`onAmmoExhausted`(第 42 行)函数。 此函数创建一个线程，该线程运行函数`a2u`(第 18 行)将该玩家从集合 A(`armed`)移动到集合 U(`unarmed`)。 类似地，当玩家的弹药被补充时，调用`onAmmoReplenished`(第 47 行)函数，然后在单独的线程中运行函数`u2a`，将玩家从集合 U(`unarmed`)移动到集合 A(`armed`)。

互斥锁`amtx`和`umtx`控制对集合`armed`和`unarmed`的访问。 要将玩家从 A 移动到 U，函数`a2u`首先获取`amtx`上的锁(第 19 行)，然后在`armed`中查找该玩家(第 20 行)。 如果找到玩家，则线程获取`umtx`上的锁(第 23 行)，将玩家放入`unarmed`(第 23 行)，释放`umtx`上的锁(第 24 行)，并将玩家从`armed`移除(第 25 行)。

函数`u2a`本质上具有相同的逻辑，但首先获取`umtx`上的锁，然后获取`amtx`上的锁，这会导致一个致命的缺陷。 如果一个玩家耗尽了弹药，而另一个玩家几乎同时补充了弹药，那么两个线程可以同时运行`a2u`和`u2a`。 也许很少会发生`exhausted`线程锁`amtx`(第 19 行)，但在它可以锁定`umtx`(第 23 行)之前，`replenished`线程锁`umtx`(第 31 行)。 现在，耗尽的线程等待由`replenished`线程持有的`umtx`，而`replenished`线程等待由`exhausted`线程持有的`amtx`。 这两个线程无法从这种状态继续运行，它们被锁定在死锁中。

**死锁**是一种状态，在这种状态下，争用共享资源的两个或多个线程被阻塞，在等待一些资源的同时持有另一些资源，使得任何线程都不可能*从该状态前进。*

 *在我们的示例中，只涉及两个线程，调试和修复问题相对容易。 修复死锁的黄金标准是确保**固定的锁获取顺序**-任何线程都以相同的顺序获取两个给定的锁。 通过重写`u2a`，如以下代码片段所示，我们可以确保不会出现死锁：

```cpp
30 auto u2a = [&](int playerId) {
31     boost::unique_lock<boost::mutex> 
32       lka(amtx, boost::defer_lock),
33       lku(umtx, boost::defer_lock);
34                                              
35     boost::lock(lka, lku);  // ordered locking
36     auto it = unarmed.find(player{playerId});
37     if (it != unarmed.end()) {
38       auto plyr = *it;
39       armed.insert(plyr);
40       lka.unlock();
41       unarmed.erase(it);
42     }
43   };
```

在前面的代码中，我们确保`u2a`先锁定`amtx`，然后再锁定`umtx`，就像`a2u`所做的那样。 我们本可以按此顺序手动获取锁，但是，我们演示了如何使用`boost::lock`来完成此操作。 我们使用`defer_lock`标志创建`unique_lock`对象`lka`和`lku`，以指示我们还不想获取锁。 然后，我们调用`boost::lock`，按照我们想要获取的顺序传递`unique_lock`，`boost::lock`确保遵守顺序。

在本例中，使用`boost::unique_lock`而不是`boost::lock_guard`有两个原因：。 首先，我们可以在不立即锁定互斥锁的情况下创建`unique_lock`。 其次，我们可以调用`unlock`提前释放`unique_lock`(第 40 行)并增加锁的粒度，这会促进并发性。

除了固定的锁获取顺序之外，避免死锁的另一种方法是让线程探测锁(使用`try_lock`)，并在未能获取特定锁的情况下回溯。 这通常会使代码变得更加复杂，但有时可能是必要的。

有许多具有死锁的真实代码示例，就像我们的示例中的示例一样，它可能会正常工作多年，但其中潜伏着死锁。 有时，在一个系统上运行时遇到死锁的概率可能非常低，而当您在另一个系统上运行相同的代码时，您可能会立即遇到死锁，这完全是因为两个系统上线程调度的差异。

### 按条件同步

Mutexes通过创建临界区来序列化对共享数据的访问。 临界区就像一个有锁的房间，外面有候机区。 当其他线程到达外面时，一个线程获得锁并占用房间，等待占用者离开房间，然后按某个定义的顺序占据它的位置。 有时，线程需要等待某个条件变为真，例如某些共享数据更改状态。 让我们看看生产者-消费者问题，看看线程等待条件的例子。

#### 条件变量与生产者-消费者问题

Unix命令行实用程序**grep**在文件中搜索使用正则表达式指定的文本模式。 它可以搜索整个文件列表。 要在文件中搜索模式，必须读取文件的完整内容并搜索该模式。 根据要搜索的文件数量，可以使用一个或多个线程并发地将文件内容读入缓冲区。 缓冲区可以存储在某些数据结构中，该数据结构根据文件和偏移量对它们进行索引。 然后，多个线程可以处理这些缓冲区并在其中搜索模式。

我们刚才描述的是生产者-消费者问题的一个示例，其中一组线程生成一些内容并将其放入数据结构中，第二组线程从数据结构中读取内容并对其执行计算。 如果数据结构为空，则消费者必须等待生产者添加一些内容。 如果数据填满了数据结构，则生产者必须等待消费者处理一些数据并在数据结构中腾出空间，然后才能尝试添加更多内容。 换句话说，消费者等待特定的条件来满足，而这些条件是生产者行为的结果，反之亦然。

对这些条件进行建模、等待并发出信号的一种方式是使用`boost::condition_variable`对象。 **条件变量**是与程序中的可测试运行时条件或谓词相关联的。 线程测试条件，如果不为真，则线程使用`condition_variable`对象等待该条件变为真。 另一个导致条件为真的线程向条件变量发出信号，这将唤醒一个或多个等待线程。 条件变量固有地与共享数据相关联，并且表示共享数据所满足的某些条件。 为了让等待的线程首先测试共享数据上的条件，它必须获取互斥锁。 为了让信令线程更改共享数据的状态，它也需要互斥。 为了让等待的线程唤醒并验证更改的结果，它再次需要互斥。 因此，我们需要将`boost::mutex`与`boost::condition_variable`结合使用。

现在，我们将使用条件变量解决固定大小队列的生产者-消费者问题。 有一个固定大小的队列，这意味着队列中元素的最大数量是有界的。 一个或多个线程产生内容，**将它们排队**(将它们追加到队列中)。 一个或多个线程**将**内容出列(从队列头部移除内容)并对内容执行计算。 我们使用在固定大小`boost::array`之上实现的循环队列，而不是任何 STL 数据结构，如`std::list`或`std::deque`：

**清单 10.13：对线程安全、固定大小的队列使用条件变量**

```cpp
 1 #include <boost/thread/thread.hpp>
 2 #include <boost/thread/mutex.hpp>
 3 #include <boost/thread/condition_variable.hpp>
 4 #include <boost/array.hpp>
 5
 6 template <typename T, size_t maxsize>
 7 struct CircularQueue
 8 {
 9   CircularQueue () : head_(0), tail_(0) {}
10
11   void pop() {
12     boost::unique_lock<boost::mutex> lock(qlock);
13     if (size() == 0) {
14       canRead.wait(lock, [this] { return size() > 0; });
15     }
16     ++ head_;
17     lock.unlock();
18     canWrite.notify_one();
19   }
20
21   T top() {
22     boost::unique_lock<boost::mutex> lock(qlock);
23    if (size() == 0) {
24       canRead.wait(lock, [this] { return size() > 0; });
25     }
26     T ret = data[head_ % maxsize];
27     lock.unlock();
28
29     return ret;
30   }
31
32   void push(T&& obj) {
33     boost::unique_lock<boost::mutex> lock(qlock);
34     if (size() == capacity()) {
35       canWrite.wait(lock, [this] 
36                         { return size() < capacity(); });
37     }
38     data[tail_++ % maxsize] = std::move(obj);
39     lock.unlock();
40     canRead.notify_one();
41   }
42
43   size_t head() const { return head_; }
44   size_t tail() const { return tail_; }
45
46   size_t count() const {
47     boost::unique_lock<boost::mutex> lock(qlock);
48     return (tail_ - head_); 
49   }
50
51 private:
52   boost::array<T, maxsize> data;
53   size_t head_, tail_;
54 
55   size_t capacity() const { return maxsize; }
56   size_t size() const { return (tail_ - head_); };
57
58   mutable boost::mutex qlock;
59   mutable boost::condition_variable canRead;
60   mutable boost::condition_variable canWrite;
61 };
62
63 int main()
64 {
65   CircularQueue<int, 200> ds;
66
67   boost::thread producer([&ds] {
68             for (int i = 0; i < 10000; ++ i) {
69               ds.push(std::move(i));
70               std::cout << i << "-->"
71                   << " [" << ds.count() << "]\n";
72             }
73          });
74
75   auto func = [&ds] {
76     for (int i = 0; i < 2500; ++ i) {
77       std::cout << "\t\t<--" << ds.top() << "\n";
78       ds.pop();
79     }
80   };
81
82   boost::thread_group consumers;
83   for (int i = 0; i < 4; ++ i) {
84     consumers.create_thread(func);
85   }
86 
87   producer.join();
88   consumers.join_all();
89 }
```

在这个清单中，我们定义了`CircularQueue<>`模板及其成员函数，包括特别感兴趣的`pop`(第 11 行)和`push`(第 32 行)成员函数。 对`push`的调用会一直阻塞，直到队列中有空间可以添加新元素。 对`pop`的调用会阻塞，直到它能够读取队列顶部的元素并将其从队列顶部移除。 实用函数`top`(第 21 行)阻塞，直到它能够从队列顶部读取一个元素，并返回该元素的副本。

为了实现必要的同步，我们定义了互斥锁`qlock`(第 58 行)和两个条件变量`canRead`(第 59 行)和`canWrite`(第 60 行)。 `canRead`条件变量与一个谓词相关联，该谓词检查队列中是否有可以读取的元素。 `canWrite`条件变量与一个谓词相关联，该谓词检查队列中是否还有可以添加新元素的空间。 互斥锁`qlock`需要锁定才能编辑队列并以任何方式检查队列的状态。

`pop`方法首先获取`qlock`上的锁(第 12 行)，然后检查队列是否为空(第 13 行)。 如果队列为空，则调用必须阻塞，直到有可供读取的项。 为此，`pop`对`canRead`条件变量调用`wait`方法，将 lock`lock`和一个 lambda 谓词传递给它进行测试(第 14 行)。 对`wait`的调用解锁`lock`中的互斥并阻塞。 如果从另一个线程调用`push`方法成功，因此数据可用，则`push`方法解锁互斥锁(第 39 行)，并通过调用`notify_one`方法向`canRead`条件变量发送信号(第 40 行)。 这将唤醒在`pop`方法调用内的`wait`调用中阻塞的一个线程。 `wait`调用自动锁定互斥锁，检查谓词(`size() > 0`)是否为真，如果为真，则返回(第 14 行)。 如果谓词不为真，它将再次解锁互斥锁并返回等待。

`pop`方法要么从等待中唤醒，并在重新获取互斥锁之后验证是否有要读取的元素，要么不必等待，因为已经有要读取的元素了。 因此，`pop`继续删除列表头部的元素(第 16 行)。 删除元素后，它解锁互斥锁(第 17 行)，并对`canWrite`条件调用`notify_one`(第 18 行)。 如果它从已满的队列中弹出一个元素，并且在`push`中有线程被阻塞，等待队列中的某个空间，则对`notify_one`的调用将恰好唤醒在`push`内的`canWrite.wait(...)`中阻塞的一个线程(第 35 行)，并使其有机会向队列中添加项。

`push`的实现实际上是对称的，并且使用我们为`pop`描述的相同概念。 我们将互斥锁传递给条件变量的`wait`方法，包装在`unique_lock`而不是`lock_guard`中，因为等待方法需要访问底层互斥锁来手动解锁它。 底层互斥是通过调用`unique_lock`的`mutex`成员函数从`unique_lock`检索的；`lock_guard`没有提供这样的机制。

为了测试我们的实现，我们创建了一个包含 200 个类型为`int`的元素的`CircularQueue`(第 65 行)，一个将 10,000 个元素推入队列的生产者线程(第 67 行)，以及 4 个分别弹出 2,500 个元素的消费者线程(第 82-85 行)。

使用者线程不是单独创建的，而是作为**线程组**的一部分创建的。 线程组是`boost::thread_group`类型的对象，它提供了一种将多个线程放在一起管理的简单方法。 由于我们希望使用相同的初始函数创建四个使用者线程并连接它们，因此很容易创建一个`thread_group`对象(第 82 行)，使用其`create_thread`成员函数在循环中创建四个线程(第 84 行)，并通过调用`join_all`方法来等待组中的所有线程(第 88 行)。

##### 条件变量细微差别

我们调用`notify_one`来通知`canRead`条件变量，并恰好唤醒一个等待读取的线程(第 39 行)。 相反，我们可以调用`notify_all`来*广播*事件并唤醒所有等待的线程，它仍然可以工作。 但是，在每次调用`push`时，我们只在队列中放入一个新元素，因此只有一个被唤醒的线程会从队列中读取新元素。 其他线程将检查队列中元素的数量，发现它是空的，然后返回等待，从而导致不必要的上下文切换。

但是，如果我们向队列中添加了大量元素，则调用`notify_all`可能比调用`notify_one`更好。 调用`notify_one`将仅唤醒一个等待线程，该线程将在循环中串行处理元素(第 63-65 行)。 调用`notify_all`将唤醒所有线程，它们并发处理元素的速度会快得多。

一个常见的难题是，是在保持互斥体的同时调用`notify_one`/`notify_all`，就像我们在前面的示例中所做的那样，还是在释放互斥体之后调用`notify_one`/`notify_all`。 这两个选项都工作得很好，但性能可能会有所不同。 如果在持有互斥锁的同时发出条件变量信号，唤醒的线程将立即阻塞，等待互斥锁，直到释放它。 因此，每个线程有两个额外的上下文切换，这可能会影响性能。 因此，如果您在发出条件变量信号之前先解锁互斥锁，您可能会看到一些性能上的好处。 因此，在解锁之后发送*信号通常是首选的方法。*

### 读者与作者的问题

以图书馆在线目录的案例为例。 图书馆设有图书查阅表。 为简单起见，让我们假设书籍只能通过书名查找，而书名是独一无二的。 代表各种客户端的多个线程同时在库上执行查找。 有时，图书管理员会将新书添加到目录中，很少会将一本书从目录中删除。 仅当具有相同标题的图书尚未存在，或者存在较旧版本的图书时，才能添加新书。

在下面的代码片断中，我们定义了一个表示图书条目的类型和表示图书馆目录的`LibraryCatalog`类的公共接口：

**清单 10.14a：库目录类型和接口**

```cpp
 1 struct book_t
 2 {
 3   std::string title;
 4   std::string author;
 5   int edition;
 6 };
 7
 8 class LibraryCatalog
 9 {
10 public:
11   typedef boost::unordered_map<std::string, book_t> map_type;
12   typedef std::vector<book_t> booklist_t;
13
14   boost::optional<book_t> find_book(const std::string& title) 
15                                                       const;
16   booklist_t find_books(const std::vector<std::string>& 
17                                            titles) const;
18   bool add_book(const book_t& book);
19   bool remove_book(const std::string& title);
20 };
```

成员函数`find_book`用于查找单个标题，并将其作为包装在`boost::optional`中的`book_t`对象返回。 使用`boost::optional`，如果找不到标题，我们可以返回空值(参见[第 2 章](02.html "Chapter 2. The First Brush with Boost's Utilities")，*第一个带有 Boost 实用程序的画笔*)。 成员函数`find_books`查找作为`vector`传递给它的标题列表，并返回`book_t`个对象的向量。 成员函数`add_book`向目录添加标题，`remove_book`从目录中删除标题。

我们希望实现该类以允许多个线程并发查找标题。 我们还希望允许图书管理员在阅读的同时添加和删除图书，而不会影响正确性或一致性。

只要目录中的数据不变，多个线程就可以同时查找标题，而不需要任何同步；因为只读操作不会导致不一致。 但是，由于目录确实允许图书管理员添加和删除图书，我们必须确保这些操作不会与读取操作交错。 因此，在制定我们的需求时，我们只说明了经典的并发问题，即读者-作者问题(Reader-Writers Problem)。 读者与作者之间的问题规定了以下限制条件：

*   任何写入线程都必须具有对数据结构的独占访问权限
*   在没有写入器线程的情况下，任何读取器线程都可以与其他读取器线程共享对数据结构的访问

在上述语句中，*读取器线程*是指只执行只读操作(如查找标题)的线程，而*写入器线程*是指以某种方式修改数据结构内容的线程，如添加和删除标题。 这有时被称为**多个读取器单个写入器**(**MRSW**)模型，因为它允许多个并发读取器或单个独占写入器。

虽然`boost::mutex`允许单个线程获取排他锁，但它不允许多个线程共享一个锁。 为此，我们需要使用`boost::shared_mutex`。 `boost::shared_mutex`符合*SharedLockable*概念，该概念包含了可锁定概念，另外还定义了应该由读取器线程调用的`lock_shared`和`unlock_shared`成员函数。 因为`shared_mutex`也符合 Lockable，所以可以使用`boost::lock_guard`或`boost::unique_lock`锁定它以进行独占访问。 现在让我们来看一下`LibraryCatalog`的实现情况：

**清单 10.14b：库目录实现**

```cpp
 1 #include <vector>
 2 #include <string>
 3 #include <boost/thread.hpp>
 4 #include <boost/optional.hpp>
 5 #include <boost/unordered/unordered_map.hpp>
 6
 7 struct book_t { /* definitions */ };
 8
 9
10 class LibraryCatalog {
11 public:
12   typedef boost::unordered_map<std::string, book_t> map_type;
13   typedef std::vector<book_t> booklist_t;
14
15   boost::optional<book_t> find_book(const std::string& title)
16                                                       const {
17     boost::shared_lock<boost::shared_mutex> rdlock(mtx);
18     auto it = catalog.find(title);
19
20     if (it != catalog.end()) {
21       return it->second;
22     }
23     rdlock.unlock();
24
25     return boost::none;
26   }
27
28   booklist_t find_books(const std::vector<std::string>& titles)
29                                                         const {
30     booklist_t result;
31     for (auto title : titles) {
32       auto book = find_book(title);
33
34       if (book) {
35         result.push_back(book.get());
36       }
37     }
38
39     return result;
40   }
41
42   bool add_book(const book_t& book) {
43     boost::unique_lock<boost::shared_mutex> wrlock(mtx);
44     auto it = catalog.find(book.title);
45
46     if (it == catalog.end()) {
47       catalog[book.title] = book;
48       return true;
49     }
50     else if (it->second.edition < book.edition) {
51       it->second = book;
52       return true;
53     }
54
55     return false;
56   }
57
58   bool remove_book(const std::string& title) {
59     boost::unique_lock<boost::shared_mutex> wrlock(mtx);
60     return catalog.erase(title);
61   }
62
63 private:
64   map_type catalog;
65   mutable boost::shared_mutex mtx;
66 };
```

方法`find_book`在编目上执行只读操作，因此使用`boost::shared_lock`模板获取共享锁(第 17 行)。 它在检索到匹配的图书(如果有的话)后释放锁(第 23 行)。 方法`find_books`是根据`find_book`实现的，对于传递给它的列表中的每个标题，它都会在循环中调用它。 由于重复锁定和解锁`shared_mutex`，这允许在读取器线程之间实现更好的整体并发性，但代价是略微影响性能。

`add_book`和`remove_book`都是可能改变目录中元素数量的变异函数。 为了修改目录，这两种方法都需要目录上的独占锁或写锁。 因此，我们使用`unique_lock`实例获取`shared_mutex`上的独占锁(第 43 和 59 行)。

#### 可升级锁

在清单 10.14b 中的`add_book`和`remove_book`方法的实现中有一个明显的问题。 这两种方法都根据首先运行的查找结果有条件地修改目录。 然而，排他锁是在两个操作开始时无条件获取的。 可以想象的是，可以用一个不存在的标题调用`remove_book`，或者用已经在目录中的图书版本调用`add_book`，循环地调用，这会严重影响系统的并发性，什么也不做。

如果我们获取了一个共享锁来执行查找，那么在获取用于修改目录的独占锁之前，我们必须释放它。 在这种情况下，查找结果将不再可靠，因为在释放共享锁和获取排他锁之间，某个其他线程可能已经修改了目录。

这个问题可以通过使用`boost::upgrade_lock`和一组关联的原语来解决。 这在下面重写的`add_book`中显示：

```cpp
 1 bool LibraryCatalog::add_book(const book_t& book) {
 2   boost::upgrade_lock<boost::shared_mutex> upglock(mtx);
 3   auto it = catalog.find(book.title);
 4
 5   if (it == catalog.end()) {
 6     boost::upgrade_to_unique_lock<boost::shared_mutex> 
 7                                             ulock(upglock);
 8     catalog[book.title] = book;
 9     return true;
10   } else if (it->second.edition > book.edition) {
11     boost::upgrade_to_unique_lock<boost::shared_mutex> 
12                                             ulock(upglock);
13     it->second = book;
14     return true;
15   }
16
17   return false;
18 }
```

我们不是从获取排他锁开始，而是在执行查找之前获取*升级锁*(第 2 行)，然后*将*升级为唯一锁(第 6-7 行和第 11-12 行)。 为了获得升级锁，我们将共享互斥锁包装在一个`upgrade_lock<boost::shared_mutex>`实例中(第 2 行)。 如果互斥体上存在有效的独占锁或另一个升级锁，则会阻止此操作，但即使存在共享锁，此操作也会继续进行。 因此，在任何时间点，互斥锁上都可以有任意数量的共享锁和最多一个升级锁。 因此，获取升级锁不会影响读取并发性。 一旦执行了查找，并且确定需要执行写操作，则通过将升级锁包装在`upgrade_to_unique_lock<boost::shared_mutex>`的实例中将其提升为唯一锁(第 6-7 行和第 11-12 行)。 这会阻塞，直到没有剩余的共享锁，然后*自动*释放升级所有权并获取`shared_mutex`的独占所有权。

### 备注

获取升级锁表示有可能将其升级为排他锁并执行写入或修改的意图。

#### Shared_mutex 的性能

`boost::shared_mutex`比`boost::mutex`慢，但在已经读锁定的互斥锁上获取额外的读锁定要快得多。 它非常适合于不需要独占写访问的频繁并发读取。 任何时候处理频繁写入时，只需使用`boost::mutex`提供独占写入访问即可。

大多数 MRSW 问题的解决方案要么更喜欢读者而不是作者，或者相反。 在**优先读取解决方案**中，当共享锁生效时，即使写入器正在等待获取排他锁，新的读取器线程也可以获取共享锁。 这会导致写匮乏，因为写入器只有在没有读取器的时候才会获得独占锁。 在**写优先解决方案**中，如果有写线程等待排他锁，那么即使现有的读取器持有共享锁，新的读取器也会排队。 这会影响读取的并发性。 Boost 1.57(当前版本)提供了一个完全公平的共享/排他锁实现，并且没有读取器或写入器偏见。

### 标准库原语

C++ 11 标准库引入了`std::mutex`和一整套锁的 RAII 包装器，包括标题`mutex`中的`std::lock_guard`、`std::unique_lock`和`std::lock`。 C++ 11 标准库还在标题`condition_variable`中引入了可用的`std::condition_variable`。 C++ 14 标准库引入了`std::shared_timed_mutex`，它对应于标题`mutex`中的`boost::shared_mutex`和`std::shared_lock`。 它们与同名的 Boost 对应，并且具有非常相似的接口。 从 C++ 14 开始，标准库中没有升级锁功能，也没有任何与方便的`boost::thread_group`等价物。

# ♪T0äBoost Coroutine

协程是这样的函数，它们可以*产生*或将控制权让给另一个协程，然后从它们先前屈服的点恢复控制权。 在收益率和恢复之间保持自动变量的状态。 协程程序可以用于复杂的控制流模式，代码非常简单和干净。 Boost 协程程序库提供两种类型的协程程序：

*   **非对称协同例程**：非对称协同例程区分呼叫方和被呼叫方协同例程。 使用非对称协同例程，被调用者只能退回给调用者。 它们通常用于从被呼叫者到呼叫者的单向数据传输，或者以其他方式传输。
*   **对称协同例程**：这样的协同例程可以将*生成*给其他协同例程，而不管调用者是谁。 它们可以用于生成复杂的协程协作链。

当协程程序产生控制权时，它被称为挂起-它的寄存器被保存，并且它将控制权让给另一个函数。 在恢复时，寄存器被恢复，并且在屈服点之后继续执行。 Boost Cooutine 库利用 Boost 上下文库来实现此目的。

区分了*堆栈协程*和*无堆栈协程*。 堆栈协程可以从协程调用的函数中挂起，也就是从嵌套的堆栈框架挂起。 使用无堆栈的协程，只有顶级例程可以挂起自己。 在本章中，我们只看非对称堆栈协程。

## 非对称协同程序

用于定义非对称协同例程的核心模板称为`boost::coroutines::asymmetric_coroutine<>`。 它接受单个类型参数，该参数表示从一个协程转移到另一个协程的值的类型。 如果不需要传输任何值，则可以是`void`。

调用或屈服于其他协同例程的协同例程必须有一种引用其他协同例程的方式。 嵌套类型`asymmetric_coroutine<T>::push_type`表示提供类型`T`的数据的协程，而嵌套类型`asymmetric_coroutine<T>::pull_type`表示使用类型`T`的数据的协程。 这两种类型都是可调用类型，带有重载的`operator()`。 使用这些类型，我们现在将编写一个使用协程从元素向量中读取数据的程序：

**清单 10.15：使用非对称协同例程**

```cpp
 1 #include <iostream>
 2 #include <boost/coroutine/all.hpp>
 3 #include <boost/bind.hpp>
 4 #include <vector>
 5 #include <string>
 6
 7 template <typename T>
 8 using pull_type = typename
 9   boost::coroutines::asymmetric_coroutine<T>::pull_type;
10
11 template <typename T>
12 using push_type = typename
13   boost::coroutines::asymmetric_coroutine<T>::push_type;
14
15 template <typename T>
16 void getNextElem(push_type<T>& sink, 
17                  const std::vector<T>& vec)
18 {
19   for (const auto& elem: vec) {
20     sink(elem);
21   }
22 }
23
24 int main()
25 {
26   std::vector<std::string> vec{"hello", "hi", "hola", 
27                                "servus"};
28   pull_type<std::string> greet_func(
29       boost::bind(getNextElem<std::string>, ::_1, 
30       boost::cref(vec)));
31
32   while (greet_func) {
33     std::cout << greet_func.get() << '\n';
34     greet_func();
35   }
36 }
```

为了开始，我们定义了两个别名模板`pull_type`和`push_type`，分别引用类型参数 T 的`asymmetric_coroutine<T>::pull_type`和`asymmetric_coroutine<T>::push_type`(第 7-9 行和第 11-13 行)。

函数`getNextElem`(第 16 行)用作协程，每次调用时将向量中的下一个元素传递给调用者。 `main`函数填充此向量(第 26-27 行)，然后重复调用`getNextElem`以获取每个元素。 因此，数据从`getNextElem`传送到`main`，`main`是调用方例程，`getNextElem`是被调用方例程。

根据协程是将数据推送到调用方还是从调用方提取数据，它应该具有以下两个签名之一：

*   `void (push_type&)`：协程将数据推送给调用者
*   `void(pull_type&)`：Coroutine 从调用者拉取数据

传递给协程的`pull_type`或`push_type`引用引用调用上下文，并表示通过其将数据推送到调用方或从调用方拉出数据的管道。

调用者例程必须将函数包装在`pull_type`或`push_type`中，具体取决于它打算从函数中拉出数据还是将数据推送到函数中。 在我们的例子中，`main`函数必须将`getNextElem`包装在`pull_type`的实例中。 但是，`getNextElem`的签名是：

```cpp
void (push_type&, const std::vector<T>&)
```

因此，我们必须使用某种机制(如 lambda 或`bind`)使其适应一致性签名。 我们使用`boost::bind`将`getNextElem`的第二个参数绑定到向量(第 29-30 行)，并将生成的一元函数对象包装在名为`greet_func`的`pull_type`实例中。 创建`pull_type`的实例将第一次调用`getNextElem`协程。

我们可以在布尔上下文中使用`greet_func`来检查是否有来自被调用者的值，并使用它在循环中旋转(第 32 行)。 在循环的每次迭代中，我们调用`pull_type`实例上的`get`成员函数以获得`getNextElem`提供的下一个值(第 33 行)。 然后，我们调用`pull_type`的重载的`operator()`将控制权让给`getNextElem`协程(第 34 行)。

另一方面，`getNextElem`协程不使用常规返回值将数据发送回调用方。 它迭代向量并使用调用上下文上的重载`operator()`返回每个元素(第 20 行)。 如果调用方必须将数据推送到被调用方，那么调用方将把被调用方包装在`push_type`中，并将被调用方的引用传递到包装在`pull_type`中的被调用方。 在下一章中，我们将看到 Boost ASIO 如何使用协同例程来简化异步的事件驱动逻辑。

# 自测题

对于多项选择题，请选择适用的所有选项：

1.  What happens if you do not call `join` or `detach` on a `boost::thread` object and a `std::thread` object?

    A.在`boost::thread`的底层线程上调用`join`。

    B.为`std::thread`调用`std::terminate`，终止程序。

    C.在`boost::thread`的底层线程上调用`detach`。

    D.在`std::thread`的底层线程上调用`detach`。

2.  What happens if an exception is allowed to propagate past the initial function with which a `boost::thread` object is created?

    A.程序通过`std::terminate`终止。

    B.这是一种未定义的行为。

    C.对`future`对象的`get`调用在调用线程中抛出异常。

    D.线程终止，但不传播异常。

3.  Should you call `notify_one` or `notify_all` on a `condition_variable` object without holding the associated mutex?

    A.不，呼叫将被阻止。

    可以，但在某些情况下可能会导致优先级反转。

    C.否，某些等待线程可能会错过该信号。

    是的，它甚至可能更快。

4.  What is the advantage of using `boost::unique_lock` over `boost::lock_guard`?

    A.`boost::unique_lock`更高效、更轻便。

    B.`boost::unique_lock`可以或采用已获取的锁。

    C.`boost::lock_guard`不能在作用域中途解锁和重新锁定。

    D.`boost::unique_lock`可以推迟获取锁。

5.  Which of the following are true of `boost::shared_mutex`?

    A.`shared_mutex`比`boost::mutex`更轻、更快。

    B.`shared_mutex`的 Boost 实现不存在读取器或写入器偏见。

    C.`shared_mutex`可作为可升级锁使用。

    D.`shared_mutex`非常适合具有高写入争用的系统。

# 摘要

在本章中，我们研究了如何使用 Boost 线程库和 C++ 11 标准库编写线程和任务方面的并发逻辑。 我们学习了如何使用未来和承诺范例来定义并发任务之间的操作顺序，以及标准库中围绕未来和承诺的一些抽象。 我们还研究了各种基于锁的线程同步原语，并将它们应用于一些常见的多线程问题。

多线程是一个困难而复杂的主题，本章仅介绍 Boost 中可用于编写并发程序的可移植 API。 Boost 线程库和 C++ 标准库中的并发编程接口是一个不断发展的集合，我们没有介绍几个特性：C++ 内存模型和原子、Boost Lockfree、线程取消、`boost::future`的实验延续，以及其他几个主题。 设计并发系统和并发数据结构中的体系结构问题是本书范围之外的其他相关主题。 希望本章中介绍的概念和方法能帮助您进一步探索这些方向。

# 发文：2013 年 2 月 10 日星期日下午 12：00

*   *操作中的 C++ 并发性*，*Anthony Williams*，*Manning Publications*
*   无锁数据结构：[http://www.boost.org/libs/lockfree](http://www.boost.org/libs/lockfree)
*   *向 C++ 标准库(版本 1)*、*Oliver Kosalke*和*NAT GoodSpeed*：[http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2014/n3985.pdf](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2014/n3985.pdf)添加协程程序的建议
*   无锁编程，Herb Sutter：[https://youtu.be/c1gO9aB9nbs](https://youtu.be/c1gO9aB9nbs)
*   原子<>武器(视频)，Herb Sutter：
    *   [https：//channel9.msdn.com/Shows/Going+Deep/Cpp-and-Beyond-2012-Herb-Sutter-atomic-Weapons-1-of-2](https://channel9.msdn.com/Shows/Going+Deep/Cpp-and-Beyond-2012-Herb-Sutter-atomic-Weapons-1-of-2)
    *   [https：//channel9.msdn.com/Shows/Going+Deep/Cpp-and-Beyond-2012-Herb-Sutter-atomic-Weapons-2-of-2](https://channel9.msdn.com/Shows/Going+Deep/Cpp-and-Beyond-2012-Herb-Sutter-atomic-Weapons-2-of-2)*