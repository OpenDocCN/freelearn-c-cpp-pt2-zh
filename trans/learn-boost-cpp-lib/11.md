# 第 11 章使用 Boost ASIO 进行网络编程

在今天的网络世界中，每秒处理数千个请求的互联网服务器有一项艰巨的任务要完成-保持响应能力，即使请求数量不断增加也不会变慢。 构建高效地处理网络 I/O 并随连接数量进行扩展的可靠进程是具有挑战性的，因为这通常需要应用程序编程人员了解底层协议栈并以巧妙的方式利用它。 增加挑战的是跨平台网络编程的编程接口和模型的差异，以及使用低级 API 的固有困难。

Boost ASIO(发音为 ay-see-oh)是一个可移植的库，用于使用一致的编程模型执行高效的网络 I/O。 重点是执行异步 I/O(因此而得名 ASIO)，即程序启动 I/O 操作并继续执行其他作业，而不会阻塞操作系统返回操作结果。 当操作在底层操作系统中完成时，ASIO 库会通知程序并采取适当的操作。 ASIO 帮助解决的问题，以及它用来解决这些问题的一致的、可移植的接口，使 ASIO 具有令人信服的用处。 但是，交互的异步本质也使它变得更加复杂，不那么直接地进行推理。 这就是我们将分两部分研究 ASIO 的原因：首先了解其交互模型，然后使用它执行网络 I/O：

*   使用 ASIO 执行任务
*   使用 ASIO 进行网络编程

ASIO 提供了执行和管理任意任务的工具包，本章第一部分的重点是理解该工具包。 我们将在本章的第二部分具体介绍 ASIO 如何使用网际协议(IP)套件中的协议来帮助编写通过网络与其他程序通信的程序。

# 使用 ASIO 执行任务

在其核心，Boost ASIO提供了一个任务执行框架，您可以使用该框架来执行任何类型的操作。 您可以将任务创建为函数对象，并将它们发布到由 Boost ASIO 维护的任务队列。 您可以征用一个或多个线程来挑选这些任务(函数对象)并调用它们。 线程不断地拾取任务，一个接一个，直到任务队列为空，此时线程不会阻塞而是退出。

## IO 服务、队列和处理程序

ASIO 的核心是类型`boost::asio::io_service`。 程序使用`io_service`接口执行网络 I/O 和管理任务。 任何想要使用 ASIO 库的程序都会创建至少一个`io_service`实例，有时还会创建多个实例。 在本节中，我们将探讨`io_service`的任务管理功能，并将网络 I/O 的讨论推迟到本章的后半部分。

下面是使用必备的“hello world”示例运行的 IO 服务：

**清单 11.1：ASIO Hello World**

```
 1 #include <boost/asio.hpp>
 2 #include <iostream>
 3 namespace asio = boost::asio;
 4
 5 int main() {
 6   asio::io_service service;
 7
 8   service.post(
 9     [] {
10       std::cout << "Hello, world!" << '\n';
11     });
12
13   std::cout << "Greetings: \n";
14   service.run();
15 }
```

我们包含便利头`boost/asio.hpp`，它包含了本章(第 1 行)示例所需的大部分 ASIO 库。 ASIO 库的所有部分都在名称空间`boost::asio`下，因此我们为此使用了一个较短的别名(第 3 行)。 程序本身只是在控制台上打印`Hello, world!`，但它是通过一个任务来打印的。

程序首先创建`io_service`的一个实例(第 6 行)，然后*使用`io_service`的`post`成员函数向其发送*一个函数对象。 在这种情况下使用 lambda 表达式定义的函数对象被称为作为**处理程序**。 对`post`的调用将处理程序添加到`io_service`内的队列中；一些线程(包括发布处理程序的线程)必须*分派*它们，即从队列中移除它们并调用它们。 对`io_service`的`run`成员函数(第 14 行)的调用就是这样做的。 它循环通过`io_service`内部队列中的处理程序，删除并调用每个处理程序。 事实上，在调用`run`之前，我们可以向`io_service`发送更多处理程序，它将调用所有已发送的处理程序。 如果我们不调用`run`，则不会调度任何处理程序。 `run`函数会一直阻塞，直到队列中的所有处理程序都被调度完毕，并且只有在队列为空时才返回。 处理程序本身可以被认为是一个独立的打包任务，而 Boost ASIO 提供了一种将任意任务作为处理程序分派的很好的机制。 请注意，处理程序必须是空函数对象，也就是说，它们不应该接受任何参数。

### 备注

默认情况下，ASIO 是仅包含标题的库，但使用 ASIO 的程序至少需要与`boost_system`链接。 在 Linux 上，我们可以使用以下命令行构建此示例：

```
$ g++ -g listing11_1.cpp -o listing11_1 -lboost_system -std=c++ 11

```

本章中的大多数示例都要求您链接到其他库。 您可以使用以下命令行构建本章中的所有示例：

```
$ g++ -g listing11_25.cpp -o listing11_25 -lboost_system -lboost_coroutine -lboost_date_time -std=c++ 11

```

如果您没有从本机软件包安装 Boost，并且要在 Windows 上安装，请参阅[第 1 章](01.html "Chapter 1. Introducing Boost")，*Boost*简介。

运行此程序将打印以下内容：

```
Greetings: Hello, World!
```

请注意，在调用`run`(第 14 行)之前，会从主函数(第 13 行)打印`Greetings:`。 对`run`的调用以调度队列中唯一的处理程序结束，该处理程序打印`Hello, World!`。 多个线程还可以同时调用同一 I/O 对象上的`run`并分派处理程序。 我们将在下一节中看看这是如何有用的。

### 处理程序状态-RUN_ONE、POLL 和 POLL_ONE

虽然`run`函数会一直阻塞，直到队列中不再有处理程序，但`io_service`的其他成员函数可以让您更灵活地处理处理程序。 但在查看此函数之前，我们需要区分挂起处理程序和就绪处理程序。

我们发布到`io_service`的处理程序都已准备好立即运行，并在队列中轮到它们时立即被调用。 通常，处理程序与底层操作系统中运行的后台任务相关联，例如网络 I/O 任务。 这样的处理程序只能在相关任务完成后调用，这就是为什么在这样的上下文中，它们被称为**完成处理程序**。 在关联任务等待完成之前，这些处理程序被称为**挂起**，一旦关联任务完成，它们就被称为**就绪**。

与`run`不同，`poll`成员函数调度所有就绪处理程序，但不等待任何挂起的处理程序准备就绪。 因此，如果没有就绪的处理程序，即使有挂起的处理程序，它也会立即返回。 `poll_one`成员函数恰好调度一个就绪处理程序(如果有)，但不会阻止等待挂起的处理程序做好准备。

`run_one`成员函数阻塞在非空队列上，等待处理程序准备就绪。 在空队列上调用时返回，否则在找到并调度就绪处理程序后立即返回。

### 邮寄与派单

对`post`成员函数的调用会将处理程序添加到任务队列并立即返回。 稍后对`run`的调用负责调度处理程序。 如果可能，还有另一个名为`dispatch`的成员函数可用于请求`io_service`立即调用处理程序。 如果在已经调用了`run`、`poll`、`run_one`或`poll_one`之一的线程中调用了`dispatch`，则将立即调用处理程序。 如果没有这样的线程可用，`dispatch`会将处理程序添加到队列中并返回，就像`post`一样。 在下面的示例中，我们从`main`函数和另一个处理程序中调用`dispatch`：

**清单 11.2：POST 与 DISPATION**

```
 1 #include <boost/asio.hpp>
 2 #include <iostream>
 3 namespace asio = boost::asio;
 4
 5 int main() {
 6   asio::io_service service;
 7   // Hello Handler – dispatch behaves like post
 8   service.dispatch([]() { std::cout << "Hello\n"; });
 9
10   service.post(
11     [&service] { // English Handler
12       std::cout << "Hello, world!\n";
13       service.dispatch([] {  // Spanish Handler, immediate
14                          std::cout << "Hola, mundo!\n";
15                        });
16     });
17   // German Handler
18   service.post([&service] {std::cout << "Hallo, Welt!\n"; });
19   service.run();
20 }
```

运行此代码会产生以下输出：

```
Hello
Hello, world!
Hola, mundo!
Hallo, Welt!
```

对`dispatch`(第 8 行)的第一个调用将一个处理程序添加到队列中，但没有调用它，因为`run`尚未在`io_service`上调用。 我们称之为 Hello Handler，因为它打印`Hello`。 紧随其后的是对`post`的两个调用(第 10、18 行)，这又添加了两个处理程序。 这两个处理程序中的第一个打印`Hello, world!`(第 12 行)，然后调用`dispatch`(第 13 行)添加另一个打印西班牙语问候语`Hola, mundo!`的处理程序(第 14 行)。 第二个处理程序打印德语问候语`Hallo, Welt`(第 18 行)。 为了方便起见，我们就称他们为英国人、西班牙人和德国人吧。 这将在队列中创建以下条目：

```
Hello Handler
English Handler
German Handler
```

现在，当我们在`io_service`(第 19 行)上调用`run`时，Hello 处理程序首先被调度并打印`Hello`。 紧随其后的是英语处理程序，它打印`Hello, World!`并在`io_service`上调用`dispatch`，传递给西班牙语处理程序。 因为这是在已经调用`run`的线程的上下文中执行的，所以对`dispatch`的调用将调用西班牙处理程序，后者打印`Hola, mundo!`。 此后，在`run`返回之前，德语处理程序被调度打印`Hallo, Welt!`。

如果英语处理程序调用`post`而不是`dispatch`(第 13 行)怎么办？ 在这种情况下，西班牙语处理程序不会立即被调用，但会排在德语处理程序之后。 德语问候语`Hallo, Welt!`将在西班牙语问候语`Hola, mundo!`之前。 输出将如下所示：

```
Hello
Hello, world!
Hallo, Welt!
Hola, mundo!
```

## 通过线程池并发执行

`io_service`对象是线程安全的，多个线程可以对其并发调用`run`。 如果队列中有多个处理程序，则可以由这些线程并发处理它们。 实际上，在给定的`io_service`上调用`run`的线程集形成了一个**线程池**。 池中的不同线程可以处理连续的处理程序。 哪个线程调度给定的处理程序是不确定的，因此处理程序代码不应该做出任何这样的假设。 在下面的示例中，我们将一组处理程序发布到`io_service`，然后启动四个线程，它们都在其上调用`run`：

**清单 11.3：简单线程池**

```
 1 #include <boost/asio.hpp>
 2 #include <boost/thread.hpp>
 3 #include <boost/date_time.hpp>
 4 #include <iostream>
 5 namespace asio = boost::asio;
 6
 7 #define PRINT_ARGS(msg) do {\
 8   boost::lock_guard<boost::mutex> lg(mtx); \
 9   std::cout << '[' << boost::this_thread::get_id() \
10             << "] " << msg << std::endl; \
11 } while (0)
12
13 int main() {
14   asio::io_service service;
15   boost::mutex mtx;
16
17   for (int i = 0; i < 20; ++ i) {
18     service.post([i, &mtx]() { 
19                          PRINT_ARGS("Handler[" << i << "]");
20                          boost::this_thread::sleep(
21                               boost::posix_time::seconds(1));
22                        });
23   }
24
25   boost::thread_group pool;
26   for (int i = 0; i < 4; ++ i) {
27     pool.create_thread([&service]() { service.run(); });
28   }
29
30   pool.join_all();
31 }
```

我们在一个循环中发布 20 个处理程序(第 18 行)。 每个处理程序打印其标识符(第 19 行)，然后休眠一秒钟(第 19-20 行)。 为了运行处理程序，我们创建了一组四个线程，每个线程都在`io_service`上运行调用(第 21 行)，并等待所有线程完成(第 24 行)。 我们定义宏`PRINT_ARGS`，它以线程安全的方式将输出写入控制台，并用当前线程 ID 进行标记(第 7-10 行)。 我们还将在其他示例中使用此宏。

要构建此示例，还必须针对`libboost_thread`、`libboost_date_time`以及 POSIX 环境中的`libpthread`进行链接：

```
$ g++ -g listing9_3.cpp -o listing9_3 -lboost_system -lboost_thread -lboost_date_time -pthread -std=c++ 11

```

在我的笔记本电脑上运行该程序一次就产生了以下输出(有些行被剪掉了)：

```
[b5c15b40] Handler[0]
[b6416b40] Handler[1]
[b6c17b40] Handler[2]
[b7418b40] Handler[3]
[b5c15b40] Handler[4]
[b6416b40] Handler[5]
…
[b6c17b40] Handler[13]
[b7418b40] Handler[14]
[b6416b40] Handler[15]
[b5c15b40] Handler[16]
[b6c17b40] Handler[17]
[b7418b40] Handler[18]
[b6416b40] Handler[19]
```

您可以看到，不同的处理程序由不同的线程执行(每个线程 ID 标记不同)。

### 提示

如果任何处理程序抛出异常，它将通过对正在执行该处理程序的线程上的`run`函数的调用传播。

### io_service：：work

有时，保持线程池启动非常有用，即使在没有处理程序要调度的情况下也是如此。 空队列上的`run`和`run_one`都不阻塞。 因此，为了让他们阻止等待一项任务，我们必须在某种程度上表明，有未完成的工作要完成。 我们通过创建`io_service::work`的实例来实现这一点，如下例所示：

**清单 11.4：使用 io_service：：Work 保持线程占用**

```
 1 #include <boost/asio.hpp>
 2 #include <memory>
 3 #include <boost/thread.hpp>
 4 #include <iostream>
 5 namespace asio = boost::asio;
 6
 7 typedef std::unique_ptr<asio::io_service::work> work_ptr;
 8
 9 #define PRINT_ARGS(msg) do {\ … 
...
14
15 int main() {
16   asio::io_service service;
17   // keep the workers occupied
18   work_ptr work(new asio::io_service::work(service));
19   boost::mutex mtx;
20
21   // set up the worker threads in a thread group
22   boost::thread_group workers;
23   for (int i = 0; i < 3; ++ i) {
24     workers.create_thread([&service, &mtx]() {
25                          PRINT_ARGS("Starting worker thread ");
26                          service.run();
27                          PRINT_ARGS("Worker thread done");
28                        });
29   }
30
31   // Post work
32   for (int i = 0; i < 20; ++ i) {
33     service.post(
34       [&service, &mtx]() {
35         PRINT_ARGS("Hello, world!");
36         service.post([&mtx]() {
37                            PRINT_ARGS("Hola, mundo!");
38                          });
39       });
40   }
41
42   work.reset(); // destroy work object: signals end of work
43   workers.join_all(); // wait for all worker threads to finish
44 }
```

在本例中，我们创建了一个包装在`unique_ptr`中的对象`io_service::work`(第 18 行)。 我们通过将对`io_service`对象的引用传递给`work`构造函数，将其与一个`io_service`对象相关联。 注意，与清单 11.3 不同，我们首先创建工作线程(第 24-27 行)，然后发布处理程序(第 33-39 行)。 然而，由于对`run`块的调用，工作线程保持原地等待处理程序(第 26 行)。 这是因为我们创建了`io_service::work`对象，该对象指示在`io_service`队列中有未完成的工作。 因此，即使在调度完所有处理程序之后，线程也不会退出。 通过在包装`work`对象的`unique_ptr,`上调用`reset`，将调用其析构函数，该函数通知`io_service`所有未完成的工作都已完成(第 42 行)。 线程中对`run`的调用返回，一旦所有线程加入，程序就退出(第 43 行)。 我们将`work`对象包装在`unique_ptr`中，以便在程序中的适当位置以异常安全的方式销毁它。

我们在这里省略了`PRINT_ARGS`的定义，请参阅清单 11.3。

## 串行化有序执行

线程池允许处理程序并发运行。 这意味着访问共享资源的处理程序需要同步对这些资源的访问。 当我们同步对全局对象`std::cout`的访问时，我们已经在清单 11.3 和 11.4 中看到了这种情况的示例。 作为在处理程序中编写同步代码(这会使处理程序代码更加复杂)的替代方案，我们可以使用**strands**。

### 提示

可以将链看作任务队列的子序列，其约束是同一链中的两个处理程序永远不会同时运行。

队列中不在该链中的其他处理程序的调度不受该链的任何影响。 让我们看一个使用线束的示例：

**清单 11.5：使用 Strands**

```
 1 #include <boost/asio.hpp>
 2 #include <boost/thread.hpp>
 3 #include <boost/date_time.hpp>
 4 #include <cstdlib>
 5 #include <iostream>
 6 #include <ctime>
 7 namespace asio = boost::asio;
 8 #define PRINT_ARGS(msg) do {\
...
13
14 int main() {
15   std::srand(std::time(0));
16   asio::io_service service;
17   asio::io_service::strand strand(service);
18   boost::mutex mtx;
19   size_t regular = 0, on_strand = 0;
20 
21  auto workFuncStrand = [&mtx, &on_strand] {
22           ++ on_strand;
23           PRINT_ARGS(on_strand << ". Hello, from strand!");
24           boost::this_thread::sleep(
25                       boost::posix_time::seconds(2));
26         };
27
28   auto workFunc = [&mtx, &regular] {
29                   PRINT_ARGS(++ regular << ". Hello, world!");
30                   boost::this_thread::sleep(
31                         boost::posix_time::seconds(2));
32                 };
33   // Post work
34   for (int i = 0; i < 15; ++ i) {
35     if (rand() % 2 == 0) {
36       service.post(strand.wrap(workFuncStrand));
37     } else {
38       service.post(workFunc);
39     }
40   }
41
42   // set up the worker threads in a thread group
43   boost::thread_group workers;
44   for (int i = 0; i < 3; ++ i) {
45     workers.create_thread([&service, &mtx]() {
46                        PRINT_ARGS("Starting worker thread ");
47                       service.run();
48                        PRINT_ARGS("Worker thread done");
49                     });
50   }
51
52   workers.join_all(); // wait for all worker threads to finish
53 }
```

在本例中，我们创建了两个处理函数：`workFuncStrand`(第 21 行)和`workFunc`(第 28 行)。 λ`workFuncStrand`捕获计数器`on_strand`，使其递增，并打印带有计数器的值前缀的消息`Hello, from strand!`。 函数`workFunc`捕获另一个计数器`regular`，使其递增，然后打印`Hello, World!`，并以计数器为前缀。 两人在返回之前都暂停了 2 秒钟。

要定义和使用链，我们首先创建一个与`io_service`实例相关联的对象`io_service::strand`(第 17 行)。 此后，我们通过使用`strand`的`wrap`成员函数包装所有处理程序来发布我们希望成为该链一部分的所有处理程序(第 36 行)。 或者，我们也可以使用 STRAN 的`post`或`dispatch`成员函数将处理程序直接发布到 STRAN，如以下代码片断所示：

```
33   for (int i = 0; i < 15; ++ i) {
34     if (rand() % 2 == 0) {
35       strand.post(workFuncStrand);
37     } else {
...
```

Strand 的`wrap`成员函数返回一个函数对象，该对象反过来调用 strand 上的`dispatch`以调用原始处理程序。 最初，添加到队列的是这个函数对象，而不是我们原来的处理程序。 当适当调度时，它将调用原始处理程序。 对这些包装处理程序的调度顺序没有限制，因此，调用原始处理程序的实际顺序可能与包装和发布它们的顺序不同。

另一方面，直接在链上调用`post`或`dispatch`可以避免中间处理程序。 直接投递到链还保证处理程序将按照它们被投递的相同顺序被调度，从而实现链中处理程序的确定性排序。 `strand`的`dispatch`成员阻塞，直到调度处理程序。 `post`成员简单地将其添加到链上并返回。

请注意，`workFuncStrand`在没有同步的情况下递增`on_strand`(第 22 行)，而`workFunc`在`PRINT_ARGS`宏内递增计数器`regular`(第 29 行)，这确保递增发生在临界区。 `workFuncStrand`处理程序被发送到链上，因此可以保证序列化；因此不需要显式同步。 另一方面，整个函数通过串进行序列化，同步较小的代码块是不可能的。 在 STRAND 上运行的处理程序和其他处理程序之间没有序列化；因此，对全局对象(如`std::cout`)的访问仍然必须同步。

以下是运行上述代码的示例输出：

```
[b73b6b40] Starting worker thread 
[b73b6b40] 0\. Hello, world from strand!
[b6bb5b40] Starting worker thread 
[b6bb5b40] 1\. Hello, world!
[b63b4b40] Starting worker thread 
[b63b4b40] 2\. Hello, world!
[b73b6b40] 3\. Hello, world from strand!
[b6bb5b40] 5\. Hello, world!
[b63b4b40] 6\. Hello, world!
…
[b6bb5b40] 14\. Hello, world!
[b63b4b40] 4\. Hello, world from strand!
[b63b4b40] 8\. Hello, world from strand!
[b63b4b40] 10\. Hello, world from strand!
[b63b4b40] 13\. Hello, world from strand!
[b6bb5b40] Worker thread done
[b73b6b40] Worker thread done
[b63b4b40] Worker thread done
```

池中有三个不同的线程，这三个线程中的两个获取了来自链的处理程序：最初，通过线程 ID`b73b6b40`，然后通过线程 ID`b63b4b40`。 这也消除了一种常见的误解，即一个链中的所有处理程序都是由同一线程调度的，但事实显然并非如此。

### 提示

同一串中的不同处理程序可以由不同的线程调度，但永远不会同时运行。

# 使用 ASIO 的网络 I/O

我们希望使用 ASIO 来构建通过网络执行 I/O 的可扩展网络服务。 此类服务从远程机器上运行的客户端接收请求，并通过网络向它们发送信息。 跨越机器边界的进程之间的数据传输是通过网络通信的特定协议来完成的。 这些协议中最普遍的是 IP 或**Internet 协议**以及在其之上的一套**协议**。 Boost ASIO 支持 IP 协议簇中的三种常用协议：TCP、UDP 和 ICMP。 我们在本书中不涉及 ICMP。

## UDP 和 TCP

**用户数据报协议**或UDP用于通过 IP 网络将**个数据报**或消息单元从一台主机传输到另一台主机。 UDP 是基于 IP 构建的非常基本的协议，在跨多个网络 I/O 操作不维护上下文的意义上是无状态的。 使用 UDP 传输数据的可靠性取决于底层网络的可靠性，UDP 传输有以下警告：

*   UDP 数据报可能根本不会被传送
*   给定的数据报可以多次传送
*   两个数据报可能不会按照从源发送的顺序传送到目标
*   UDP 将检测数据报中的任何数据损坏，并在没有任何恢复手段的情况下丢弃此类消息

因此，UDP 被认为是不可靠的协议。

如果应用程序需要协议提供更强的保证，我们可以选择**传输控制协议**或 TCP。 TCP根据字节流而不是消息进行处理。 它使用网络通信的两个端点之间的握手机制在两个点之间建立持久的**连接**，并在连接的生命周期内保持状态。 两个端点之间的所有通信都通过这样的连接进行。 以比 UDP 稍高的延迟为代价，TCP 可以保证以下几点：

*   在给定的连接上，接收应用程序按发送顺序接收发送方发送的字节流
*   线路上任何丢失或损坏的数据都可以重新传输，从而极大地提高了传输的可靠性

能够自行处理不可靠和数据丢失的实时应用程序通常使用 UDP。 此外，许多更高级别的协议都运行在 UDP 之上。 TCP 的使用频率更高，其正确性比实时性能更重要，例如，电子邮件和文件传输协议、HTTP 等。

## IP 地址

IP 地址是用于唯一地标识连接到 IP 网络的接口的数字标识符。 较旧的 IPv4 协议使用 40 亿(2<sup>32</sup>)个地址空间中的 32 位 IP 地址。 新兴的 IPv6 协议在 3.4×10<sup>38</sup>(2<sup>128</sup>)个唯一地址的地址空间中使用 128 比特的 IP 地址，这几乎是取之不尽的。 您可以使用类`boost::asio::ip::address`表示这两种类型的 IP 地址，而特定于版本的地址可以使用`boost::asio::ip::address_v4`和`boost::asio::ip::address_v6`表示。

### IPv4 地址

熟悉的IPv4 地址(如 212.54.84.93)是 32 位无符号整数，用*点分四元组表示*；四个 8 位无符号整数或*八位字节*表示地址中的四个字节，从左边的最高有效位到右边的最低有效位，用点(句号)分隔。 每个二进制八位数的范围从 0 到 255。 IP 地址通常以网络字节顺序(即大端顺序)进行解释。

#### 子网

较大的计算机网络通常被划分为称为**子网**的逻辑部分。 子网由一组可以使用广播消息相互通信的节点组成。 子网有一个关联的 IP 地址池，它们有一个共同的前缀，通常称为*路由前缀*或*网络地址*。 IP 地址字段的其余部分称为*主机部分*。

给定 IP 地址*和前缀长度*，我们可以使用**网络掩码**计算前缀。 子网的网络掩码是一个 4 字节位掩码，其按位 AND 与子网中的 IP 地址一起产生路由前缀。 对于路由前缀长度为 N 的子网，网络掩码设置了最高有效的 N 位，其余 32-N 位未设置。 网络掩码通常用点分四元符号表示。 例如，如果地址 172.31.198.12 的路由前缀为 16 位，则其网络掩码为 255.255.0.0，路由前缀为 172.31.0.0。

通常，必须明确指定路由前缀的长度。 **无类域间路由**(**CIDR)表示法**使用尾部斜杠和表示前缀长度的 0 到 32 之间的数字来扩充点分四元表示法。 因此，10.209.72.221/22 表示前缀长度为 22 的 IP 地址。 一种较旧的分类方案称为*有类方案*，它将 IPv4 地址空间划分为多个范围，并为每个范围分配一个*类*(请参见下表)。 属于每个范围的地址被认为属于相应的类别，并且路由前缀的长度是根据类别确定的，而没有使用 CIDR 表示法指定。

<colgroup><col style="text-align: left"> <col style="text-align: left"> <col style="text-align: left"> <col style="text-align: left"> <col style="text-align: left"></colgroup> 
| 

等级 / 种类 / 社会等级 / 班级

 | 

地址范围

 | 

前缀长度

 | 

网络掩码

 | 

备注

 |
| --- | --- | --- | --- | --- |
| 甲类 | 0.0.0.0-127.255.255.255 | 8 个 | 255.0.0.0 |   |
| B 类 | 128.0.0.0-191.255.255.255 | 16 个 | 255.255.0.0 |   |
| C 类 | 192.0.0.0-223.255.255.255 | 24 个 | 255.255.255.0 |   |
| D 类 | 224.0.0.0-239.255.255.255 | 未指明 | 未指明 | 多播数据 |
| E 类和 E 类 | 240.0.0-255.255.255.255 | 未指明 | 未指明 | 矜持的，拘谨的 / 已被预订的 |

#### 特殊地址

某些 IPv4 地址有特殊含义。 例如，在主机部分中设置了所有位的 IP 地址称为子网的**广播地址**，用于向子网中的所有主机广播消息。 例如，网络 172.31.0.0/16 中的广播地址为 172.31.255.255。

侦听传入请求的应用程序使用**未指定地址**0.0.0.0(`INADDR_ANY`)侦听所有可用的网络接口，而无需知道系统上检测到的地址。

**环回地址**127.0.0.1 通常与虚拟网络接口相关联，该虚拟网络接口不与任何硬件相关联，并且不需要主机连接到网络。 通过环回接口发送的数据会立即显示为发送方主机本身的接收数据。 通常用于测试机箱内的网络应用程序，您可以配置其他环回接口并关联范围从 127.0.0.0 到 127.255.255.255 的环回地址。

#### 使用 Boost 处理 IPv4 地址

现在让我们看一个构建 IPv4 地址的代码示例，并使用类型`boost::asio::ip::address_v4`从这些地址中收集有用信息：

**清单 11.6：处理 IPv4 地址**

```
 1 #include <boost/asio.hpp>
 2 #include <iostream>
 3 #include <cassert>
 4 #include <vector>
 5 namespace asio = boost::asio;
 6 namespace sys = boost::system;
 7 using namespace asio::ip;
 8
 9 void printAddrProperties(const address& addr) {
10   std::cout << "\n\n" << addr << ": ";
11
12   if (addr.is_v4()) {
13     std::cout << "netmask=" << address_v4::netmask(addr.to_v4());
14   } else if (addr.is_v6()) { /* ... */ }
15
16   if (addr.is_unspecified()) { std::cout << "is unspecified, "; }
17   if (addr.is_loopback()) { std::cout << "is loopback, "; }
18   if (addr.is_multicast()) { std::cout << "is multicast, "; }
19 }
20
21 int main() {
22   sys::error_code ec;
23   std::vector<address> addresses;
24   std::vector<const char*> addr_strings{"127.0.0.1", 
25            "10.28.25.62", "137.2.33.19", "223.21.201.30",
26            "232.28.25.62", "140.28.25.62/22"};
27
28   addresses.push_back(address_v4());       // default: 0.0.0.0
29   addresses.push_back(address_v4::any());  // INADDR_ANY
30
31   for (const auto& v4str : addr_strings) {
32     address_v4 addr = address_v4::from_string(v4str, ec);
33     if (!ec) {
34       addresses.push_back(addr);
35     }
36   }
37
38   for (const address& addr1: addresses) {
39     printAddrProperties(addr1);
40   }
41 }
```

本例重点介绍了对 IPv4 地址的一些基本操作。 我们创建一个由`boost::asio::ip::address`对象(不仅仅是`address_v4`)组成的向量，并使用`address_v4::from_string`静态函数推送从它们的字符串表示构造的 IPv4 地址(第 32 行)。 我们使用`from_string`的双参数重载(获取地址字符串)和非常数引用(如果无法解析地址字符串，则设置为对`error_code`对象的非常数引用)。 存在一个只有一个参数的重载，如果有错误就会抛出。 请注意，您可以隐式将`address_v4`实例转换或分配给`address`实例。 `address_v4`的默认构造实例等效于未指定的地址 0.0.0.0(第 28 行)，该地址也由`address_v4::any()`返回(第 29 行)。

为了打印地址的属性，我们编写了`printAddrProperties`函数(第 9 行)。 我们通过将 IP 地址流式传输到`std::cout`来打印 IP 地址(第 10 行)。 我们使用`is_v4`和`is_v6`成员函数检查地址是 IPv4 还是 IPv6 地址(第 12、14 行)，使用`address_v4::netmask`静态函数打印 IPv4 地址的网络掩码(第 13 行)，还使用适当的成员谓词检查地址是否是未指定的地址、环回地址或 IPv4 多播地址(D 类)(第 16-18 行)。 请注意，`address_v4::from_string`函数不能识别 CIDR 格式(从 Boost 版本 1.57 开始)，网络掩码是根据有类方案计算的。

在下一节中，在简要概述 IPv6 地址之后，我们将增加`printAddrProperties`(第 14 行)函数以打印 IPv6 特定属性。

### IPv6 地址

在其最常用的形式中，IPv6 地址表示为八个 2 字节无符号十六进制整数的序列，用冒号分隔。 按照惯例，十六进制整数中的数字`a`到`f`以小写形式写入，每个 16 位数字中的前导零被省略。 以下是此表示法中的 IPv6 地址示例：

2001：0c2f：003a：01e0：0000：0000：0000：002a

一个包含两个或多个零项的序列可以完全折叠。 因此，前面的地址可以写为 2001：C2F：3A：1E0：：2A。 所有前导零都已删除，字节 16 和 63 之间的连续零项已折叠，只剩下冒号对(：：)。 如果有多个零项序列，则最长的序列被折叠，如果存在平局，则最左边的序列被折叠。 因此，我们可以将 2001：0000：0000：01e0：0000：0000：001A：002a 缩写为 2001：：1e0：0：0：1A：2A。 请注意，最左边的两个零项序列是折叠的，而位 32 和 63 之间的另一个序列不折叠。

在从 IPv4 过渡到 IPv6 的环境中，软件通常同时支持 IPv4 和 IPv6。 *IPv4 映射的 IPv6 地址*用于实现 IPv6 和 IPv4 接口之间的通信。 IPv4 地址映射到前缀为：：ffff：0：0/96 且最后 32 位与 IPv4 地址相同的 IPv6 地址。 例如，172.31.201.43 将表示为：：ffff：172.31.201.43/96。

#### 地址类、作用域和子网

有三类 IPv6 地址：

*   **单播地址**：这些地址标识单个网络接口
*   **组播地址**：这些地址标识一组网络接口，并用于向该组中的所有接口发送数据
*   **任播地址**：这些地址标识一组网络接口，但是发送到**任播**地址的数据被传送到在拓扑上最接近发送方的一个或多个接口，而不是该组中的所有接口

在单播和任播地址中，地址的最低有效 64 位代表主机 ID。通常，较高的 64 位代表网络前缀。

每个 IPv6 地址还具有**作用域**，该作用域标识其有效的网段：

*   **节点本地**地址(包括环回地址)用于节点内的通信。
*   **全局**地址是可跨网络到达的可路由地址。
*   **本地链路地址**地址会自动分配给每个启用 IPv6 的接口，并且只能在网络内访问，也就是说，路由器不会路由流向本地链路地址的流量。 即使接口具有可路由地址，也会将本地链路地址分配给接口。 本地链路地址的前缀为 fe80：：/64。

#### 特殊地址

类似于 IPv4 中的 127.0.0.1 的IPv6**环回地址**为：：1.IPv6 中的**未指定地址**(全零)写为：：(`in6addr_any`)。 IPv6 中没有广播地址，组播地址用于定义接收方接口组，这不在本书的讨论范围内。

#### 使用 Boost 处理 IPv6 地址

在下面的示例中，我们构造 IPv6 地址并使用`boost::asio::ip::address_v6`类查询这些地址的属性：

**清单 11.7：处理 IPv6 地址**

```
 1 #include <boost/asio.hpp>
 2 #include <iostream>
 3 #include <vector>
 4 namespace asio = boost::asio;
 5 namespace sys = boost::system;
 6 using namespace asio::ip;
 7
 8 void printAddr6Properties(const address_v6& addr) {
 9   if (addr.is_v4_mapped()) { std::cout << "is v4-mapped, "; }
10   else {  
11     if (addr.is_link_local()) { std::cout << "is link local";}
12   }  
13 }
14
15 void printAddrProperties(const address& addr) { ... }
16
17 int main() {
18   sys::error_code ec;
19   std::vector<address> addresses;
20   std::vector<const char*> addr_strings{"::1", "::",
21     "fe80::20", "::ffff:223.18.221.9", "2001::1e0:0:0:1a:2a"};
22
23   for (const auto& v6str: addr_strings) {
24     address addr = address_v6::from_string(v6str, ec);
25     if (!ec) { addresses.push_back(addr); }
26   }
27
28   for (const auto& addr : addresses) {
29     printAddrProperties(addr);
30   }
31 }
```

这个示例使用特定于 IPv6 的检查增强了清单 11.6。 函数`printAddrProperties`(第 15 行)与清单 11.6 中的函数相同，因此不会完整重复。 `printAddr6Properties`函数(第 8 行)检查地址是否为 IPv4 映射的 IPv6 地址(第 9 行)以及是否为本地链路地址(第 11 行)。 其他相关检查已经通过`printAddrProperties`中与版本无关的`address`成员执行(请参见清单 11.6)。

我们创建了一个由`boost::asio::ip::address`对象(不仅仅是`address_v6`)组成的向量，并使用`address_v6::from_string`静态函数(第 24 行)推送从它们的字符串表示构造的 IPv6 地址(第 24 行)，该函数返回`address_v6`对象，这些对象可以隐式转换为`address`。 请注意，我们有环回地址、未指定地址、IPv4 映射地址、常规 IPv6 单播地址和本地链路地址(第 20-21 行)。

## 端点、套接字和名称解析

应用程序**在提供网络服务时将**绑定到 IP 地址，并且多个应用程序从 IP 地址开始发起与其他应用程序的出站通信。 多个应用程序可以使用不同的**端口**绑定到同一 IP 地址。 端口是一个无符号 16 位整数，它与 IP 地址和协议(TCP、UDP 等)一起唯一标识通信**端点**。 数据通信在两个这样的端点之间进行。 Boost ASIO 为 UDP 和 TCP 提供不同的端点类型，即`boost::asio::ip::udp::endpoint`和`boost::asio::ip::tcp::endpoint`。

### 端口

许多标准和广泛使用的网络服务使用固定的、众所周知的端口。 端口 0 到 1023 被分配给众所周知的系统服务，包括 FTP、SSH、Telnet、SMTP、DNS、HTTP 和 HTTPS。 广泛使用的应用程序可能会向**互联网编号分配机构**(**IANA**)注册 1024 到 49151 之间的标准端口。 49151 以上的端口可由任何应用程序使用，无需注册。 知名端口到服务的映射通常保存在磁盘文件中，例如 POSIX 系统上的`/etc/services`和 Windows 上的`%SYSTEMROOT%\system32\drivers\etc\services`。

### 插座

**套接字**表示用于网络通信的端点。 它代表通信通道的一端，并提供执行所有数据通信的接口。 Boost ASIO 为 UDP 和 TCP 提供了截然不同的套接字类型，即`boost::asio::ip::udp::socket`和`boost::asio::ip::tcp::socket`。 套接字始终与相应的本地端点对象相关联。 所有现代操作系统上的本机网络编程接口都使用 Berkeley Sockets API 的某些派生接口，后者是一种用于执行网络通信的 C API。 Boost ASIO 库提供围绕此核心 API 构建的类型安全抽象。

套接字是**I/O 对象**的一个示例。 在 ASIO 中，I/O 对象是用于启动 I/O 操作的对象类。 操作由**I/O 服务**对象分派到底层操作系统，该对象是`boost::asio::io_service`的实例。 在本章的前面部分，我们了解了 I/O 服务对象作为任务管理器的作用。 但它们的主要角色是作为底层操作系统上操作的接口。 每个 I/O 对象由关联的 I/O 服务实例构成。 这样，在 I/O 对象上启动高级 I/O 操作，但 I/O 对象和 I/O 服务之间的交互保持封装。 在接下来的几节中，我们将看到使用 UDP 和 TCP 套接字进行网络通信的示例。

### 主机名和域名

通过名称而不是数字地址来识别网络中的主机通常更方便。 域名系统(DNS)提供了一种分层命名系统，其中网络中的每个主机都由一个主机名来标识，该主机名由标识网络的唯一名称限定，称为**完全限定域名**或简称为**域名**。 例如，虚构的域名`elan.taliesyn.org`可以映射到 IP 地址 140.82.168.29。 这里，`elan`将标识特定主机，`taliesyn.org`将标识该主机所属的域。 单个网络中的不同计算机组很可能向不同的域报告，甚至一台给定的计算机也可能是多个域的一部分。

#### 名称解析

世界各地和专用网络内的 DNS 服务器的层次结构维护名称到地址的映射。 应用程序要求配置的 DNS 服务器将完全限定的域名解析为地址。 DNS 服务器要么将请求解析为 IP 地址，要么将其转发到层次结构中级别更高的另一个 DNS 服务器(如果有)。 如果所有 DNS 服务器(一直到层次结构的根)都没有答案，则解析失败。 发起此类名称解析请求的专用程序或库称为**解析器**。 Boost ASIO 提供特定于协议的解析器：`boost::asio::ip::tcp::resolver`和`boost::asio::ip::udp::resolver`，用于执行此类名称解析。 我们在主机名上查询服务，并获得该服务的一个或多个端点。 以下示例显示了如何在给定主机名和服务名或端口(可选)的情况下执行此操作：

**清单 11.8：查找主机**的 IP 地址

```
 1 #include <boost/asio.hpp>
 2 #include <iostream>
 3 namespace asio = boost::asio;
 4
 5 int main(int argc, char *argv[]) {
 6   if (argc < 2) {
 7     std::cout << "Usage: " << argv[0] << " host [service]\n";
 8     exit(1);
 9   }
10   const char *host = argv[1];
11   const char *svc = (argc > 2) ? argv[2] : "";
12
13   try {
14     asio::io_service service;
15     asio::ip::tcp::resolver resolver(service);
16     asio::ip::tcp::resolver::query query(host, svc);
17     asio::ip::tcp::resolver::iterator end,
18                             iter = resolver.resolve(query);
19     while (iter != end) {
20       asio::ip::tcp::endpoint endpoint = iter->endpoint();
21       std::cout << "Address: " << endpoint.address()
22                 << ", Port: " << endpoint.port() << '\n';
23       ++ iter;
24     }
25   } catch (std::exception& e) {
26     std::cout << e.what() << '\n';
27   }
28 }
```

您可以在命令行上向该程序传递一个主机名和一个可选的服务名，从而运行该程序。 该程序将它们解析为 IP 地址和端口，并将它们打印到标准输出(第 21-22 行)。 该程序创建一个`io_service`的实例(第 14 行)，它将成为底层操作系统上操作的管道，并创建一个`boost::asio::ip::tcp::resolver`的实例(第 15 行)，它为请求名称解析提供接口。 我们根据主机名和服务名创建名称查找请求，封装在`query`对象中(第 16 行)，并调用`resolver`的`resolve`成员函数，将`query`对象作为参数传递(第 18 行)。 函数的作用是：向查询解析的一系列`endpoint`对象返回一个**端点迭代器**。 我们遍历此序列，打印每个端点的地址和端口号。 这将打印 IPv4 和 IPv6 地址(如果有的话)。 如果我们需要特定于某个 IP 版本的 IP 地址，则需要使用`query`的三参数构造函数，并在第一个参数中指定协议。 例如，要仅查找 IPv6 地址，我们可以使用以下命令：

```
asio::ip::tcp::resolver::query query(asio::ip::tcp::v6(), 
 host, svc);

```

查找失败时，`resolve`函数抛出异常，除非我们使用接受非常数引用`error_code`的双参数版本作为第二个参数，并在出错时设置它。 在下面的示例中，我们执行反向查找。 在给定 IP 地址和端口的情况下，我们查找关联的主机名和服务名：

**清单 11.9：查找主机和服务名**

```
 1 #include <boost/asio.hpp>
 2 #include <iostream>
 3 namespace asio = boost::asio;
 4
 5 int main(int argc, char *argv[]) {
 6   if (argc < 2) {
 7     std::cout << "Usage: " << argv[0] << " ip [port]\n";
 8     exit(1);
 9   }
10
11   const char *addr = argv[1];
12   unsigned short port = (argc > 2) ? atoi(argv[2]) : 0;
13
14   try {
15     asio::io_service service;
16     asio::ip::tcp::endpoint ep(
17               asio::ip::address::from_string(addr), port);
18     asio::ip::tcp::resolver resolver(service);
19     asio::ip::tcp::resolver::iterator iter = 
20                              resolver.resolve(ep), end;
21     while (iter != end) {
22       std::cout << iter->host_name() << " "
23                 << iter->service_name() << '\n';
24       iter++ ;
25     }
26   } catch (std::exception& ex) {
27     std::cerr << ex.what() << '\n';
28   }
29 }
```

我们从命令行将 IP地址和端口号传递给程序，并使用它们构造`endpoint`(第 16-17 行)。 然后，我们将`endpoint`传递给`resolver`的`resolve`成员函数(第 19 行)，并迭代结果。 本例中的迭代器指向`boost::asio::ip::tcp::query`个对象，我们使用适当的成员函数打印每个对象的主机名和服务名(第 22-23 行)。

## 缓冲区

数据作为字节流在网络上发送或接收。 连续字节流可以用一对值来表示：序列的起始地址和序列中的字节数。 Boost ASIO 为这样的序列提供了两个抽象：`boost::asio::const_buffer`和`boost::asio::mutable_buffer`。 `const_buffer`类型表示在网络上发送数据时通常用作数据源的只读序列。 `mutable_buffer`表示需要在缓冲区中添加或更新数据时使用的读写序列，例如，当您从远程主机接收数据时：

**清单 11.10：使用 CONST_BUFFER 和 MUTABLE_BUFFER**

```
 1 #include <boost/asio.hpp>
 2 #include <iostream>
 3 #include <cassert>
 4 namespace asio = boost::asio;
 5
 6 int main() {
 7   char buf[10];
 8   asio::mutable_buffer mbuf(buf, sizeof(buf));
 9   asio::const_buffer cbuf(buf, 5);
10
11   std::cout << buffer_size(mbuf) << '\n';
12   std::cout << buffer_size(cbuf) << '\n';
13
14   char *mptr = asio::buffer_cast<char*>(mbuf);
15   const char *cptr = asio::buffer_cast<const char*>(cbuf);
16   assert(mptr == cptr && cptr == buf);
17   
18   size_t offset = 5;
19   asio::mutable_buffer mbuf2 = mbuf + offset;
20   assert(asio::buffer_cast<char*>(mbuf2)
21         - asio::buffer_cast<char*>(mbuf) == offset);
22   assert(buffer_size(mbuf2) == buffer_size(mbuf) - offset);
23 }
```

在本例中，我们展示了如何将字符数组包装在`mutable_buffer`和`const_buffer`中(第 8-9 行)。 在构造缓冲区时，您可以指定内存区域的起始地址和区域的长度(以字节数表示)。 `const char`数组只能包装在`const_buffer`中，而不能包装在`mutable_buffer`中。 这些缓冲区包装器*不*分配存储、管理任何堆分配的内存或执行任何数据复制。

函数`boost::asio::buffer_size`返回以字节为单位的缓冲区长度(第 11-12 行)。 这是您在构造缓冲区时传递的长度，它与缓冲区中存在的数据无关。 默认-初始化的缓冲区长度为零。

函数模板`boost::asio::buffer_cast<>`用于获取指向缓冲区底层字节数组的指针(第 14-15 行)。 请注意，如果我们尝试使用`buffer_cast`从`const_buffer`获取可变数组，则会出现编译错误：

```
asio::const_buffer cbuf(addr, length);
char *buf = asio::buffer_cast<char*>(cbuf); // fails to compile

```

最后，可以使用`operator+`创建从一个偏移量到另一个缓冲区的缓冲区(第 19 行)。 结果缓冲区的长度将比原始缓冲区的长度小偏移的长度(第 22 行)。

### 矢量化 I/O 的缓冲序列

有时，从一系列缓冲区发送数据或将接收的数据拆分到一系列缓冲区是很方便的。 每个序列调用一次网络 I/O 函数效率很低，因为这些调用最终会转换为系统调用，而且每次调用都会有开销。 另一种方法是使用网络 I/O 函数，该函数可以处理作为参数传递给它的缓冲区的**序列。 这通常称为**矢量化 I/O**或**聚集-分散 I/O**。 所有 Boost ASIO 的 I/O 函数都处理缓冲区序列，因此它们必须传递缓冲区序列，而不是单个缓冲区。 与 ASIO I/O 功能配合使用的有效缓冲区序列满足以下条件：**

*   具有返回双向迭代器的成员函数`begin`，该迭代器指向`mutable_buffer`或`const_buffer`
*   有一个成员函数`end`，它返回指向序列末尾的迭代器
*   是可复制的

要使缓冲区序列有用，它必须是`const_buffer`序列或`mutable_buffer`序列。形式上，这些要求在**ConstBufferSequence**和**MutableBufferSequence**概念中总结。 这是一组稍微简化的条件，但对于我们的目的来说已经足够了。 我们可以使用标准库容器(如`std::vector`、`std::list`等)以及 Boost 容器来生成这样的序列。 然而，由于我们经常只处理单个缓冲区，Boost 提供了`boost::asio::buffer`函数，该函数可以轻松地将单个缓冲区调整为长度为 1 的缓冲区序列。 这里有一个简短的例子来说明这些想法：

**清单 11.11：使用缓冲区**

```
 1 #include <boost/asio.hpp>
 2 #include <vector>
 3 #include <string>
 4 #include <iostream>
 5 #include <cstdlib>
 6 #include <ctime>
 7 namespace asio = boost::asio;
 8
 9 int main() {
10   std::srand(std::time(nullptr));
11
12   std::vector<char> v1(10);
13   char a2[10];
14   std::vector<asio::mutable_buffer> bufseq(2);
15
16   bufseq.push_back(asio::mutable_buffer(v1.data(), 
17                                         v1.capacity()));
18   bufseq.push_back(asio::mutable_buffer(a2, sizeof(a2)));
19
20   for (auto cur = asio::buffers_begin(bufseq),
21        end = asio::buffers_end(bufseq); cur != end; cur++) {
22     *cur = 'a' + rand() % 26;
23   }
24
25   std::cout << "Size: " << asio::buffer_size(bufseq) << '\n';
26
27   std::string s1(v1.begin(), v1.end());
28   std::string s2(a2, a2 + sizeof(a2));
29
30   std::cout << s1 << '\n' << s2 << '\n';
31 }
```

在本例中，我们创建一个可变缓冲区序列，作为两个`mutable_buffer`的`vector`(第 14 行)。 两个可变缓冲区包装了一个`char`s 的`vector`(第 16-17 行)和一个`char`s 数组(第 18 行)。 使用`buffers_begin`(第 20 行)和`buffers_end`函数(第 21 行)，我们确定缓冲区序列`bufseq`封装的整个字节范围，并对其进行迭代，将每个字节设置为随机字符(第 22 行)。 当这些写入底层向量或数组时，我们使用底层向量或数组构造字符串并打印其内容(第 27-28 行)。

## 同步和异步通信

在接下来的部分中，我们将把我们对 IP 地址、端点、套接字、缓冲区和其他ASIO基础结构的理解集中在一起，这些基础结构是我们在编写网络客户端和服务器程序时学到的。 我们的示例使用交互的**客户端-服务器模型**，其中**服务器**程序服务传入的请求，而**客户端**程序发起这样的请求。 这样的客户端被称为**主动端点**，而这样的服务器被称为**被动端点**。

客户端和服务器可以同步通信**，阻塞每个网络 I/O 操作，直到底层 OS 处理完请求，然后才进入下一步。 或者，它们可以使用**异步 I/O**，在不等待它们完成的情况下启动网络 I/O，并在完成后通知它们。 与同步情况不同，使用异步 I/O 时，如果有 I/O 操作要执行，程序不会空闲等待。 因此，随着对等点数量和数据量的增加，异步 I/O 可以更好地扩展。 我们将同时研究同步和异步通信模型。 虽然异步交互的编程模型是事件驱动的，并且更加复杂，但是使用 Boost ASIO 协程可以使其非常易于管理。 在编写 UDP 和 TCP 服务器之前，我们将查看 ASIO 截止日期计时器，以了解如何使用 ASIO 编写同步和异步逻辑。**

 **## ASIO 截止时间计时器

ASIO提供了`basic_deadline_timer`模板，使用该模板可以等待经过特定持续时间或等待绝对时间点。 专业化认证`deadline_timer`定义为：

```
typedef basic_deadline_timer<boost::posix_time::ptime> 
                                             deadline_timer;
```

它分别使用`boost::posix_time::ptime`和`boost::posix_time::time_duration`作为时间点和持续时间类型。 以下示例说明了应用程序如何使用`deadline_timer`等待经过的持续时间：

**清单 11.12：同步等待**

```
 1 #include <boost/asio.hpp>
 2 #include <boost/date_time.hpp>
 3 #include <iostream>
 4
 5 int main() {
 6   boost::asio::io_service service;
 7   boost::asio::deadline_timer timer(service);
 8
 9   long secs = 5;
10   std::cout << "Waiting for " << secs << " seconds ..." 
11             << std::flush;
12   timer.expires_from_now(boost::posix_time::seconds(secs));
13
14   timer.wait();
15 
16   std::cout << " done\n";
17 }
```

我们创建了一个对象`io_service`(第 6 行)，它充当底层操作系统上操作的管道。 我们创建一个与`io_service`相关联的`deadline_timer`的实例(第 7 行)。 我们使用`deadline_timer`的成员函数`expires_from_now`(第 12 行)指定等待的 5 秒持续时间。 然后，我们调用`wait`成员函数进行阻塞，直到持续时间过去。 请注意，我们不需要在`io_service`实例上调用`run`。 我们可以使用`expires_at`成员函数来等待特定的时间点，如下所示：

```
using namespace boost::gregorian;
using namespace boost::posix_time;

timer.expires_at(day_clock::local_day(), 
                 hours(16) + minutes(12) + seconds(58));
```

有时，程序不想阻止等待计时器开始计时，或者通常不想阻止等待它感兴趣的任何未来事件。 在此期间，它可以完成其他有价值的工作，因此因此比它阻塞等待事件时响应更快。 我们只想告诉计时器在计时器计时时通知我们，同时继续做其他工作，而不是阻塞事件。 为此，我们调用`async_wait`成员函数并将其传递给*完成处理程序*。 完成处理程序是我们使用`async_wait`注册的函数对象，一旦计时器超时就会调用它：

**清单 11.13：异步等待**

```
 1 #include <boost/asio.hpp>
 2 #include <boost/date_time.hpp>
 3 #include <iostream>
 4
 5 void on_timer_expiry(const boost::system::error_code& ec)
 6 {
 7   if (ec) {
 8     std::cout << "Error occurred while waiting\n";
 9   } else {
10     std::cout << "Timer expired\n";
11   }
12 }
13
14 int main()
15 {
16   boost::asio::io_service service;
17   boost::asio::deadline_timer timer(service);
18
19
20   long secs = 5;
21   timer.expires_from_now(boost::posix_time::seconds(secs));
22
23   std::cout << "Before calling deadline_timer::async_wait\n";
24   timer.async_wait(on_timer_expiry);
25   std::cout << "After calling deadline_timer::async_wait\n";
26
27   service.run();
28 }
```

与清单 11.12 相比，清单 11.13 有两个本质上的变化。 我们调用`deadline_timer`而不是`wait`的`async_wait`成员函数，并向其传递一个指向完成处理函数`on_timer_expiry`的指针。 然后，我们对`io_service`对象调用`run`。 当我们运行此程序时，它会打印以下内容：

```
Before calling deadline_timer::async_wait
After calling deadline_timer::async_wait
Timer expired
```

对`async_wait`的调用不会阻塞(第 24 行)，因此会快速连续打印前两行。 在此之后，对`run`(第 27 行)的调用将阻塞，直到计时器超时，并分派计时器的完成处理程序。 除非发生错误，否则完成处理程序会打印`Timer expired`。 因此，在出现前两条消息和来自完成处理程序的第三条消息之间存在时间延迟。

## 使用 ASIO 协程的异步逻辑

`deadline_timer`的`async_wait`成员函数启动异步操作。 这样的函数在其启动的操作完成之前返回。 它注册一个完成处理程序，并通过调用该处理程序将异步事件的完成通知给程序。 如果我们必须按顺序运行这样的异步操作，控制流就会变得复杂。 例如，假设我们想要等待 5 秒，打印`Hello`，然后再等待 10 秒，最后打印`world`。 使用 Synchronous`wait`非常简单，如以下代码片段所示：

```
boost::asio::deadline_timer timer;
timer.expires_from_now(boost::posix_time::seconds(5));
timer.wait();
std::cout << "Hello, ";
timer.expires_from_now(boost::posix_time::seconds(10));
timer.wait();
std::cout << "world!\n";
```

在许多现实场景中，尤其是在网络 I/O 的情况下，阻塞同步操作不是一种选择。 在这种情况下，代码变得相当复杂。 下面的示例使用`async_wait`作为异步操作的模型，说明了异步代码的复杂性：

**清单 11.14：异步操作**

```
 1 #include <boost/asio.hpp>
 2 #include <boost/bind.hpp>
 3 #include <boost/date_time.hpp>
 4 #include <iostream>
 5
 6 void print_world(const boost::system::error_code& ec) {
 7   std::cout << "world!\n";
 8 }
 9
10 void print_hello(boost::asio::deadline_timer& timer,
11                  const boost::system::error_code& ec) {
12   std::cout << "Hello, " << std::flush;
13
14   timer.expires_from_now(boost::posix_time::seconds(10));
15   timer.async_wait(print_world);
16 }
17
18 int main()
19 {
20   boost::asio::io_service service;
21   boost::asio::deadline_timer timer(service);
22   timer.expires_from_now(boost::posix_time::seconds(5));
23
24   timer.async_wait(boost::bind(print_hello, boost::ref(timer),
25                                            ::_1));
26
27   service.run();
28 }
```

对于相同的功能，将从同步逻辑转移到异步逻辑需要两倍以上的代码行和复杂的控制流。 我们将函数`print_hello`(第 10 行)注册为第一个 5 秒等待的完成处理程序(第 22、24 行)。 `print_hello`接着使用相同的计时器开始 10 秒的等待，并将函数`print_world`(第 6 行)注册为该等待的完成处理程序(第 14-15 行)。

注意，我们使用`boost::bind`生成第一个 5 秒等待的完成处理程序，将`timer`从`main`函数传递给`print_hello`函数。 因此，`print_hello`函数使用相同的定时器。 我们为什么要这样做呢？ 首先，`print_hello`需要使用相同的`io_service`实例来启动 10 秒等待操作和前 5 秒等待操作。 `timer`实例引用此`io_service`实例，并由两个完成处理程序使用。 此外，在`print_hello`中创建本地`deadline_timer`实例将是有问题的，因为`print_hello`将在计时器开始计时之前返回，并且本地计时器对象将被销毁，因此它永远不会停止。

示例 11.14 说明了控制流的*反转问题，这是异步编程模型中非常复杂的一个来源。 我们不能再将一系列语句串在一起，并假设每个语句只在前一条语句启动的操作完成后才启动操作-这对于同步模型来说是一个安全的假设。 相反，我们依靠来自`io_service`的通知来确定运行下一个操作的正确时间。 逻辑在各个功能之间是零散的，需要跨这些功能共享的任何数据都需要更多的管理工作。*

ASIO 使用 Boost Cooutine 库的薄包装器简化了异步编程。 与 Boost 协程一样，可以使用堆栈和非堆栈协程。 在这本书中，我们只看堆叠的协程。

使用`boost::asio::spawn`函数模板，我们可以将任务作为协程启动。 如果调度协同例程并调用异步函数，则该协同例程将被挂起。 同时，`io_service`调度其他任务，包括其他协程。 一旦异步操作完成，启动该操作的协同例程将恢复，并继续执行下一步。 在下面的清单中，我们使用协程重写清单 11.14：

**清单 11.15：使用协程**进行异步编程

```
 1 #include <boost/asio.hpp>
 2 #include <boost/asio/spawn.hpp>
 3 #include <boost/bind.hpp>
 4 #include <boost/date_time.hpp>
 5 #include <iostream>
 6
 7 void wait_and_print(boost::asio::yield_context yield,
 8                     boost::asio::io_service& service)
 9 {
10   boost::asio::deadline_timer timer(service);
11
12   timer.expires_from_now(boost::posix_time::seconds(5));
13   timer.async_wait(yield);
14   std::cout << "Hello, " << std::flush;
15 
16   timer.expires_from_now(boost::posix_time::seconds(10));
17   timer.async_wait(yield);
18   std::cout << "world!\n";
19 }
20
21 int main()
22 {
23   boost::asio::io_service service;
24   boost::asio::spawn(service,
25           boost::bind(wait_and_print, ::_1, 
26                                       boost::ref(service)));
27   service.run();
28 }
```

`wait_and_print`函数是协例程，它有两个参数：类型为`boost::asio::yield_context`的对象和对`io_service`实例的引用(第 7 行)。 `yield_context`是 Boost Coroutine 的一种薄薄的包装。 我们必须使用`boost::asio::spawn`来调度协程，并且这样的协程必须有签名`void (boost::asio::yield_context)`。 因此，我们使用`boost::bind`调整`wait_and_print`函数，使其与`spawn`期望的协程签名兼容。 我们将第二个参数绑定到对`io_service`实例的引用(第 24-26 行)。

`wait_and_print`协程在堆栈上创建一个`deadline_timer`实例，并启动一个 5 秒的异步等待，将其`yield_context`传递给`async_wait`函数以代替完成处理程序。 这会暂停`wait_and_print`协同例程，并且只有在等待完成后才会恢复。 同时，可以从`io_service`队列处理其他任务(如果有的话)。 一旦等待结束并恢复`wait_and_print`，它将打印`Hello`并开始 10 秒的等待。 协程再次暂停，仅在 10 秒后恢复，然后打印`world`。 协程使异步逻辑与同步逻辑一样简单和可读，开销非常小。 在接下来的几节中，我们将使用协程来编写 TCP 和 UDP 服务器。

## UDP

UDP I/O 模型相对简单，客户端和服务器之间的区别很模糊。 对于使用 UDP 的网络 I/O，我们创建 UDP 套接字，并使用`send_to`和`receive_from`函数将数据报发送到特定端点。

### 同步 UDP 客户端和服务器

在本节中，我们编写一个 UDP 客户端(清单 11.16)和一个同步 UDP 服务器(清单 11.17)。 UDP 客户端尝试向给定端点上的 UDP 服务器发送一些数据。 UDP 服务器阻止等待接收来自个或多个 UDP 客户端的数据。 发送数据后，UDP 客户端阻止等待从服务器接收响应。 服务器在收到数据后，在继续处理更多传入消息之前发回一些响应。

**清单 11.16：同步 UDP 客户端**

```
 1 #include <boost/asio.hpp>
 2 #include <iostream>
 3 #include <exception>
 4 namespace asio = boost::asio;
 5
 6 int main(int argc, char *argv[]) {
 7   if (argc < 3) {
 8     std::cerr << "Usage: " << argv[0] << " host port\n";
 9     return 1;
10   }
11
12   asio::io_service service;
13   try {
14     asio::ip::udp::resolver::query query(asio::ip::udp::v4(),
15                                        argv[1], argv[2]);
16     asio::ip::udp::resolver resolver(service);
17     auto iter = resolver.resolve(query);
18     asio::ip::udp::endpoint endpoint = iter->endpoint();
19   
20     asio::ip::udp::socket socket(service, 
21                                  asio::ip::udp::v4());
22     const char *msg = "Hello from client";
23     socket.send_to(asio::buffer(msg, strlen(msg)), endpoint);
24     char buffer[256];
25     size_t recvd = socket.receive_from(asio::buffer(buffer,
26                                  sizeof(buffer)), endpoint);
27     buffer[recvd] = 0;
28     std::cout << "Received " << buffer << " from " 
29        << endpoint.address() << ':' << endpoint.port() << '\n';
30   } catch (std::exception& e) {
31     std::cerr << e.what() << '\n';
32   }
33 }
```

我们通过在命令行上向客户端传递服务器主机名和要连接的服务(或端口)来运行客户端。 它将它们解析为 UDP 的端点(IP 地址和端口号)(第 13-17 行)，为 IPv4 创建一个 UDP 套接字(第 18 行)，并对其调用`send_to`成员函数。 我们传递给`send_to`，包含要发送的数据和目的地端点的 a`const_buffer`(第 23 行)。

使用 ASIO 执行网络 I/O 的每个程序都使用*I/O 服务*，它是类型`boost::asio::io_service`的实例。 我们已经看到`io_service`作为任务管理器发挥作用。 但是 I/O 服务的主要角色是底层操作系统上操作的接口。 ASIO 程序使用负责启动 I/O 操作的*I/O 对象*。 例如，套接字就是 I/O 对象。

我们调用 UDP 套接字上的`send_to`成员函数向服务器发送预定义的消息字符串(第 23 行)。 请注意，我们将消息数组包装在一个长度为 1 的缓冲区序列中，该缓冲区序列是使用`boost::asio::buffer`函数构造的，如本章前面关于缓冲区的部分所示。 一旦`send_to`完成，客户端将在同一套接字上调用`recv_from`，使用`boost::asio::buffer`传递由可写字符数组构造的可变缓冲区序列(第 25-26 行)。 `receive_from`的第二个参数是对`boost::asio::ip::udp::endpoint`对象的非常数引用。 当`receive_from`返回时，该对象包含发送消息的远程端点的地址和端口号(第 28-29 行)。

对`send_to`和`receive_from`的调用是**阻塞调用**。 直到传递给它的缓冲区被写入系统中的底层 UDP 缓冲区，才会返回对`send_to`的调用。 稍后可能会通过线路将 UDP 缓冲区分派到服务器。 直到接收到一些数据后，才会返回对`receive_from`的调用。

我们可以使用单个UDP 套接字向多个其他端点发送数据，并且可以在单个套接字上接收来自多个其他端点的数据。 因此，对`send_to`的每个调用都将目的地端点作为输入。 同样，每个对`receive_from`的调用都会接受对端点的非常数引用，并在返回时将其设置为发送方的端点。 我们现在将使用 ASIO 编写相应的 UDP 服务器：

**清单 11.17：同步 UDP 服务器**

```
 1 #include <boost/asio.hpp>
 2 #include <exception>
 4 #include <iostream>
 5 namespace asio = boost::asio;
 6
 8 int main() 
 9 {
10   const unsigned short port = 55000;
11   const std::string greet("Hello, world!");
12
13   asio::io_service service;
14   asio::ip::udp::endpoint endpoint(asio::ip::udp::v4(), port);
15   asio::ip::udp::socket socket(service, endpoint);
16   asio::ip::udp::endpoint ep;
17
18   while (true) try {	
19     char msg[256];
20     auto recvd = socket.receive_from(asio::buffer(msg, 
21                                             sizeof(msg)), ep);
22     msg[recvd] = 0;
23     std::cout << "Received: [" << msg << "] from [" 
24               << ep << "]\n";
25
26     socket.send_to(asio::buffer(greet.c_str(), greet.size()),
27                    ep);
27     socket.send_to(asio::buffer(msg, strlen(msg)), ep);
28   } catch (std::exception& e) {
29     std::cout << e.what() << '\n';
30   }
31 }
```

同步 UDP 服务器在端口 55000 上创建类型为`boost::asio::ip::udp::endpoint`的单个 UDP 端点，保持地址未指定(第 14 行)。 注意，我们使用了一个双参数`endpoint`构造函数，它以*协议*和 port 作为参数。 服务器为该端点创建类型为`boost::asio::ip::udp::socket`的单个 UDP 套接字(第 15 行)，并循环旋转，在每次迭代中调用套接字上的`receive_from`，等待客户端发送一些数据。 数据在名为`msg`的`char`数组中接收，该数组被传递到`receive_from`，该数组被包装在长度为 1 的可变缓冲区序列中。 对`receive_from`的调用返回接收到的字节数，用于在`msg`中添加一个终止空字符，以便可以像使用 C 样式字符串一样使用它(第 22 行)。 通常，UDP 将传入数据表示为包含字节序列的消息，并将其解释留给应用程序。 服务器每次从客户端接收数据时，都会回显发送的数据，前面带有固定的问候语字符串。 为此，它在套接字上调用两次`send_to`成员函数，传递要发送的缓冲区和接收方的端点(第 26-27 行，28 行)。

对`send_to`和`receive_from`的调用是同步的，仅当数据完全传递到操作系统(`send_to`)或完全被应用程序接收(`receive_from`)时才返回。 如果多个客户端实例同时向服务器发送消息，服务器一次仍只能处理一条消息，因此客户端会排队等待响应。 当然，如果客户端没有等待响应，它们可能都已发送消息并退出，但服务器仍会连续接收这些消息。

### 发帖主题：Re：Колибри0.7.0

UDP 服务器的异步版本可以显著提高服务器的响应性。 传统的异步模型可能需要更复杂的编程模型，但是协程可以显著改善这种情况。

#### 使用完成处理器链的异步 UDP 服务器

对于异步通信，我们使用`socket`的`async_receive_from`和`async_send_to`成员函数。 这些函数不等待操作系统处理 I/O 请求，而是立即返回。 向它们传递一个函数对象，该对象将在底层操作完成时调用。 此函数对象在`io_service`的任务队列中排队，并在操作系统上的实际操作返回时调度：

```
template <typename MutableBufSeq, typename ReadHandler>
deduced async_receive_from(
    const MutableBufSeq& buffers,
    endpoint_type& sender_ep,
 ReadHandler handler);

template <typename ConstBufSeq, typename WriteHandler>
deduced async_send_to(
    const ConstBufSeq& buffers,
    endpoint_type& sender_ep,
 WriteHandler handler);

```

传递给`async_receive_from`的读处理程序和传递给`async_send_to`的写处理程序的签名如下：

```
void(const boost::system::error_code&, size_t)
```

处理程序期望传递给`error_code`对象的非常数引用，指示已完成操作的状态以及读取或写入的字节数。 处理程序可以调用其他异步 I/O 操作并注册其他处理程序。 因此，整个 I/O 操作是根据处理程序链定义的。 现在我们来看一个用于异步 UDP 服务器的程序：

**清单 11.18：异步 UDP 服务器**

```
 1 #include <boost/asio.hpp>
 2 #include <iostream>
 3 namespace asio = boost::asio;
 4 namespace sys = boost::system;
 5
 6 const size_t MAXBUF = 256;
 7
 8 class UDPAsyncServer {
 9 public:
10   UDPAsyncServer(asio::io_service& service, 
11                  unsigned short port) 
12      : socket(service, 
13           asio::ip::udp::endpoint(asio::ip::udp::v4(), port))
14   {  waitForReceive();  }
15
16   void waitForReceive() {
17     socket.async_receive_from(asio::buffer(buffer, MAXBUF),
18           remote_peer,
19           [this] (const sys::error_code& ec,
20                   size_t sz) {
21             const char *msg = "hello from server";
22             std::cout << "Received: [" << buffer << "] "
23                       << remote_peer << '\n';
24             waitForReceive();
25
26             socket.async_send_to(
27                 asio::buffer(msg, strlen(msg)),
28                 remote_peer,
29                 [this](const sys::error_code& ec,
30                        size_t sz) {});
31           });
32   }
33
34 private:
35   asio::ip::udp::socket socket;
36   asio::ip::udp::endpoint remote_peer;
37   char buffer[MAXBUF];
38 };
39
40 int main() {
41   asio::io_service service;
42   UDPAsyncServer server(service, 55000);
43   service.run();
44 }
```

UDP 服务器封装在类`UDPAsyncServer`中(第 8 行)。 要启动服务器，我们首先创建必需的`io_service`对象(第 42 行)，然后创建`UDPAsyncServer`的一个实例(第 43 行)，该实例被传递给`io_service`实例及其应该使用的端口号。 最后，调用`io_service`的`run`成员函数开始处理传入的请求(第 44 行)。 那么`UDPAsyncServer`是如何运作的呢？

`UDPAsyncServer`的构造函数使用本地端点初始化成员 UDP`socket` (第 12-13 行)。 然后，它调用成员函数`waitForReceive`(第 14 行)，该函数依次调用套接字上的`async_receive_from`(第 18 行)，以开始等待任何传入的消息。 我们调用`async_receive_from,`，传递由`buffer`成员变量生成的可变缓冲区(第 17 行)、对`remote_peer`成员变量的非常数引用(第 18 行)以及定义接收操作的完成处理程序的 lambda 表达式(第 19-31 行)。 `async_receive_from`启动 I/O 操作，将处理程序添加到`io_service`中的任务队列，然后返回。 只要队列中有 I/O 任务，对`io_service`(第 43 行)上的`run`的调用就会阻塞。 当 UDP 消息出现时，操作系统接收数据，并调用处理程序采取进一步的操作。 要了解 UDP 服务器如何无休止地处理越来越多的消息，我们需要了解处理程序的作用。

当服务器接收到消息时，调用*接收处理程序*。 它打印收到的消息和远程发送者的详细信息(第 22-23 行)，然后向`waitForReceive`发出调用，从而重新启动接收操作。 然后，它将消息`hello from server`(第 21 行)发送回由`remote_peer`成员变量标识的发送方。 为此，它调用 UDP`socket`的`async_send_to`成员函数，传递消息缓冲区(第 27 行)、目的地端点(第 28 行)和另一个 lambda 形式的处理程序(第 29-32 行)，该处理程序不执行任何操作。

注意，我们捕获 lambda 中的`this`指针，以便能够访问周围作用域中的成员变量(第 20、29 行)。 此外，这两个处理程序都不使用`error_code`参数进行错误检查，这在实际软件中是必须的。

#### 使用协程的异步 UDP 服务器

处理程序跨一组处理程序链接逻辑，并在处理程序之间共享状态变得特别复杂。 这是获得更好性能的代价，但这是我们可以避免的代价，正如我们在清单 11.15 中看到的那样，在清单 11.15 中使用 ASIO 协程来处理`boost::asio::deadline_timer`上的异步等待。 现在，我们将使用 ASIO 协程来编写异步 UDP 服务器：

**清单 11.19：使用 ASIO 协程的异步 UDP 服务器**

```
 1 #include <boost/asio.hpp>
 2 #include <boost/asio/spawn.hpp>
 3 #include <boost/bind.hpp>
 4 #include <boost/shared_ptr.hpp>
 5 #include <boost/make_shared.hpp>
 6 #include <iostream>
 7 namespace asio = boost::asio;
 8 namespace sys = boost::system;
 9
10 const size_t MAXBUF = 256;
11 typedef boost::shared_ptr<asio::ip::udp::socket>
12                                   shared_udp_socket;
13
14 void udp_send_to(boost::asio::yield_context yield,
15                  shared_udp_socket socket,
16                  asio::ip::udp::endpoint peer)
17 {
18     const char *msg = "hello from server";
19     socket->async_send_to(asio::buffer(msg, std::strlen(msg)),
20                          peer, yield);
21 }
22
23 void udp_server(boost::asio::yield_context yield,
24                 asio::io_service& service,
25                 unsigned short port)
26 {
27   shared_udp_socket socket =
28       boost::make_shared<asio::ip::udp::socket>(service,
29           asio::ip::udp::endpoint(asio::ip::udp::v4(), port));
30
31   char buffer[MAXBUF];
32   asio::ip::udp::endpoint remote_peer;
33   boost::system::error_code ec;
34
35   while (true) {
36     socket->async_receive_from(asio::buffer(buffer, MAXBUF),
37                 remote_peer, yield[ec]);
38
39     if (!ec) {
40       spawn(socket->get_io_service(), 
41         boost::bind(udp_send_to, ::_1, socket,
42                                  remote_peer));
43     }
44   }
45 }
46
47 int main() {
48   asio::io_service service;
49   spawn(service, boost::bind(udp_server, ::_1,
50                      boost::ref(service), 55000));
51   service.run();                               
52 }
```

使用协同例程后，异步 UDP 服务器的结构与清单 11.18 有很大的不同，更接近清单 11.17 的同步模型。 函数`udp_server`包含 UDP 服务器的核心逻辑(第 23 行)。 它应该用作协程；因此，它的一个参数是`boost::asio::yield_context`类型(第 23 行)。 它接受两个附加参数：对`io_service`实例的引用(第 24 行)和 UDP 服务器端口(第 25 行)。

在 main 函数中，我们创建`io_service`的一个实例(第 48 行)，然后使用`boost::asio::spawn`函数模板(第 49-50 行)添加一个任务，将`udp_server`作为协程运行。 我们适当地绑定了`udp_server`的服务和端口参数。 然后，我们在`io_service`实例上调用`run`以开始处理 I/O 操作。 对`run`的调用调度`udp_server`协同例程(第 51 行)。

`udp_server`协程创建与未指定的 IPv4 地址(0.0.0.0)和作为参数传递的特定端口相关联的 UDP 套接字(第 27-29 行)。 套接字被包装在`shared_ptr`中，其原因稍后将变得清晰。 协程堆栈上还有其他变量，用于保存从客户端接收的数据(第 31 行)和标识客户端端点(第 32 行)。 然后，`udp_server`函数在调用套接字上的`async_receive_from`的循环中旋转，传递接收处理程序的`yield_context`(第 36-37 行)。 这会暂停执行`udp_server`协程，直到`async_receive_from`完成。 同时，对`run`的调用继续并处理其他任务(如果有的话)。 一旦对`async_receive_from`函数的调用完成，`udp_server`协同例程将恢复执行并继续其循环的下一次迭代。

对于每个完成的接收操作，`udp_server`都会发送一个固定的问候语字符串(“Hello from server”)来响应客户端。 发送此问候语的任务也封装在协程`udp_send_to`(第 14 行)中，`udp_server`协程使用`spawn`(第 40 行)将其添加到任务队列中。 我们将标识客户端的 UDP 套接字和端点作为参数传递给此协程。 请注意，名为`remote_peer`的局部变量按值传递给`udp_send_to`协程(第 42 行)。 它在`udp_send_to`内部用作`async_send_to`的参数，以指定响应的接收者(第 19-20 行)。 我们传递一个副本而不是对`remote_peer`的引用，因为当发出对`async_send_to`的调用时，对`async_receive_from`的另一个调用可以是活动的，并且可以在`async_send_to`使用`remote_peer`对象之前覆盖它。 我们还传递了包装在`shared_ptr`中的套接字。 与端点不同，套接字是不可复制的。 如果套接字对象位于`udp_server`函数中的自动存储中，并且`udp_server`在仍有挂起的`udp_send_to`任务时退出，则对`udp_send_to`内套接字的引用将无效，并可能导致崩溃。 因此，`shared_ptr`包装器是正确的选择。

如果您注意到了，`async_receive_from`的处理程序被写为`yield[ec]`(第 37 行)。 `yield_context`类有一个重载的下标操作符，我们可以使用它指定对`error_code`类型变量的可变引用。 当异步操作完成时，作为下标运算符的参数传递的变量将设置为错误代码(如果有)。

### 提示

在编写异步服务器时，更喜欢使用协同例程而不是处理程序链接。 协程实现了更简单的代码和更直观的控制流。

### 性能和并发性

我们声称异步通信模式提高了服务器的响应性。 让我们确切地了解是什么因素促成了这种改善。 在清单 11.17 的同步模型中，除非`send_to`函数返回，否则无法发出对`receive_from`的调用。 在清单 11.18 的异步代码中，一旦收到消息并使用(第 23-25 行)，就会调用`waitForReceive`，它不会等待`async_send_to`完成。 同样，在清单 11.19(它演示了在异步模型中使用协同例程)中，协同例程帮助挂起等待异步 I/O 操作完成的函数，同时继续处理队列中的其他任务。 这是提高异步服务器响应性的主要原因。

值得注意的是，在清单 11.18 中，所有 I/O 都发生在单个线程上。 这意味着在任何给定的时间点，我们的程序只处理一条传入的 UDP 消息。 这允许我们重用`buffer`和`remote_peer`成员变量，而不必担心同步问题。 在再次调用`waitForReceive`之前(第 24 行)，我们仍然必须确保打印接收到的缓冲区(第 22-23 行)。 如果颠倒了顺序，缓冲区可能会在打印之前被新的传入消息覆盖。

考虑一下如果我们在接收处理程序而不是发送处理程序中调用`waitForReceive`会发生什么，如下所示：

```
18     socket.async_receive_from(asio::buffer(buffer, MAXBUF),
19           remote_peer,
20           [this] (const sys::error_code& ec,
21                   size_t sz) {
...            ...
26             socket.async_send_to(
27                 asio::buffer(msg, strlen(msg)),
28                 remote_peer,
29                 [this](const sys::error_code& ec,
30                        size_t sz) {
31                   waitForReceive();
32                 });
33           });
```

在本例中，只有在发送完成后才会启动接收；因此，即使使用异步调用，也不会比清单 11.17 中的同步示例更好。

在清单 11.18 中，我们在发回内容时不需要从远程对等点接收的缓冲区，因此在发送完成之前我们不需要保留该缓冲区。 这允许我们在不等待发送完成的情况下启动异步接收(第 24 行)。 接收可以首先完成并覆盖缓冲区，但只要发送操作不使用缓冲区，一切都是正常的。 在现实世界中，情况往往并非如此，所以让我们看看如何在不将接收延迟到发送之后的情况下解决这个问题。 以下是处理程序的修改实现：

```
  17 void waitForReceive() {
 18   boost::shared_array<char> recvbuf(new char[MAXBUF]);
 19   auto epPtr(boost::make_shared<asio::ip::udp::endpoint>());
 20   socket.async_receive_from(
 21         asio::buffer(recvbuf.get(), MAXBUF),
  22         *epPtr,
 23         [this, recvbuf, epPtr] (const sys::error_code& ec,
  24                 size_t sz) {
 25           waitForReceive();
  26
  27           recvbuf[sz] = 0;
  28           std::ostringstream sout;
  29           sout << '[' << boost::this_thread::get_id()
  30                << "] Received: " << recvbuf.get()
  31                << " from client: " << *epPtr << '\n';
  32           std::cout << sout.str() << '\n';
  33           socket.async_send_to(
 34               asio::buffer(recvbuf.get(), sz),
  35               *epPtr,
 36               [this, recvbuf, epPtr](
 37                      const sys::error_code& ec, size_t sz) {
  38               });
  39        });
  40 }
```

现在，我们不再依赖共享成员变量的缓冲区，而是分配一个缓冲区来接收每条新消息(第 18 行)。 这样就不需要清单 11.18 中的`buffer`成员变量。 我们使用`boost::shared_array`包装器，因为这个缓冲区需要从`waitForReceive`调用传递给接收处理程序，而且，只有在最后一个对它的引用消失时才应该释放它。 同样，我们删除表示远程端点的`remote_peer`成员变量，并为每个新请求使用`shared_ptr`包装的端点。

我们将底层数组传递给`async_receive_from`(第 21 行)，并通过在`async_receive_from`的完成处理程序中捕获它的`shared_array`包装器(第 23 行)来确保它存在足够长的时间。 出于同样的原因，我们还捕获了端点包装器`epPtr`。 接收处理程序调用`waitForReceive`(第 25 行)，然后打印从客户端接收的消息，并以当前线程的线程 ID 为前缀(着眼于未来)。 然后它调用`async_send_to`，传递接收到的缓冲区，而不是某个固定消息(第 34 行)。 同样，我们需要确保缓冲区和远程端点在发送完成之前一直有效；因此，我们在发送完成处理程序中捕获缓冲区的`shared_array`包装器和远程端点的`shared_ptr`包装器(第 36 行)。

基于协同例程的异步 UDP 服务器的更改(清单 11.19)在同一行上：

```
 1 #include <boost/shared_array.hpp>
...
14 void udp_send_to(boost::asio::yield_context yield,
15               shared_udp_socket socket,
16               asio::ip::udp::endpoint peer,
17               boost::shared_array<char> buffer, size_t size)
18 {
19     const char *msg = "hello from server";
20     socket->async_send_to(asio::buffer(msg, std::strlen(msg)),
21                          peer, yield);
22     socket->async_send_to(asio::buffer(buffer.get(), size),
23                           peer, yield);
24 }
25
26 void udp_server(boost::asio::yield_context yield,
27                 asio::io_service& service,
28                 unsigned short port)
29 {
30   shared_udp_socket socket =
31       boost::make_shared<asio::ip::udp::socket>(service,
32           asio::ip::udp::endpoint(asio::ip::udp::v4(), port));
33
34   asio::ip::udp::endpoint remote_peer;
35   boost::system::error_code ec;
36
38   while (true) {
39     boost::shared_array<char> buffer(new char[MAXBUF]);
40     size_t size = socket->async_receive_from(
41                       asio::buffer(buffer.get(), MAXBUF),
42                       remote_peer, yield[ec]);
43
44     if (!ec) {
45       spawn(socket->get_io_service(), 
46         boost::bind(udp_send_to, ::_1, socket, remote_peer,
47                                  buffer, size));
43     }
44   }
45 }
```

由于从客户端接收的数据需要回显，因此`udp_send_to`协程必须能够访问该数据。 因此，它将包含接收到的数据和读取的字节数的缓冲区作为参数(第 17 行)。 为了确保该数据不会被后续的接收覆盖，我们必须在`udp_server`(第 39 行)中分配缓冲区，用于在循环的每次迭代中接收数据。 我们将此缓冲区以及`async_receive_from`(第 40 行)返回的读取字节数传递给`udp_send_to`(第 47 行)。 有了这些更改，我们的异步UDP服务器现在可以维护每个传入请求的上下文，直到它响应了该对等体，而不需要延迟处理较新的请求。

这些更改还使处理程序成为线程安全的，因为本质上，我们删除了处理程序之间的所有共享数据。 虽然`io_service`仍然是共享的，但它是线程安全对象。 我们可以很容易地将 UDP 服务器变成多线程服务器。 我们是这样做的：

```
46 int main() {
47   asio::io_service service;
48   UDPAsyncServer server(service, 55000);
49
50   boost::thread_group pool;
51   pool.create_thread([&service] { service.run(); });
52   pool.create_thread([&service] { service.run(); });
53   pool.create_thread([&service] { service.run(); });
54   pool.create_thread([&service] { service.run(); });
55   pool.join_all();
56 }
```

这将创建四个并发处理传入 UDP 消息的工作线程。 同样的道理也适用于协程程序。

## TCP

在网络 I/O 方面，UDP 的编程模型非常简单--要么发送消息，要么接收消息，或者两者兼而有之。 相比之下，TCP是一只相当复杂的野兽，它的交互模型还有一些额外的细节需要理解。

除了可靠性保证之外，TCP 还实现了几种巧妙的算法，以确保过于急切的发送方不会用大量数据淹没相对较慢的接收方(**流控制**)，并且所有发送方都能公平地分享网络带宽(**拥塞控制**)。 所有这些都需要在 TCP 层进行大量计算，TCP 需要维护一些状态信息来执行这些计算。 为此，TCP 在端点之间使用**个连接**。

### 建立 TCP 连接

**TCP 连接**由一对 TCP 套接字组成，这些套接字可能位于通过 IP 网络连接的不同主机上，并有一些相关的状态数据。 在连接的每一端都维护相关的连接状态信息。 **TCP 服务器**通常开始*监听传入连接*，并且被认为构成连接的**被动端**。 **TCP 客户端**发起连接到 TCP 服务器的请求，并且被称为连接的*主动端*。 称为**TCP 3 次握手**的定义明确的机制用于建立 TCP 连接。 存在用于协调连接终止的类似机制。 连接也可以单方面重置或终止，比如应用程序或主机因各种原因停机或出现某种不可恢复的错误。

#### 客户端和服务器端调用

要设置TCP 连接，服务器进程必须侦听端点，客户端进程必须主动发起到该端点的连接。 服务器执行以下步骤：

1.  创建 TCP 侦听器套接字。
2.  创建用于侦听传入连接的本地终结点，并将 TCP 侦听器套接字绑定到此终结点。
3.  开始监听监听程序上的传入连接。
4.  接受任何传入连接，并打开一个服务器端端点(与侦听器端点不同)以服务于该连接。
5.  在该连接上执行通信。
6.  处理连接的终止。
7.  继续侦听其他传入连接。

客户端依次执行以下步骤：

1.  创建一个 TCP 套接字，并可选择将其绑定到本地终结点。
2.  连接到由 TCP 服务器提供服务的远程终结点。
3.  连接建立后，在该连接上执行通信。
4.  处理连接的终止。

### 同步 TCP 客户端和服务器

现在，我们将编写一个 TCP 客户端，该客户端连接到指定主机和端口上的 TCP 服务器，向服务器发送一些文本，然后从服务器接收一些消息：

**清单 11.20：同步 TCP 客户端**

```
 1 #include <boost/asio.hpp>
 2 #include <iostream>
 3 namespace asio = boost::asio;
 4
 5 int main(int argc, char* argv[]) {
 6   if (argc < 3) {
 7     std::cerr << "Usage: " << argv[0] << " host port\n";
 8     exit(1);
 9   }
10
11   const char *host = argv[1], *port = argv[2];
12
13   asio::io_service service;
14   asio::ip::tcp::resolver resolver(service);
15   try {
16     asio::ip::tcp::resolver::query query(asio::ip::tcp::v4(),
17                                        host, port);
18     asio::ip::tcp::resolver::iterator end, 
19                        iter = resolver.resolve(query);
20
21     asio::ip::tcp::endpoint server(iter->endpoint());
22     std::cout << "Connecting to " << server << '\n';
23     asio::ip::tcp::socket socket(service, 
24                                  asio::ip::tcp::v4());
25     socket.connect(server);
26     std::string message = "Hello from client";
27     asio::write(socket, asio::buffer(message.c_str(),
28                                    message.size()));
29     socket.shutdown(asio::ip::tcp::socket::shutdown_send);
30 
31     char msg[BUFSIZ];
32     boost::system::error_code ec;
33     size_t sz = asio::read(socket, 
34                          asio::buffer(msg, BUFSIZ), ec);
35     if (!ec || ec == asio::error::eof) {
36       msg[sz] = 0;
37       std::cout << "Received: " << msg << '\n';
38     } else {
39       std::cerr << "Error reading response from server: "
40                 << ec.message() << '\n';
41     }
34   } catch (std::exception& e) {
35     std::cerr << e.what() << '\n';
36   }
37 }
```

TCP 客户端解析在命令行上传递给它的主机和端口(或服务名)(第 16-19 行)，并创建一个表示要连接到的服务器的端点(第 21 行)。 它创建一个 IPv4 套接字(第 23 行)，并调用其上的`connect`成员函数来发起到远程服务器的连接(第 25 行)。 `connect`调用会一直阻塞，直到建立连接，或者在连接尝试失败时抛出异常。 一旦连接成功，我们就使用`boost::asio::write`函数将文本`Hello from client`发送到服务器(第 27-28 行)。 我们使用参数`shutdown_send`调用套接字的`shutdown`成员函数(第 29 行)以关闭到服务器的写入通道。 这在服务器端显示为 EOF。 然后，我们使用`read`函数接收服务器发送的任何消息(第 33-34 行)。 `boost::asio::write`和`boost::asio::read`都在阻止调用。 调用`write`将在失败时抛出异常，例如，如果连接被重置或发送因服务器繁忙而超时。 我们调用`read`的非抛出重载，在失败时，它将非常数引用设置为我们传递给它的错误代码。

函数`boost::asio::read`尝试读取尽可能多的字节以填充传递的缓冲区，并进行阻塞，直到所有数据都已到达或接收到文件结尾。 尽管文件末尾被`read`标记为错误条件，但它可以简单地指示服务器已完成数据发送，我们会对接收到的任何数据感兴趣。 为此，我们特别使用了非抛出重载`read`，如果在`error_code`引用中设置了错误，我们将区分文件结束错误和其他错误(第 35 行)。 出于同样的原因，我们调用`shutdown`来关闭该连接上的写通道(第 29 行)，这样服务器就不会等待更多的输入。

### 提示

与 UDP 不同，TCP 是面向流的，不定义消息边界。 应用程序必须定义自己的机制来标识消息边界。 一些策略包括在消息中添加消息长度的前缀，使用字符序列作为消息结束标记，或者使用固定长度的消息。 在本书的示例中，我们使用`tcp::socket`的`shutdown`成员函数，该函数使接收方读取文件末尾，表示我们已完成发送消息。 这使示例变得简单，但在实践中，这并不是最灵活的策略。

现在让我们编写TCP 服务器，它将处理来自此客户端的请求：

**清单 11.21：同步 TCP 服务器**

```
 1 #include <boost/asio.hpp>
 2 #include <boost/thread.hpp>
 3 #include <boost/shared_ptr.hpp>
 4 #include <boost/array.hpp>
 5 #include <iostream>
 6 namespace asio = boost::asio;
 7
 8 typedef boost::shared_ptr<asio::ip::tcp::socket> socket_ptr;
 9
10 int main() {
11   const unsigned short port = 56000;
12   asio::io_service service;
13   asio::ip::tcp::endpoint endpoint(asio::ip::tcp::v4(), port);
14   asio::ip::tcp::acceptor acceptor(service, endpoint);
15
16   while (true) {
17     socket_ptr socket(new asio::ip::tcp::socket(service));
18     acceptor.accept(*socket);
19     boost::thread([socket]() {
20       std::cout << "Service request from "
21                 << socket->remote_endpoint() << '\n';
22       boost::array<asio::const_buffer, 2> bufseq;
23       const char *msg = "Hello, world!";
24       const char *msg2 = "What's up?";
25       bufseq[0] = asio::const_buffer(msg, strlen(msg));
26       bufseq[1] = asio::const_buffer(msg2, strlen(msg2));
27 
28       try {
29         boost::system::error_code ec;
30         char recvbuf[BUFSIZ];
31         auto sz = read(*socket, asio::buffer(recvbuf,
32                                             BUFSIZ), ec);
33         if (!ec || ec == asio::error::eof) {
34           recvbuf[sz] = 0;
35           std::cout << "Received: " << recvbuf << " from "
36                     << socket->remote_endpoint() << '\n';
37           write(*socket, bufseq);
38           socket->close();
39         }
40       } catch (std::exception& e) {
41         std::cout << "Error encountered: " << e.what() << '\n';
42       }
43     });
44   }
45 }
```

TCP 服务器做的第一件事是创建侦听器套接字并将其绑定到本地端点。 使用 Boost ASIO，您可以通过创建`asio::ip::tcp::acceptor`的实例并将其传递给要绑定到的端点来实现这一点(第 14 行)。 我们创建一个 IPv4 端点，只指定端口而不指定地址，以便它使用未指定的地址 0.0.0.0(第 13 行)。 我们通过将端点传递给`acceptor`的构造函数将端点绑定到侦听器(第 14 行)。 然后，我们在循环中旋转，等待传入的连接(第 16 行)。 我们创建一个新套接字，因为我们需要一个不同的套接字来充当每个新连接的服务器端端点(第 17 行)。 然后，我们调用接受器上的`accept`成员函数(第 18 行)，将新套接字传递给它。 对`accept`的调用将阻塞，直到建立新连接。 当`accept`返回时，传递给它的套接字表示所建立的连接的服务器端端点。

我们创建一个新线程来为每个建立的新连接提供服务(第 19 行)。 我们使用 lambda(第 19-44 行)为该线程生成初始函数，为该连接捕获`shared_ptr`包装的服务器端`socket`(第 19 行)。 在线程中，我们调用`read`函数来读取客户端发送的数据(第 31-32 行)，然后使用`write`写回数据(第 37 行)。 为了说明它是如何完成的，我们从一个从两个字符串设置的多缓冲区序列发送数据(第 22-26 行)。 该线程中的网络 I/O 在 try-block 内完成，以确保没有异常逃脱该线程。 请注意，在对`write`的调用返回之后(第 38 行)，我们在套接字上调用`close`。 这将关闭来自服务器端的连接，并且客户端读取接收到的流中的文件结尾。

#### 并发性和性能

TCP 服务器独立地处理每个连接。 但是，为每个新连接创建一个新线程的伸缩性很差，如果大量连接在非常短的时间间隔内命中它，服务器的资源可能会超载。 处理此问题的一种方法是限制线程数量。 早些时候，我们修改了清单 11.18 中的 UDP 服务器示例，以使用线程池并限制线程总数。 我们可以使用清单 11.21 中的 TCP 服务器执行相同的操作。 以下是如何做到这一点的概要：

```
12 asio::io_service service;
13 boost::unique_ptr<asio::io_service::work> workptr(
14                                    new dummyWork(service));
15 auto threadFunc = [&service] { service.run(); };
16 
17 boost::thread_group workers;
18 for (int i = 0; i < max_threads; ++ i) { //max_threads
19   workers.create_thread(threadFunc);
20 }
21
22 asio::ip::tcp::endpoint ep(asio::ip::tcp::v4(), port);
23 asio::ip::tcp::acceptor acceptor(service, ep);24 while (true) {
25   socket_ptr socket(new asio::ip::tcp::socket(service));
26   acceptor.accept(*socket);
27
28   service.post([socket] { /* do I/O on the connection */ });
29 }
30
31 workers.join_all();
32 workptr.reset(); // we don't reach here
```

首先，我们创建固定数量的线程的池(第 15-20 行)，并通过将虚拟工作发送到`io_service`的任务队列(第 13-14 行)来确保它们不会退出。 我们没有为每个新连接创建线程，而是将该连接的处理程序发布到`io_service`的任务队列(第 28 行)。 该处理程序可以与清单 11.21 中每个连接线程的初始函数完全相同。 然后，池中的线程按照自己的调度调度处理程序。 可以根据系统中的处理器数量轻松调整`max_threads`表示的线程数量。

虽然使用线程池限制了线程的数量，但它对提高服务器的响应性几乎没有什么作用。 在大量新连接涌入的情况下，较新连接的处理程序将在队列中形成大量积压，而这些客户端将在服务器为较早连接提供服务时保持等待。 我们已经通过使用异步 I/O 解决了 UDP 服务器中的类似问题。在下一节中，我们将使用相同的策略更好地扩展我们的 TCP 服务器。

### Колибриобработельный异步 tcp 服务器

同步 TCP 服务器效率低下，主要是因为套接字上的读写操作会阻塞有限的时间，等待操作完成。 在此期间，即使有线程池，服务连接的线程也只是空闲地等待 I/O 操作完成，然后才能继续处理下一个可用连接。

我们可以使用异步 I/O 消除这些空闲等待。正如我们在使用异步 UDP 服务器时看到的那样，我们可以使用处理程序链或协程程序来编写异步 TCP 服务器。 处理程序链使代码变得复杂，因此容易出错，而协程使代码更具可读性和直观性。 我们将首先使用协同例程编写一个异步 TCP 服务器，然后使用更传统的处理程序链接，以便正确看待这两种方法之间的区别。 您可以在第一次阅读时跳过处理程序链接实现。

#### 使用协程的异步 TCP 服务器

以下是通过协同例程使用异步 I/O 的 TCP 服务器的完整代码：

**清单 11.22：使用协程**的异步 TCP 服务器

```
 1 #include <boost/asio.hpp>
 2 #include <boost/asio/spawn.hpp>
 3 #include <boost/thread.hpp>
 4 #include <boost/shared_ptr.hpp>
 5 #include <boost/make_shared.hpp>
 6 #include <boost/bind.hpp>
 7 #include <boost/array.hpp>
 8 #include <iostream>
 9 #include <cstring>
10
11 namespace asio = boost::asio;
12 typedef boost::shared_ptr<asio::ip::tcp::socket> socketptr;
13
14 void handle_connection(asio::yield_context yield,
15                        socketptr socket)
16 {
17   asio::io_service& service = socket->get_io_service();
18   char msg[BUFSIZ];
19   msg[0] = '\0';
20   boost::system::error_code ec;
21   const char *resp = "Hello from server";
22
23   size_t size = asio::async_read(*socket, 
24                      asio::buffer(msg, BUFSIZ), yield[ec]);
25
26   if (!ec || ec == asio::error::eof) {
27     msg[size] = '\0';
28     boost::array<asio::const_buffer, 2> bufseq;
29     bufseq[0] = asio::const_buffer(resp, ::strlen(resp));
30     bufseq[1] = asio::const_buffer(msg, size);
31
32     asio::async_write(*socket, bufseq, yield[ec]);
33     if (ec) {
34       std::cerr << "Error sending response to client: "
35                 << ec.message() << '\n';
36     }
37   } else {
38     std::cout << ec.message() << '\n';
39   }
40 }
41
42 void accept_connections(asio::yield_context yield,
43                         asio::io_service& service,
44                         unsigned short port)
45 {
46   asio::ip::tcp::endpoint server_endpoint(asio::ip::tcp::v4(),
47                                           port);
48   asio::ip::tcp::acceptor acceptor(service, server_endpoint);
49
50   while (true) {
51     auto socket = 
52         boost::make_shared<asio::ip::tcp::socket>(service);
53     acceptor.async_accept(*socket, yield);
54
55     std::cout << "Handling request from client\n";
56     spawn(service, boost::bind(handle_connection, ::_1, 
57                                socket));
58   }
59 }
60
61 int main() {
62   asio::io_service service;
63   spawn(service, boost::bind(accept_connections, ::_1,
64                              boost::ref(service), 56000));
65   service.run();
66 }
```

我们使用两个协程：`accept_connections`处理传入的连接请求(第 42 行)，而`handle_connection`对每个新连接执行 I/O(第 14 行)。 `main`函数调用`spawn`函数模板，将`accept_connections`任务添加到`io_service`队列，作为协程运行(第 63 行)。 派生函数模板可以通过标题`boost/asio/spawn.hpp`(第 2 行)获得。 对`io_service`的`run`成员函数的调用调用了`accept_connections`协程，该协程循环等待新的连接请求(第 65 行)。

除了必需的`yield_context`之外，`accept_connections`函数还接受两个参数。 这些是对`io_service`实例的引用，以及要侦听新连接的端口-当`main`函数产生此协程时(第 63-64 行)，这些值由`main`函数绑定。 `accept_connections`函数为未指定的 IPv4 地址及其传递的特定端口创建一个端点(第 46-47 行)，并为该端点创建一个接受者(第 48 行)。 然后，它在循环的每次迭代中调用接受者的`async_accept`成员函数，传递对 TCP 套接字的引用，并将本地`yield_context`作为完成处理程序(第 53 行)。 这会暂停`accept_connections`协同例程，直到接受新连接。 一旦接收到新的连接请求，`async_accept`就接受它，将传递给它的套接字引用设置为新连接的服务器端套接字，并恢复`accept_connections`协程。 `accept_connections`协同例程将`handle_connection`协同例程添加到`io_service`队列以处理该特定连接上的 I/O(第 56-57 行)。 在循环的下一次迭代中，它再次等待新的传入连接。

除了`yield_context`之外，`handle_connection`协程还将包装在`shared_ptr`中的 TCP 套接字作为参数。 `accept_connections`协程创建此套接字，并将其传递给`handle_connection`，包装在`shared_ptr`中。 `handle_connection`函数接收客户端使用`async_read`发送的任何数据(第 23-24 行)。 如果接收成功，则发送回响应字符串`Hello from server`，然后使用长度为 2 的缓冲区序列回显接收的数据(第 28-30 行)。

#### 不带协程的异步 TCP 服务器

我们现在看看如何在没有协程的情况下编写异步 TCP 服务器。 这涉及到处理程序之间更复杂的握手，因此，我们希望将代码拆分成适当的类。 我们在两个单独的头文件中定义了两个类。 类`TCPAsyncServer`(清单 11.23)表示侦听传入连接的服务器实例。 它位于`asyncsvr.hpp`头文件中。 类`TCPAsyncConnection`(清单 11.25)表示单个连接的处理上下文。 它位于`asynconn.hpp`头文件中。

`TCPAsyncServer`为每个新的传入连接创建`TCPAsyncConnection`的新实例。 `TCPAsyncConnection`实例从客户端读取传入数据，并将消息发送回客户端，直到客户端关闭与服务器的连接。

要启动服务器，请创建`TCPAsyncServer`的实例，传递`io_service`的实例和端口号，然后调用`io_service`的`run`成员函数开始处理新连接：

**清单 11.23：异步 TCP 服务器(asyncsvr.hpp)**

```
 1 #ifndef ASYNCSVR_HPP
 2 #define ASYNCSVR_HPP
 3 #include <boost/asio.hpp>
 4 #include <boost/shared_ptr.hpp>
 5 #include <boost/make_shared.hpp>
 6 #include <iostream>
 7 #include "asynconn.hpp"
 8
 9 namespace asio = boost::asio;
10 namespace sys = boost::system;
11 typedef boost::shared_ptr<TCPAsyncConnection>
12               TCPAsyncConnectionPtr;
13
14 class TCPAsyncServer {
15 public:
16   TCPAsyncServer(asio::io_service& service, unsigned short p)
17           : acceptor(service,
18                     asio::ip::tcp::endpoint(
19                           asio::ip::tcp::v4(), p)) {
20     waitForConnection();
21   }
22
23   void waitForConnection() {
24     TCPAsyncConnectionPtr connectionPtr = boost::make_shared
25           <TCPAsyncConnection>(acceptor.get_io_service());
26     acceptor.async_accept(connectionPtr->getSocket(),
27           [this, connectionPtr](const sys::error_code& ec) {
28             if (ec) {
29               std::cerr << "Failed to accept connection: "
30                         << ec.message() << "\n";
31             } else {
32               connectionPtr->waitForReceive();
33               waitForConnection();
34             }
35           });
36   }
37
38 private:
39   asio::ip::tcp::acceptor acceptor;
40 };
41
42 #endif /* ASYNCSVR_HPP */
```

`TCPAsyncServer`类有一个类型为`boost::asio::ip::tcp::acceptor`的接受器成员变量，用于侦听和接受传入连接(第 39 行)。 构造函数使用未指定 IPv4 地址和特定端口上的本地 TCP 端点初始化接受器(第 17-19 行)，然后调用`waitForConnection`成员函数(第 20 行)。

`waitForConnection`函数创建包装在名为`connectionPtr`的`shared_ptr`中的`TCPAsyncConnection`的新实例(第 24-25 行)，以处理来自客户端的每个新连接。 我们已经包含了我们自己的头文件`asynconn.hpp`来访问`TCPAsyncConnection`的定义(第 7 行)，稍后我们将讨论这一点。 然后，它调用接受器上的`async_accept`成员函数来监听新的传入连接并接受它们(第 26-27 行)。 我们传递给`async_accept`，非常数引用是`TCPAsyncConnection`的成员之一的`tcp::socket`对象，以及每次建立新连接时调用的完成处理程序(第 27-35 行)。 它是一个异步调用，并且立即返回。 但每次建立新连接时，套接字引用都会被设置为服务于该连接的服务器端套接字，并调用完成处理程序。

`async_accept`的完成处理程序被编写为 lambda，它捕获指向`TCPAsyncServer`实例和`connectionPtr`的`this`指针(第 27 行)。 这允许 lambda 在`TCPAsyncServer`实例和服务于此特定连接的`TCPAsyncConnection`实例上调用成员函数。

### 提示

Lambda 表达式生成一个函数对象，并将捕获的`connectionPtr`复制到其中的一个成员。 由于`connectionPtr`是`shared_ptr`，因此其引用计数在该过程中会增加。 `async_accept`函数将此函数对象推入`io_service`的任务处理程序队列，因此，即使在`waitForConnection`返回之后，`TCPAsyncConnection`的底层实例也会继续存在。

在建立连接时，当调用完成处理程序时，它会做两件事。 如果没有错误，它通过调用`TCPAsyncConnection`对象上的`waitForReceive`函数在新连接上启动 I/O(第 32 行)。 然后，它通过捕获的`this`指针在`TCPAsyncServer`对象上调用`waitForConnection`，重新开始等待下一个连接(第 33 行)。 如果出现错误，它会打印一条消息(第 29-30 行)。 `waitForConnection`调用是异步的，我们很快就会发现`waitForReceive`调用也是异步的，因为这两个调用都调用异步 ASIO 函数。 处理程序返回后，服务器继续处理现有连接上的 I/O 或接受新连接：

**清单 11.24：运行异步服务器**

```
 1 #include <boost/asio.hpp>
 2 #include <boost/thread.hpp>
 3 #include <boost/shared_ptr.hpp>
 4 #include <iostream>
 5 #include "asyncsvr.hpp"
 6 #define MAXBUF 1024
 7 namespace asio = boost::asio;
 8
 9 int main() {
10   try {
11     asio::io_service service;
12     TCPAsyncServer server(service, 56000);
13     service.run();
14   } catch (std::exception& e) {
15     std::cout << e.what() << '\n';
16   }
17 }
```

要运行服务器，我们只需用`io_service`和端口号实例化它(第 12 行)，然后调用`io_service`上的`run`方法(第 13 行)。 我们正在构建的服务器将是线程安全的，因此我们还可以从每个线程池调用`run`，以便在处理传入连接时引入一些并发性。 现在我们将了解如何处理每个连接上的 I/O：

**清单 11.25：每个连接的 I/O 处理程序类(asynConn.hpp)**

```
 1 #ifndef ASYNCONN_HPP
 2 #define ASYNCONN_HPP
 3
 4 #include <boost/asio.hpp>
 5 #include <boost/thread.hpp>
 6 #include <boost/shared_ptr.hpp>
 7 #include <iostream>
 8 #define MAXBUF 1024
 9
10 namespace asio = boost::asio;
11 namespace sys = boost::system;
12
13 class TCPAsyncConnection
14   : public boost::enable_shared_from_this<TCPAsyncConnection> {
15 public:
16   TCPAsyncConnection(asio::io_service& service) :
17       socket(service) {}
18
19   asio::ip::tcp::socket& getSocket() {
20     return socket;
21   }
22
23   void waitForReceive() {
24     auto thisPtr = shared_from_this();
25     async_read(socket, asio::buffer(buf, sizeof(buf)),
26         [thisPtr](const sys::error_code& ec, size_t sz) {
27           if (!ec || ec == asio::error::eof) {
28             thisPtr->startSend();
29             thisPtr->buf[sz] = '\0'; 
30             std::cout << thisPtr->buf << '\n';
31             
32             if (!ec) { thisPtr->waitForReceive(); }
33           } else {
34             std::cerr << "Error receiving data from "
35                     "client: " << ec.message() << "\n";
36           }
37         });
38   }
39
40   void startSend() {
41     const char *msg = "Hello from server";
42     auto thisPtr = shared_from_this();
43     async_write(socket, asio::buffer(msg, strlen(msg)),
44         [thisPtr](const sys::error_code& ec, size_t sz) {
45           if (ec) {
46             if (ec == asio::error::eof) {
47                thisPtr->socket.close();
48             }
49             std::cerr << "Failed to send response to "
50                     "client: " << ec.message() << '\n';
51           }
52         });
53   }
54
55 private:
56   asio::ip::tcp::socket socket;
57   char buf[MAXBUF];
58 };
59
60 #endif /* ASYNCONN_HPP */
```

在清单 11.23 中，我们看到了如何创建实例(包装在`shared_ptr`中)来处理每个新连接，并通过调用`waitForReceive`成员函数在其上启动 I/O。 现在让我们了解一下它的实现。 `TCPAsyncConnection`有两个用于在连接上执行异步 I/O 的公共成员：`waitForReceive`执行异步接收(第 23 行)和`startSend`执行异步发送(第 40 行)。

`waitForReceive`函数通过调用套接字上的`­async­_read`函数启动接收(第 25 行)。 数据被接收到`buf`成员(行 57)。 当完全接收到数据时，调用该调用的完成处理程序(第 26-37 行)。 如果没有错误，它调用`startSend`，后者向客户端异步发送消息(第 28 行)，然后再次调用`waitForReceive`，前提是前一次接收没有遇到文件结尾(第 32 行)。 因此，只要没有读取错误，服务器就会一直等待读取连接上的更多数据。 如果出现错误，它会打印一条诊断消息(第 34-35 行)。

函数`startSend`使用函数`async_write`将文本`Hello from server`发送到客户端。 它的处理程序在成功时不执行任何操作，但在失败时打印诊断消息(第 49-50 行)。 对于 EOF 写入错误，它关闭套接字(第 47 行)。

#### TCPAsyncConnection 的寿命

只要客户端保持与服务器的连接，`TCPAsyncConnection`的每个实例就需要继续存在。 这使得很难将此对象的作用域绑定到服务器中的任何函数。 这就是我们创建包装在`shared_ptr`中的`TCPAsyncConnection`对象，然后在处理程序 lambdas 中捕获它的原因。 用于在连接上执行 I/O 的`TCPAsyncConnection`成员函数`waitForReceive`和`startSend`都是异步的。 因此，它们在返回之前将一个处理程序推入`io_service`的任务队列中。这些处理程序捕获`TCPAsyncConnection`的`shared_ptr`包装实例，以在调用之间保持该实例的活动状态。

为了使处理程序能够从`waitForReceive`和`startSend`中访问`TCPAsyncConnection`对象的`shared_ptr`包装实例，需要`TCPAsyncConnection`的这些成员函数能够访问它们被调用的`shared_ptr`包装实例。 我们在[第 3 章](03.html "Chapter 3. Memory Management and Exception Safety")，*内存管理和异常安全*中学到的*从这个*习语中启用共享就是为这些目的量身定做的。 这就是我们从`enable_shared_from_this<TCPAsyncConnection>`推导出`TCPAsyncConnection`的原因。 因此，`TCPAsyncConnection`继承了`shared_from_this`成员函数，该函数返回我们需要的`shared_ptr`包装的实例。 这意味着应该始终动态分配`TCPAsyncConnection`并将其包装在`shared_ptr`中，任何其他方式都会导致未定义的行为。

这就是我们在`waitForReceive`(第 24 行)和`startSend`(第 42 行)中调用`shared_from_this`的原因，它被各自的处理程序捕获(第 26、44 行)。 只要`waitForReceive`成员函数不断被`async_read`的完成处理程序调用(第 32 行)，`TCPAsyncConnection`实例就会继续存在。 如果由于远程终结点关闭连接或其他原因，在接收过程中遇到错误，则此循环将中断。 包装`TCPAsyncConnection`对象的`shared_ptr`不再被任何处理程序捕获，并在作用域结束时被销毁，从而关闭连接。

#### 性能和并发性

请注意，TCP 异步服务器的两个实现，无论有没有协同例程，都是单线程的。 但是，在这两种实现中都不存在线程安全问题，所以我们也可以使用线程池，每个线程都会在`io_service`上调用`run`。

#### 控制流倒置

对异步系统进行编程的最大困难是控制流的反转。 要编写同步服务器的代码，我们知道必须按以下顺序调用操作：

1.  对接受者调用`accept`。
2.  在套接字上调用`read`。
3.  在套接字上调用`write`。

我们知道`accept`只有在连接建立后才返回，所以调用`read`是安全的。 此外，`read`仅在读取了请求的字节数或遇到文件结尾后才返回。 因此，随后进行`write`呼叫是安全的。 与异步模型相比，这使得编写代码非常容易，但也引入了等待，这会影响我们在处理请求时处理其他等待连接的能力。

我们使用异步 I/O 消除了等待，但在使用处理程序链接时失去了模型的简单性。 因为我们不能确定异步 I/O 操作在哪一点完成，所以我们要求`io_service`在我们的请求完成时运行特定的处理程序。 我们仍然知道在那之后要做什么手术，但我们不再知道什么时候做。 因此，我们告诉`io_service`*运行什么*，并且它使用来自操作系统的适当通知来知道*何时*运行它们。 此模型中最大的挑战是跨处理程序维护对象状态和管理对象生存期。

协程程序通过允许将异步 I/O 操作序列写入单个协程程序来消除控制流的这种*反转，该协程程序被*挂起*，而不是等待异步操作完成，并在操作完成时*恢复*。 这允许无需等待的逻辑，而无需处理程序链接的固有复杂性。*

### 提示

在编写异步服务器时，始终优先使用协程而不是处理程序链接。

# 自测题

对于多项选择题，请选择适用的所有选项：

1.  What is the difference between `io_service::dispatch` and `io_service::post`?

    A.`dispatch`立即返回，而`post`在返回之前运行处理程序

    B.`post`立即返回，而`dispatch`可能会在当前线程上运行处理程序(如果可能)，或者它的行为类似于 POST

    C.`post`是线程安全的，而`dispatch`不是

    D.`post`在`dispatch`运行处理程序时立即返回

2.  What happens if a handler throws an exception when it is dispatched?

    A.这是一种未定义的行为

    B.它通过调用`std::terminate`来终止程序

    C.要在调度处理程序的`io_service`上运行的调用将抛出

    D.停止`io_service`

3.  What is the role of the unspecified address 0.0.0.0 (IPv4) or ::/1 (IPv6)?

    A.它用于与系统上的本地服务通信

    B.发送到此地址的数据包将被回送到发送方

    C.用于向网络中所有连接的主机广播

    D.它用于绑定到所有可用接口，而无需知道地址

4.  Which of the following statements about TCP are true?

    A.TCP 比 UDP 更快

    B.TCP 检测到数据损坏，但没有检测到数据丢失

    C.TCP 比 UDP 更可靠

    D.TCP 重新传输丢失或损坏的数据

5.  What do we mean when we say that a particular function, for example, `async_read`, is asynchronous?

    A.函数在请求的操作完成之前返回

    B.该函数在另一个线程上启动操作并立即返回

    C.请求的操作被排队等待由同一线程或另一线程处理

    D.该函数如果可以立即执行该操作，则执行该操作；如果不能立即执行该操作，则返回错误

6.  How can we ensure that an object created just before calling an asynchronous function would still be available in the handler?

    A.使对象成为全局对象。

    B.在处理程序中复制/捕获包装在`shared_ptr`中的对象。

    C.动态分配对象并将其包装在`shared_ptr`中。

    D.使对象成为类的成员。

# 摘要

ASIO 是一个设计良好的库，可用于编写快速、灵活的网络服务器，这些服务器利用系统上可用的最优异步 I/O 机制。 它是一个不断发展的库，也是技术规范的基础，该技术规范建议在 C++ 标准的未来修订版中添加网络库。

在本章中，我们学习了如何将 Boost ASIO 库用作任务队列管理器，以及如何利用 ASIO 的 TCP 和 UDP 接口编写通过网络通信的程序。 使用 Boost ASIO，我们能够强调网络编程的一些一般问题、针对大量并发连接进行扩展所面临的挑战，以及异步 I/O 的优势和复杂性。特别是，我们看到了与旧的链接处理程序模型相比，使用堆栈协程如何使编写异步服务器变得轻而易举。 虽然我们没有介绍无堆栈协程、ICMP 协议和串口通信等内容，但本章涵盖的主题应该会为您理解这些领域提供坚实的基础。

# 发文：2013 年 2 月 10 日星期日下午 12：00

*   *用 C++ 进行异步思考*(博客)，*Christopher Kohlhoff*：[http://blog.think-async.com/](http://blog.think-async.com/)
*   *网络库建议书*，*Christopher Kohlhoff*：[http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2014/n4332.html](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2014/n4332.html)**